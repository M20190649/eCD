%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-0.5ex}
\section{Related Work}
\label{sec-into}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\eat{%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Trajectory compression algorithms are normally classified into two categories, namely lossless compression and lossy compression\cite{Muckell:Compression}.
(1) Lossless compression methods enable exact reconstruction of the original data from the compressed data without information loss.
%For example, delta compression \cite{Nibali:Trajic} is a lossless compression technique, which has zero error and a time complexity of $O(n)$, where $n$ is the number of data points in a trajectory. The limitation of lossless compression lies in that its compression ratio is relatively poor \cite{Nibali:Trajic}.
(2) In contrast, lossy compression methods allow errors or derivations, compared with the original trajectories.
These techniques typically identify important data points, and remove statistical redundant data points from a trajectory, or replace original data points in a trajectory with other places of interests, such as roads and shops.
They focus on good compression ratios with acceptable errors.
%, and a large number of lossy trajectory compression techniques have been developed.
%
%In this work we focus on lossy compression of trajectory data,
We next introduce the related work on lossy trajectory compression  from two aspects: line simplification based methods and semantics based methods.

\subsection{Line simplification based methods}
}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%Line simplification (\lsa) methods use a set of continuous line segments to represent a compressed trajectory (Fig.\ref{fig:notations}).
The idea of piece-wise line simplification comes from computational geometry.
Its target is to approximate a given finer piece-wise linear curve by another coarser piece-wise linear curve, which is typically a subset of the former, such that the maximum distance of the former from the later is bounded by a user specified constant $\epsilon$.
The optimal methods that find the minimal number of points or segments (\ie the $min$--$\#$ problem) have the time complexity of $O(n^2)$ where $n$ is the number of the original points\cite{Chan:Optimal}.
They are time-consuming, making them impractical for large inputs~\cite{Heckbert:Survey}. Hence, many work targeting at finding the sub-optimal results were developed.
\eat{
The distinct Douglas-Peucker (\dpa) algorithm \cite{Douglas:Peucker} (see Figure~\ref{fig:notations}) is invented in 1970s, for reducing the number of points required to represent a digitized line or its caricature in the context of computer graphics and image processing.
The basic \dpa is a batch approach with a time complexity of $O(n^2)$.
%Algorithm \dpa is the foundation of many subsequent \lsa algorithms.
Some online \lsa algorithms were further developed by combining batch algorithms (\eg \dpa) with sliding/open windows \cite{Meratnia:Spatiotemporal, Liu:BQS}.
Recently, the authors of this paper developed a one-pass trajectory simplification algorithm (\operb) \cite{Lin:Operb}, which runs great fast and also has comparable compression ratio comparing with batch algorithms. Moreover, the ``cone intersection" algorithm \cite{Williams:Longest, Sklansky:Cone, Dunham:Cone, Zhao:Sleeve} is another notable one-pass \lsa algorithm.
}
%In this section, we focus on the piece-wise line simplification based methods for trajectory data.
In particular, the state-of-the-art the sub-optimal line simplification approaches can be classified into three categories, \ie \emph{batch algorithms}, \emph{online algorithms} and \emph{one-pass algorithms}.
%
Moreover, for trajectory compression, there are two types of widely used distance metrics, namely the \ped and \sed approaches.
The \ped is developed in company with the line simplification algorithms and is applied in most of the three category algorithms;
the \sed is first introduce in ~\cite{Meratnia:Spatiotemporal}, called the \emph{time-ratio distance}, and formally presented in ~\cite{Potamias:Sampling}, called the \emph{Synchronous Euclidean Distance}. It is a specific distance metric for trajectory data, and is normally enabled in some batch and online algorithms.
%
We next introduce these algorithms and their distance metrics.

\stitle{Batch algorithms.}
The batch algorithms enforces global distance checking policy.
Global checking requires that all trajectory points be loaded before they start compressing, hence they run in batch.
Furthermore, these batch algorithms can be either top-down or bottom-up.
Top-down algorithms, e.g., Ramer \cite{Ramer:Split} and Douglas-Peucker \cite{Douglas:Peucker}, recursively divide a trajectory into sub-trajectories until the stopping condition is met.
%
Bottom-up algorithms, e.g., Theo Pavlidis' Algorithm \cite{Pavlidis:Segment}, is the natural complement to top-down ones, which recursively merge adjacent sub-trajectories with the smallest distance, initially $n/2$  sub-trajectories for a trajectory with $n$ points, until the stopping condition is met.
%
The distances of newly generated line segments are recalculated during the process.
%
These batch algorithms originally support \ped, however, it is easy to extend them to support \sed.
%
The batch nature and high time complexities make them not practical in online scenarios.


\stitle{Online algorithms.}
The online algorithms enforces a constrained global distance checking policy which restricts the checking within a sliding or opening window.
%, hence, they are online algorithms.
Constrained global checking algorithms need not have the entire trajectory ready before they start compressing, and are appropriate for compressing trajectories on sensors of mobile devices.
%Moreover, the existing constrained global checking algorithms~\cite{Keogh:online,Meratnia:Spatiotemporal,Muckell:Compression} usually use a sliding or opening window and compress sub-trajectories in the window.
Several line simplification algorithms have been developed, e.g., by combining \dpa or \pavlidis with sliding or opening windows for online processing\cite{Meratnia:Spatiotemporal}. %, Keogh:online
%\cite{Meratnia:Spatiotemporal} is a combination of Top-down and opening window while \cite{Keogh:online} is a combination of Bottom-up and sliding window.
These methods still have a high time and/or space complexity, which significantly hinders their utility in resource-constrained mobile devices \cite{Liu:BQS}.
%
\bqsa \cite{Liu:BQS} and \squishe\cite{Muckell:Compression} further optimize the opening window algorithms.
%
\bqsa \cite{Liu:BQS} fast the processing by picking out at most eight special points from an open window based on a convex hull. However, the convex hull method also hinders \bqsa supporting \sed.
%The time complexity of \bqsa is $O(n^2)$ in the worst case.
%it \eat{optimizes the \pavlidis by using} 
The \squishe\cite{Muckell:Compression} algorithm is an combination of {opening} window and Bottom-up. It uses a doubly linked list $Q$ so as to achieve a better efficiency. \squishe supports \sed, however, it is not linear time, and its compression ratio is obviously poorer than our algorithm \cist.

\stitle{One-pass algorithms.}
The one-pass algorithms enforces a local checking policy.
\eat{The local checking policy, the key to achieve the \emph{one-pass} processing, They do not need a window to buffer the preview read points.
Meanwhile, a trajectory compression algorithm is {\em one-pass} if it processes each point in a trajectory once and only once when compressing the trajectory.
}
They do not need a window to buffer the preview read points as they process each point in a trajectory once and only once.
Obviously, the one-pass algorithms have a linear time complexity and a constant space.
%
The $n^{th}$ point routine and the routine of random-selection of points \cite{Shi:Survey} are two naive one-pass algorithms.
In these routines, for every fixed number of consecutive points along the line, the $n^{th}$ point and one random point among them are retained, respectively.
They run fast, however, they are not error bounded.
%
In Reumann-Witkam routine\cite{Reumann:Strip}, it builds a strip paralleling to the line connecting the first two points, then the points within this strip compose one section of the line.
The Reumann-Witkam routine also runs fast but it is limited in compression ratio.
%
Williams~\cite{Williams:Longest} and Sklansky and Gonzalez \cite{Sklansky:Cone} proposed linear time algorithms based on the idea of sector intersection, Dunham \cite{Dunham:Cone} and Zhao \cite{Zhao:Sleeve} further extended these algorithms.
These algorithms run fast as well as have comparable compression ratio with the \dpa and \pavlidis algorithms.
%
Moreover, {fast \bqsa \cite{Liu:BQS} (\fbqsa in short), the simplified version of \bqsa, has a linear time complexity.}
%
The authors of this paper have also developed the One-Pass ERror Bounded (\operb) algorithm \cite{Lin:Operb}.
%
The sector intersection algorithms, \fbqsa and \operb only support \ped,
while the one-pass algorithm presented in this paper supports \sed.



There are also semantics based trajectory compression methods (interested readers are referred to ~\cite{Lin:Operb} for more details), these approaches are orthogonal to line simplification based methods, and may be combined with each other to further improve the effectiveness of trajectory compression.

\eat{%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Semantics based methods}.
The trajectories of certain moving objects such as cars and trucks are constrained by road networks. These moving objects typically travel along road networks, instead of the line segment between two points. Trajectory compression methods based on road networks \cite{Chen:Trajectory, Popa:Spatio,Civilis:Techniques,Hung:Clustering, Gotsman:Compaction, Song:PRESS}  project trajectory points onto roads (also known as Map-Matching). Moreover, \cite{Gotsman:Compaction, Song:PRESS} mines and uses high frequency patterns of compressed trajectories, instead of roads, to further improve compression effectiveness.
%
Some methods \cite{Schmid:Semantic, Richter:Semantic} compress trajectories beyond the use of road networks, which further make use
of other user specified domain knowledge, such as places of interests along the trajectories \cite{Richter:Semantic}.
%
There are also compression algorithms preserving the direction of the trajectory \cite{Long:Direction, Long:Trajectory}. %As it mentions that the trajectory of a moving object contains a large amount of semantic information that could be used to compress the trajectory. For example, the driving direction of a moving object implies the information of the next direction.

These approaches are orthogonal to line simplification based methods, and may be combined with each other to further improve the effectiveness of trajectory compression.
}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
