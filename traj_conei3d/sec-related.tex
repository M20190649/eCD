%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-0.5ex}
\section{Related Work}
\label{sec-into}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\eat{%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Trajectory compression algorithms are normally classified into two categories, namely lossless compression and lossy compression\cite{Muckell:Compression}.
(1) Lossless compression methods enable exact reconstruction of the original data from the compressed data without information loss.
%For example, delta compression \cite{Nibali:Trajic} is a lossless compression technique, which has zero error and a time complexity of $O(n)$, where $n$ is the number of data points in a trajectory. The limitation of lossless compression lies in that its compression ratio is relatively poor \cite{Nibali:Trajic}.
(2) In contrast, lossy compression methods allow errors or derivations, compared with the original trajectories.
These techniques typically identify important data points, and remove statistical redundant data points from a trajectory, or replace original data points in a trajectory with other places of interests, such as roads and shops.
They focus on good compression ratios with acceptable errors.
%, and a large number of lossy trajectory compression techniques have been developed.
%
%In this work we focus on lossy compression of trajectory data,
We next introduce the related work on lossy trajectory compression  from two aspects: line simplification based methods and semantics based methods.

\subsection{Line simplification based methods}
}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%Line simplification (\lsa) methods use a set of continuous line segments to represent a compressed trajectory (Fig.\ref{fig:notations}).
The idea of piece-wise line simplification comes from computational geometry.
Its target is to approximate a given finer piece-wise linear curve by another coarser piece-wise linear curve, which is typically a subset of the former, such that the maximum distance of the former from the later is bounded by a user specified constant $\epsilon$.
The optimal methods that find the minimal number of points or segments have the time complexity of $O(n^2)$ where $n$ is the number of the original points \cite{Chan:Optimal}.
They are time-consuming and impractical for large inputs~\cite{Heckbert:Survey}. Hence, many studies have been targeting at finding the sub-optimal results.
\eat{
The distinct Douglas-Peucker (\dpa) algorithm \cite{Douglas:Peucker} (see Figure~\ref{fig:notations}) is invented in 1970s, for reducing the number of points required to represent a digitized line or its caricature in the context of computer graphics and image processing.
The basic \dpa is a batch approach with a time complexity of $O(n^2)$.
%Algorithm \dpa is the foundation of many subsequent \lsa algorithms.
Some online \lsa algorithms were further developed by combining batch algorithms (\eg \dpa) with sliding/open windows \cite{Meratnia:Spatiotemporal, Liu:BQS}.
Recently, the authors of this paper developed a one-pass trajectory simplification algorithm (\operb) \cite{Lin:Operb}, which runs great fast and also has comparable compression ratio comparing with batch algorithms. Moreover, the ``cone intersection'' algorithm \cite{Williams:Longest, Sklansky:Cone, Dunham:Cone, Zhao:Sleeve} is another notable one-pass \lsa algorithm.
}
%In this section, we focus on the piece-wise line simplification based methods for trajectory data.
In particular, the state-of-the-art the sub-optimal line simplification approaches fall into three categories, \ie \emph{batch algorithms}, \emph{online algorithms} and \emph{one-pass algorithms}.

For trajectory compression, there are two types of widely used distance metrics: perpendicular Euclidean distances (\ped) and synchronous Euclidean distances (\sed).
Mostly existing line simplification algorithms use \ped, and more attentions are needed to be paid on \sed. 
\sed was first introduced in the name of \emph{time-ratio distance} in~\cite{Meratnia:Spatiotemporal}, and formally presented in~\cite{Potamias:Sampling} as the \emph{synchronous Euclidean distance}. %It is a specific distance metric for trajectory data, and is normally enabled in some batch and online algorithms.

We next introduce these line simplification  algorithms from the aspect of the three categories.

\stitle{Batch algorithms.}
The batch algorithms adopt a global distance checking policy that requires all trajectory points are loaded before compressing starts.
These batch algorithms can be either top-down or bottom-up.

Top-down algorithms, e.g., Ramer \cite{Ramer:Split} and Douglas-Peucker \cite{Douglas:Peucker}, recursively divide a trajectory into sub-trajectories until the stopping condition is met.
%
Bottom-up algorithms, e.g., Theo Pavlidis' algorithm \cite{Pavlidis:Segment}, is the natural complement of the top-down ones, which recursively merge adjacent sub-trajectories with the smallest distance, initially $n/2$  sub-trajectories for a trajectory with $n$ points, until the stopping condition is met.
%
The distances of newly generated line segments are recalculated during the process.
%
These batch algorithms originally only support \ped, but are easy to be extended to support \sed~\cite{Meratnia:Spatiotemporal}.
%
The batch nature and high time complexities make batch algorithms impractical for online scenarios and resource-constrained devices \cite{Lin:Operb}.


\stitle{Online algorithms.}
The online algorithms adopt a constrained global distance checking policy that restricts the checking within a sliding or opening window.
%, hence, they are online algorithms.
Constrained global checking algorithms do not need to have the entire trajectory ready before they start compressing, and are more appropriate than batch algorithm for compressing trajectories for online scenarios.
%Moreover, the existing constrained global checking algorithms~\cite{Keogh:online,Meratnia:Spatiotemporal,Muckell:Compression} usually use a sliding or opening window and compress sub-trajectories in the window.

Several line simplification algorithms have been developed, e.g., by combining \dpa or \pavlidis with sliding or opening windows for online processing\cite{Meratnia:Spatiotemporal}. %, Keogh:online
%\cite{Meratnia:Spatiotemporal} is a combination of Top-down and opening window while \cite{Keogh:online} is a combination of Bottom-up and sliding window.
These methods still have a high time and/or space complexity, which significantly hinders their utility in resource-constrained mobile devices \cite{Liu:BQS}.
%
\bqsa \cite{Liu:BQS} and \squishe\cite{Muckell:Compression} further optimize the opening window algorithms.
%
\bqsa \cite{Liu:BQS} fast the processing by picking out at most eight special points from an open window based on a convex hull, which, however, hardly supports  \sed.
%The time complexity of \bqsa is $O(n^2)$ in the worst case.
%it \eat{optimizes the \pavlidis by using}
The \squishe\cite{Muckell:Compression} algorithm is an combination of {opening} window and bottom-up online algorithm. It uses a doubly linked list $Q$ to achieve a better efficiency. Although \squishe supports \sed, it is not one-pass, and has a relatively poor compression ratio.

\stitle{One-pass algorithms.}
The one-pass algorithms adopt a local distance checking policy.
\eat{The local checking policy, the key to achieve the \emph{one-pass} processing, They do not need a window to buffer the preview read points.
Meanwhile, a trajectory compression algorithm is {\em one-pass} if it processes each point in a trajectory once and only once when compressing the trajectory.
}
They do not need a window to buffer the previously read points as they process each point in a trajectory once and only once.
Obviously, the one-pass algorithms run in linear time and constant space.
%

The $n$--${th}$ point routine and the routine of random-selection of points \cite{Shi:Survey} are two naive one-pass algorithms.
In these routines, for every fixed number of consecutive points along the line, the $n$--${th}$  point and one random point among them are retained, respectively.
They are fast, but are obviously not error bounded.
%
In Reumann-Witkam routine\cite{Reumann:Strip}, it builds a strip paralleling to the line connecting the first two points, then the points within this strip compose one section of the line.
The Reumann-Witkam routine also runs fast, and at the same time, it has limited compression ratios.
%
The sector intersection (\cia) algorithm \cite{Williams:Longest, Sklansky:Cone} was developed for graphic and pattern recognition in the late 1970s, for the approximation of arbitrary planar curves by linear segments or finding a polygonal approximation of a set of input data points in a 2D Cartesian coordinate system. \cite{Dunham:Cone} optimized algorithm \cia by considering the distance between a potential end point and the initial point of a line segment, and the \sleeve algorithm \cite{Zhao:Sleeve} in the cartographic discipline essentially applies the same idea as the \cia algorithm.
%
Moreover, {fast \bqsa \cite{Liu:BQS} (\fbqsa in short), the simplified version of \bqsa, has a linear time complexity.}
%
The authors of this article also developed an One-Pass ERror Bounded (\operb) algorithm \cite{Lin:Operb}.
%
It is worth pointing out that all existing one-pass algorithms\cite{Williams:Longest, Sklansky:Cone, Dunham:Cone, Zhao:Sleeve,Liu:BQS,Lin:Operb} use \ped, while this study focuses on \sed.



Semantics based trajectory compression methods are orthogonal to line simplification based methods (see~\cite{Lin:Operb} for more details), and may be combined with each other to further improve the effectiveness of trajectory compression.

\eat{%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Semantics based methods}.
The trajectories of certain moving objects such as cars and trucks are constrained by road networks. These moving objects typically travel along road networks, instead of the line segment between two points. Trajectory compression methods based on road networks \cite{Chen:Trajectory, Popa:Spatio,Civilis:Techniques,Hung:Clustering, Gotsman:Compaction, Song:PRESS}  project trajectory points onto roads (also known as Map-Matching). Moreover, \cite{Gotsman:Compaction, Song:PRESS} mines and uses high frequency patterns of compressed trajectories, instead of roads, to further improve compression effectiveness.
%
Some methods \cite{Schmid:Semantic, Richter:Semantic} compress trajectories beyond the use of road networks, which further make use
of other user specified domain knowledge, such as places of interests along the trajectories \cite{Richter:Semantic}.
%
There are also compression algorithms preserving the direction of the trajectory \cite{Long:Direction, Long:Trajectory}. %As it mentions that the trajectory of a moving object contains a large amount of semantic information that could be used to compress the trajectory. For example, the driving direction of a moving object implies the information of the next direction.

These approaches are orthogonal to line simplification based methods, and may be combined with each other to further improve the effectiveness of trajectory compression.
}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
