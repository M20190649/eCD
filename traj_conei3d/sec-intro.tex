%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-0.5ex}
\section{Introduction}
\label{sec-intro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Various mobile devices, such as smart-phones, on-board diagnostics, personal navigation devices, and wearable smart devices, have been using their sensors to collect massive trajectory data of moving objects at a certain sampling rate (e.g., a data point every $5$ seconds), which is transmitted to cloud servers for various applications such as location based services and trajectory mining.
%
Transmitting and storing raw trajectory data consumes too much network bandwidth and storage capacity \cite{Chen:Trajectory, Meratnia:Spatiotemporal, Liu:BQS, Muckell:Compression,Cao:Spatio, Popa:Spatio,Nibali:Trajic}. %Schmid:Semantic, Richter:Semantic, Long:Direction,
%Further, we find that the online transmitting of raw trajectories also seriously aggravates several other issues such as out-of-order and duplicate data points in our experiences when implementing an online vehicle-to-cloud data transmission system.
%These issues can be resolved or greatly alleviated by trajectory compression techniques via removing redundant data points of trajectories \cite{Douglas:Peucker, Hershberger:Speeding, Meratnia:Spatiotemporal, Liu:BQS, Muckell:survey, Muckell:Compression, Chen:Trajectory, Chen:Fast,Cao:Spatio, Shi:Survey, Nibali:Trajic}, % Keogh:online, Richter:Semantic, Long:Direction, Song:PRESS
%
%Trajectory compression techniques remove redundant data points of trajectories,
%, or replace original data points in a trajectory with other places of interests, such as roads and shops.
%A large number of trajectory compression techniques have been developed,
% among which the piece-wise line {simplification}  technique is widely used \cite{Douglas:Peucker, Hershberger:Speeding, Liu:BQS, Muckell:Compression, Chen:Trajectory, Chen:Fast, Cao:Spatio, Shi:Survey}, due to its distinct advantages: (a) simple and easy to implement, (b) no need of extra knowledge and suitable for freely  moving  objects \cite{Popa:Spatio}, and (c) bounded errors with good compression ratios.
%
It is known that these issues can be resolved or greatly alleviated by trajectory compression techniques via removing redundant data points of trajectories \cite{Douglas:Peucker, Hershberger:Speeding, Meratnia:Spatiotemporal, Liu:BQS, Muckell:survey, Muckell:Compression, Chen:Trajectory, Cao:Spatio, Shi:Survey, Nibali:Trajic, Long:Direction, Popa:Spatio, Han:Compress, Chen:Fast}, among which the piece-wise line simplification technique is widely used \cite{Douglas:Peucker, Meratnia:Spatiotemporal, Muckell:survey, Muckell:Compression, Chen:Trajectory, Cao:Spatio, Shi:Survey, Liu:BQS, Lin:Operb, Chen:Fast}, due to its distinct advantages: (a) simple and easy to implement, (b) no need of extra knowledge and suitable for freely  moving  objects, and (c) bounded errors with good compression ratios \cite{Popa:Spatio,Lin:Operb}.

\begin{figure*}[tb!]
\centering
%\vspace{-1ex}
\includegraphics[scale=0.76]{figures/Fig-DP.png}
%\vspace{-1ex}
\caption{\small A trajectory $\dddot{\mathcal{T}}[P_0, \ldots, P_{10}]$  with eleven points is represented by two (left) and four (right) continuous line segments (solid blue), compressed by the Douglas--Peucker algorithm \cite{Douglas:Peucker} using \ped and \sed, respectively. The Douglas--Peucker algorithm firstly creates line segment $\protect\vv{P_0P_{10}}$, then it calculates the distance of each point in the trajectory to $\protect\vv{P_{0}P_{10}}$. It finds that point $P_{4}$ has the maximum distance to $\protect\vv{P_{0}P_{10}}$, and is greater than the user defined threshold $\epsilon$. Then it goes to compress sub-trajectories $[P_0, \ldots, P_{4}]$ and $[P_{4}, \ldots, P_{10}]$, separately.
}
\vspace{-2ex}
\label{fig:notations}
\end{figure*}


Originally, line simplification (\lsa) algorithms adopt the \emph{perpendicular Euclidean distance} (\ped) as a metric to compute the errors,
\eg $|\vv{P_4P^*_4}|$ is the \ped of data point $P_4$ to the line $\overline{P_0P_{10}}$ in Figure~\ref{fig:notations} (left).
Line simplification algorithms using \ped have good compression ratios~ \cite{Douglas:Peucker, Hershberger:Speeding, Liu:BQS, Muckell:Compression, Chen:Trajectory, Cao:Spatio, Shi:Survey}.  However, when using \ped, the temporal information is lost. Thus, a spatio-temporal query, \eg ``\emph{the position of a moving object at time $t$}", on the compressed trajectories by \lsa algorithms using \ped may return an approximate point $P'$ whose distance to the actual position $P$ of the moving object at time $t$ is unbounded. %For example, a query for the position of $P_7$ at time $t_7$ may return an approximate data point $P'_7$ whose distance to $P_7$ is great than the  bound $\epsilon$ in Figure~\ref{fig:notations} (left).


\eat{, of a data point to a proposed generalized line (\eg in Figure~\ref{fig:notations} (left), $|P_4P^*_4|$ is the \ped of $P_4$ to the line $\overline{P_0P_{10}}$) as the condition to discard or retain that data point.
\lsa algorithms using \ped have good compression ratios and are error bounded on \ped, hence they are widely used in scenarios that compression ratio is the most concerned factor. However, when using \ped, the temporal information of trajectory points is lost. Thus, a temporal-spatio query, \eg ``\emph{the position $P$ of a moving object at time $t$}", on trajectories compressed by \lsa algorithms using \ped returns an approximated point $P'$ whose distance to the actual position $P$ at time $t$ is unbounded. For example, a query at time $t_7$ returns an approximated point $P'_7$ whose distance to the point $P_7$ is great than the threshold $\epsilon$.

,  and implemented it in Douglas-Peucker (\dpa) ~\cite{Douglas:Peucker} algorithm
}


The \emph{synchronous Euclidean distance} (\sed) was then introduced for trajectory compression to support the above spatio-temporal queries \cite{Meratnia:Spatiotemporal}. \sed is the Euclidean distance of a data point to its \emph{approximate temporally synchronized data point \cite{Meratnia:Spatiotemporal}} on the corresponding line segment. For instance, $P'_4$ and $P'_7$ are the \emph{synchronized data points} of points $P_4$ and $P_7$ \wrt line segments $\vv{P_0P_{10}}$ and $\vv{P_4P_{10}}$, respectively, in Figure~\ref{fig:notations} (right).
\lsa algorithms using \sed may produce more line segments. However, the use of \sed ensures that the Euclidean distance between a data point and its  synchronized point \wrt the corresponding line segment is bounded \textcolor{blue}{by an user specified parameter $\epsilon$}. Hence, the above spatio-temporal query over the trajectories compressed by \sed enabled approaches returns the synchronized point $P'$ of a data point $P$ within the bounded distance $\epsilon$.


\textcolor{blue}{No matter using \ped or \sed metric, the problem targeting at finding out the minimal number of line segments to represent the original polygonal lines \wrt an error bound $\epsilon$ is known as the ``min-\#" problem\cite{Imai:Optimal,Chan:Optimal}. For this problem, 
	%there exists the optimal \lsa algorithm using \sed whose time complexity is $O(n^3)$.
	the authors of \cite{Imai:Optimal} showed that an optimal \lsa algorithm using \ped can be found in $O(n^3)$ time, where $n$ is the number of the original points. 
	%
	Later, the authors of \cite{Chan:Optimal} proved that an optimal algorithm using \ped could be implemented in $O(n^2)$ time with the help of \textit{sector intersection} mechanism. 
	Though \cite{Chan:Optimal} did not discuss the \sed metric, it is obviously that the time complexity of the optimal \lsa algorithm using \sed currently is still $O(n^3)$ as those optimization mechanisms are \ped specific and could not work with \sed. 
	The high time complexities of the optimal \lsa algorithms using \sed make them impractical.}


\textcolor{blue}{Sub-optimal \lsa algorithms} using \sed have been developed for \textcolor{blue}{trajectory compression, including} batch algorithms (\eg Douglas-Peucker based algorithm \dpsed \cite{Meratnia:Spatiotemporal}) and online algorithms (\eg\ \squishe \cite{Muckell:Compression}).
However, these methods still have a high time and/or space complexity, which hinders their utility in resource-constrained devices. %\cite{Lin:Operb}
%
On the other hand, there are \textcolor{blue}{linear complexity \lsa algorithms using \ped} \cite{Williams:Longest, Sklansky:Cone, Dunham:Cone, Zhao:Sleeve, Lin:Operb} that are more efficient for resource-constrained devices. 
%
\textcolor{blue}{The key idea of them to achieve a linear time complexity is that they apply optimization strategies, \eg the \textit{sector intersection} mechanism in \cite{Williams:Longest, Sklansky:Cone, Dunham:Cone, Zhao:Sleeve} and the \textit{fitting function} approach in our preview work \cite {Lin:Operb}, to fast the process of simplification and save resources. 
As mentioned above, these algorithms are only applicable for \ped because the core optimization strategies they applied would not work correctly if the \ped metric is replaced by other metrics, such as \sed.} 
\textcolor{blue}{Indeed, {the developing of an efficient \lsa algorithm using \sed is more challenging than using \ped}.}
\textcolor{blue}{And, to our knowledge, there is no effective \lsa algorithm using \sed that has a linear time complexity.}





\stitle{{Contributions}}.
To this end, we propose \textcolor{blue}{ a near optimal and} two one-pass \textcolor{blue}{sub-optimal} error bounded \lsa algorithms using \sed for compressing trajectories. % in an efficient and effective way. % error bounded

\sstab {(1)} We first develop a novel local synchronous distance checking approach, \ie spatio-temporal \underline{C}one \underline{I}ntersection using the \underline{S}ynchronous \underline{E}uclidean \underline{D}istance (CISED).
%, by extending the sector intersection method \cite{Williams:Longest, Sklansky:Cone, Zhao:Sleeve}\eat{(Section~\ref{sec-localcheck})}. 
We also approximate the intersection of spatio-temporal cones with the intersection of regular polygons, and develop a fast regular polygon intersection algorithm, such that each data point in a trajectory is checked in $O(1)$ time during the entire process of trajectory simplification.

\sstab {(2)} \textcolor{blue}{We then show that an optimal trajectory simplification algorithm using \sed can achieve $O(n^2 \log n)$ time by using our local synchronous distance checking technique, and provide a \textit{near optimal} trajectory simplification algorithm \cisto that achieves $O(n^2)$ time and $O(n)$ space.}

\sstab {(3)} We next develop two one-pass \textcolor{blue}{\textit{sub-optimal}} trajectory simplification algorithms \cist and \cista, \textcolor{blue}{achieving $O(n)$ time and $O(1)$ space}, based on our local synchronous distance checking technique\eat{ (Section~\ref{sec-alg})}. 
Algorithms \cist belongs to strong simplification that only has original points in its outputs, while algorithm \cista belongs to weak simplification that allows interpolated data points in its output.


\sstab (4) Using four real-life trajectory datasets (\truck, \sercar, \geolife, \pricar),
we finally conduct an extensive experimental study\eat{ (Section~\ref{sec-exp})}, by comparing our methods \textcolor{blue}{and \cisto,} \cist and \cista  with algorithms \dps~\cite{Meratnia:Spatiotemporal} (the most effective existing \lsa algorithm using \sed) and \squishe \cite{Muckell:Compression} (the most efficient existing \lsa algorithm using \sed).

{For execution time,} algorithms \cist and \cista are on average ($14.21$, $18.19$, $17.06$, $9.98$) and ($2.84$, $3.45$, $3.69$, $2.86$) times faster than \dps and \squishe on (\sercar, \geolife, \mopsi, \pricar), respectively.
%
For compression ratios, algorithm \cisto has the best compression ratios among all strong simplification algorithms.
Algorithm \cist is better than \squishe and comparable with \dps. The sizes of
the outputs of \cist are on average ($79.5\%$, $79.5\%$, $66.0\%$, $72.7\%$),
($109.1\%$, $109.7\%$, $113.5\%$, $109.2\%$) and {($134.3\%$, $133.3\%$,
  $148.4\%$, $135.4\%$)} of \squishe, \dps and \cisto on ( \sercar, \geolife, \mopsi, \pricar), respectively. 
Moreover, algorithm \cista is comparable with \cisto and better than \squishe
and \dps  that are on average ($57.9\%$, $58.8\%$, $48.4\%$, $54.6\%$),
($79.6\%$, $81.2\%$, $83.3\%$, $82.1\%$) and {($98.1\%$, $98.7\%$, $108.9\%$,
  $101.7\%$)} of \squishe, \dps and \cisto on (\sercar, \geolife, \mopsi, \pricar), respectively.


\stitle{{Organization}}.
The remainder of the article is organized as follows.
Section \ref{sec-preliminary} introduces the basic concepts and techniques.
Section \ref{sec-localcheck} presents our local synchronous distance checking method.
Section \ref{sec-optimal} and Section \ref{sec-alg} present our near optimal trajectory simplification algorithm and one-pass trajectory simplification algorithms, respectively.
Section \ref{sec-exp} reports the experimental results, followed by related work in
Section \ref{sec-related} and conclusion in Section \ref{sec-conclusion}.
%The appendix covers additional related work and experimental results.





