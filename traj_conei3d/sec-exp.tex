%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental Study} %
\label{sec-exp}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


In this section, we present an extensive experimental study of our one-pass trajectory simplification algorithms (\cist and \cista) compared with the optimal algorithm using \sed and existing algorithms of \dps and \squishe on trajectory datasets.
%
Using four real-life trajectory datasets, we conducted sets of experiments to evaluate:
(1) the compression ratios of algorithms \cist and \cista vs. \dps, \squishe and the optimal algorithm,
(2) the average errors of algorithms \cist and \cista vs. \dps, \squishe and the optimal algorithm,
(3) the running time of algorithms \cist and \cista vs. \dps, \squishe and the optimal algorithm,
(4) the impacts of polygon intersection algorithms \rpia and \cpia and the edge number $m$ of inscribed regular polygons to the compression ratios, errors and running time of algorithms \cist and \cista,
(5) the impacts of the distance metrics \ped and \sed on the compression ratios, errors and running time of trajectory simplification algorithms, and
\textcolor{blue}{(6) the impacts of the distance metrics \ped and \sed on trajectory-based applications like spatio-temporal queries.}


\subsection{Experimental Setting}
%We first introduce the settings of our experimental study.

\stitle{Real-life Trajectory Datasets}.
We use four real-life datasets \sercar, \geolife, \mopsi and \pricar shown in Table~\ref{tab:datasets} to test our solutions.

% \ni \emph{(1) Truck trajectory data} (\truck) is the GPS trajectories collected by \eat{10,368} trucks equipped with GPS sensors in China
% during a period from Mar. 2015 to Oct. 2015. The sampling rate varied from 1s to 60s.
%Trajectories mostly have around $50$ to $90$ thousand data points.

\vspace{0.5ex}
\ni \emph{(1) Service car trajectory data} (\sercar) is the GPS trajectories collected by a Chinese car rental company during Apr. 2015 to Nov. 2015. The sampling rate was one point per $3$--$5$ seconds, and
each trajectory has around $114.1K$ points.
%.We randomly chose $1,000$ cars from them

\vspace{0.5ex}
\ni \emph{(2) GeoLife trajectory data} (\geolife) is the GPS trajectories collected in GeoLife project~\cite{Zheng:GeoLife} by 182 users in a period from Apr. 2007 to Oct. 2011. These trajectories have a variety of sampling rates, among which 91\% are logged with one point per 1-5 seconds. %or each 5-10 meters
%The longest trajectory has 2,156,994 points.

\vspace{0.5ex}
\ni \emph{(3) Mopsi trajectory data} (\mopsi) is the GPS trajectories collected in Mopsi project~\cite{Mopsi} by 51 users in a period from 2008 to 2014. Most routes are in Joensuu region, Finland.
The sampling rate was one point per $2$ seconds, and each trajectory has around $153.9K$ points.
%exist on every continent.

\vspace{0.5ex}
\ni \emph{(4) Private car trajectory data} (\pricar) is a small set GPS trajectories collected with a high sampling rate of one point per second by our team members in 2017. There are 10 trajectories and each trajectory has around 11.8K points.

%{This dataset contains 182 trajectories, one trajectory for each user, with a total distance of about 1.2 million kilometers. }

\vspace{0.5ex}
As the optimal \lsa algorithm~\cite{Imai:Optimal} has both high time and space complexities, \ie $O(n^3)$ time and $O(n^2)$ space, it is impossible to compress the entire datasets (too slow and out of memory). Hence, we further build four \textit{small datasets} such that each includes 10 middle-size ($10K$ points per trajectory) trajectories selected from \sercar, \geolife, \mopsi and \pricar, respectively.

%The details of these datasets are shown in Table~\ref{tab:dataset}.

\stitle{Algorithms and implementation}.
We implement seven \lsa algorithms, \ie our \cist and \cista,  sector intersection algorithm using \ped (\kw{SIPED})~\cite{Dunham:Cone, Zhao:Sleeve}, \kw{DPPED} and \dps (\dpa using \ped~\cite{Douglas:Peucker} and \dpa using \sed~\cite{Meratnia:Spatiotemporal}, the existing sub-optimal \lsa algorithms having the best compression ratios), \squishe~\cite{Muckell:Compression} (the fastest existing \lsa algorithm using \sed) and the optimal \lsa algorithm using \sed (see Section~\ref{subsec-optimal}).
We also implement the polygon intersection algorithms, \cpia and our \rpia.

All algorithms were implemented with Java.
All tests were run on an {x64-based  PC with 8 Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz and 8GB of memory, and each test was repeated
over 3 times and the average is reported here.

%
%\textcolor{blue}{
%In the comparation of compression ratio and average error, we selected a subset from the datasets subject to the limit of memory space and time. Concretely, we selected ($100$, $95$, $1000$, $10$) trajectories from datasets {\sercar, \geolife, \mopsi, \pricar} respectively.
%}
%\textcolor{blue}{
%As for efficiency, we use the full dataset, and exclude the optimal algorithm.
%}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experimental Results}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We next present our findings.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Evaluation of Compression Ratios}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


In the first set of tests, we evaluate the impacts of parameter $m$ on the
compression ratios of our algorithms \cist and \cista, and compare the compression ratios of \cist and \cista with \dps, \squishe and the optimal algorithm.
%
The compression ratio is defined as follows: Given a set of trajectories $\{\dddot{\mathcal{T}_1}, \ldots, \dddot{\mathcal{T}_M}\}$ and their piece-wise line representations $\{\overline{\mathcal{T}_1}, \ldots, \overline{\mathcal{T}_M}\}$, the compression ratio of an algorithm is $(\sum_{j=1}^{M} |\overline{\mathcal{T}}_j |)/(\sum_{j=1}^{M} |\dddot{\mathcal{T}}_j |)$.
By the definition, \emph{algorithms with lower compression ratios are better}.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%Compression Ratios


\begin{figure*}[tb!]
\centering
\includegraphics[scale = 0.290]{Figures/Exp-M-e-60-CR-service.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-M-e-60-CR-geolife.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-M-e-60-CR-mopsi.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-M-e-60-CR-private.png}
%\vspace{-1ex}
\caption{\small Evaluation of compression ratios: fixed error bound with $\epsilon=60$ meters and varying $m$.
Here ``R'' denotes our fast regular polygon intersection algorithm \rpia, and ``C'' denotes the convex polygon intersection algorithm \cpia, respectively.}
\label{fig:m-cr-e60}
%\vspace{-1ex}
\end{figure*}


\begin{figure*}[tb!]
\centering
\includegraphics[scale = 0.290]{Figures/Exp-CR-epsilon-service.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-CR-epsilon-geolife.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-CR-epsilon-mopsi.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-CR-epsilon-private.png}
%\vspace{-1ex}
\caption{\small Evaluation of compression ratios: fixed with $m=16$ and varying error bound $\epsilon$.}
\label{fig:cr-m16}
%\vspace{-1.0ex}
\end{figure*}



\begin{figure*}[tb!]
\centering
\includegraphics[scale = 0.290]{Figures/Exp-opt-CR-epsilon-service.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-opt-CR-epsilon-geolife.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-opt-CR-epsilon-mopsi.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-opt-CR-epsilon-private.png}
%\vspace{-1ex}
\caption{\small Evaluation of compression ratios: fixed with $m=16$ and varying error bound $\epsilon$ (on small datasets).}
\label{fig:cr-optimal-m16}
%\vspace{-1.0ex}
\end{figure*}



\begin{figure*}[tb!]
\centering
\includegraphics[scale = 0.2900]{Figures/Exp-CR-size-service.png}\hspace{1ex}
\includegraphics[scale = 0.2900]{Figures/Exp-CR-size-geolife.png}\hspace{1ex}
\includegraphics[scale = 0.2900]{Figures/Exp-CR-size-mopsi.png}\hspace{1ex}
\includegraphics[scale = 0.2900]{Figures/Exp-CR-size-private.png}
%\vspace{-1ex}
\caption{\small Evaluation of compression ratios: fixed with $m=16$ and $\epsilon=60$ meters, and varying the size of trajectories.}
\label{fig:cr-size}
\vspace{-1ex}
\end{figure*}




%\vspace{0.5ex}
\stitle{Exp-1.1: Impacts of parameter $m$ on compression ratios}.
To evaluate the impacts of the number $m$ of edges of polygons on the compression ratios of algorithms \cist and \cista, and also to confirm that our fast regular polygon intersection algorithm \rpia has the same compression ratios as the convex polygon intersection algorithm \cpia,
we fixed the error bound {$\epsilon =60$ meters}, and varied $m$ from $4$ to $40$. The results are reported in Figure~\ref{fig:m-cr-e60}.

\ni(1) Algorithms \cist and \cista using \rpia have the same compression ratios as their counterparts using \cpia for all cases.

\ni(2) When varying $m$, the compression ratios of algorithms
{\cist and \cista} decrease with the increase of $m$ on all datasets.
\textcolor{blue}{The increase of edge number $m$ of a polygon lets the polygon more closely approximate its corresponding circle, which has higher potential to have common intersections and further leads to a better compression ratio.}

%The feature is holding on all error bounds $\epsilon$.
%small error bounds, \eg $\epsilon < 60$ meters, and large error bounds, \eg $\epsilon > 60$ meters.

\ni(3) When varying $m$, the compression ratios of algorithms {\cist and \cista} decrease (a) fast when $m < 12$, (b) slowly when $m \in [12, 20]$, and (c) very slowly when $m > 20$. Hence, \emph{the region of $[12, 20]$ is a good candidate region for $m$ in terms of compression ratios.}
Here the compression ratio of $m$=$12$ is only on average {$100.95\%$} of $m$=$20$.


%\ni(1) The polygon intersection algorithms \rpia and \cpia have the same impacts on compression ratios on all datasets. \eg the compression ratio of \rpia equipped simplification algorithm \cist, \ie \cist-\rpia, is the same as the \cpia equipped simplification algorithm, \ie \cist-\cpia, for each $m$.


%\vspace{0.5ex}
\stitle{Exp-1.2: Impacts of the error bound $\epsilon$ on compression ratios (vs. algorithms \dps and \squishe)}.
To evaluate the impacts of error bound $\epsilon$ on compression ratios, we fixed {$m$=$16$}, the middle of $[12, 20]$, and varied $\epsilon$ from $10$ meters to $200$ meters on the entire four datasets, respectively.
The results are reported in Figure~\ref{fig:cr-m16} .
%Figure~\ref{fig:cr-m10}.  and


\ni (1) When increasing $\epsilon$, the compression ratios of all these algorithms decrease on all datasets.
\textcolor{blue}{It is clear a larger $\epsilon$ will include more points into a line segment and bring a better compression ratio.}
%\textcolor{blue}{More specifically, the compression ratio $cr$ of each algorithm has approximately an exponential relation to $\epsilon$, \ie $cr=a^\epsilon$, where $a$ is in $(0,1)$.}

\ni (2) Dataset \pricar has the lowest compression ratios, compared with datasets \mopsi, \sercar and \geolife, due to its highest sampling rate,
\sercar has the highest compression ratios due to its lowest sampling rate, and \geolife and \mopsi have the compression ratios in the middle accordingly.

\ni {(3)} Algorithm \cist is better than \squishe ~{and close to} \dps on all datasets and for all $\epsilon$.
%
The compression ratios of \cist are on average {($79.3\%$, $71.9\%$, $67.3\%$, $72.7\%$) and ($109.2\%$, $108.0\%$, $111.7\%$, $109.1\%$)} of \squishe and
\dps on {datasets (\sercar, \geolife, \mopsi, \pricar)}, respectively.
For example, when $\epsilon$ = $40$ meters, the compression ratios of algorithms
\squishe, \cist and \dps are
{($20.0\%$, $8.0\%$, $5.7\%$, $4.9\%$), ($16.1\%$, $5.8\%$, $3.9\%$, $3.6\%$) and ($14.8\%$, $5.4\%$, $3.4\%$, $3.4\%$)} on  {datasets (\sercar, \geolife, \mopsi, \pricar)}, respectively.
\textcolor{blue}{\cist shows better compression ratios than \squishe because \cist applies a greedy policy, \ie it includes as many points as possible into a line segment during the process, while \squishe applies a loose error prediction policy. This prediction method is not accurate enough, thus, in order to ensure the error bound, it may ignore too many potential points that could be represented by a line segment.}

%\textcolor{blue}{\cist shows better compression ratios than \squishe because \cist applies a greedy policy, \ie it includes as many points as possible into a line segment, while \squishe applies a loose distancce checking policy, \ie it estimates the lowest \sed error and removes the point ``predicted to introduce the lowest amount of error into the compression\cite{Muckell:Compression}" . Its prediction method is not accurate enough, thus, in order to ensure the error bound, it may ignore too many potential points that could be represented by a line segment.}

\ni {(4)} Algorithm \cista has better compression ratios than \dps, \squishe and \cist on all datasets and for all $\epsilon$.
The compression ratios of \cista are on average ($57.7\%$, $53.8\%$, $50.0\%$, $54.6\%$), ($79.5\%$, $81.0\%$, $83.0\%$, $82.0\%$) and {($72.9\%$, $75.0\%$, $74.3\%$, $75.1\%$) of algorithms
\squishe, \dps and \cist on {datasets (\sercar, \geolife, \mopsi, \pricar)}, respectively.
For example, when $\epsilon$ = $40$ meters, the compression ratios of algorithm
\cista are ($11.5\%$, $4.3\%$, $2.8\%$, $2.7\%$) on datasets (\sercar, \geolife, \mopsi, \pricar), respectively.
%
\textcolor{blue}{Algorithm CISED-W extends the radii of base circles of spatio-temporal cones from $\epsilon/2$ in CISED-S to $\epsilon$, thus, it has better compression ratios than \cist.}

%\vspace{0.5ex}
\stitle{Exp-1.3: Impacts of the error bound $\epsilon$ on compression ratios (vs. the optimal algorithm).}
To evaluate the impacts of error bound $\epsilon$ on compression ratios, we again fixed {$m$=$16$}, the middle of $[12, 20]$, and varied $\epsilon$ from $10$ to $200$ meters on the first $1K$ points of each trajectory of the selected \textit{small datasets}, respectively.
The results are reported in Figure~\ref{fig:cr-optimal-m16} .
%Figure~\ref{fig:cr-m10}.  and

\ni {(1)} Algorithm \cist is worse than the optimal algorithm on all datasets and for all $\epsilon$.
More specifically, the compression ratios of \cist are on average ($134.6\%$, $150.7\%$, $155.5\%$, $138.5\%$) of the optimal algorithm on {datasets (\sercar, \geolife, \mopsi, \pricar)}, respectively.
For example, when $\epsilon$ = $40$ meters, the compression ratios of \cist and the optimal algorithm are
($22.0\%$, $5.9\%$, $1.9\%$, $3.3\%$) and {($16.4\%$, $4.2\%$, $0.9\%$, $2.4\%$)}
on  {datasets (\sercar, \geolife, \mopsi, \pricar)}, respectively.

\ni {(2)} Algorithm \cista~has the closest compression ratios to the optimal algorithm on all datasets and for all $\epsilon$.
The compression ratios of \cista are on average  ($94.8\%$, $115.5\%$, $119.7\%$, $107.5\%$)} of the optimal algorithm on {datasets (\sercar, \geolife, \mopsi, \pricar)}, respectively.
For example, when $\epsilon$ = $40$ meters, the compression ratios of algorithm
\cista are ($14.6\%$, $4.6\%$, $1.2\%$, $2.5\%$) on datasets (\sercar, \geolife, \mopsi, \pricar), respectively.
%
{ This is because algorithm CISED-W allows data interpolations, by Proposition \ref{prop-circle-intersection}, it extends the radii of the base circles of the spatio-temporal cones from $\epsilon/2$ in CISED-S to $\epsilon$ in CISED-W to contain more points.}

\stitle{Exp-1.4: Impacts of trajectory sizes on compression ratios}.
To evaluate the impacts of trajectory size, \ie the number of data points in a trajectory, on compression ratios,
we chose the same {$10$} trajectories from datasets \sercar, \geolife, \mopsi and \pricar, respectively,
fixed {$m$=$16$} and $\epsilon$=$60$ meters, and varied the size \trajec{|T|} of trajectories from $1K$ points to $10K$ points.
%
The results are reported in Figure~\ref{fig:cr-size}.

\ni(1) The compression ratios of these algorithms ordered from the best to the worst are \cista, \dps, \cist and \squishe, on all datasets with all sizes of trajectories, \textcolor{blue}{which is consistent with the above tests}.

\ni(2) The sizes of input trajectories have few impacts on the compression ratios of \lsa algorithms on all datasets.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Evaluation of Average Errors}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Average error
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure*}[tb!]
	\centering
	\includegraphics[scale = 0.2900]{Figures/Exp-M-e-60-error-service.png}\hspace{1ex}
	\includegraphics[scale = 0.2900]{Figures/Exp-M-e-60-error-geolife.png}\hspace{1ex}
	\includegraphics[scale = 0.2900]{Figures/Exp-M-e-60-error-mopsi.png}\hspace{1ex}
	\includegraphics[scale = 0.2900]{Figures/Exp-M-e-60-error-private.png}
	%\vspace{-1ex}
	\caption{\small Evaluation of average errors: fixed error bound with $\epsilon = 60$ meters and varying $m$.
Here ``R'' denotes our fast regular polygon intersection algorithm \rpia, and ``C'' denotes \cpia, respectively.}
	\label{fig:m-error-e60}
	%\vspace{-1ex}
\end{figure*}


\begin{figure*}[tb]
	\centering
	\includegraphics[scale = 0.2900]{Figures/Exp-error-epsilon-service.png}\hspace{1ex}
	\includegraphics[scale = 0.2900]{Figures/Exp-error-epsilon-geolife.png}\hspace{1ex}
	\includegraphics[scale = 0.2900]{Figures/Exp-error-epsilon-mopsi.png}\hspace{1ex}
	\includegraphics[scale = 0.2900]{Figures/Exp-error-epsilon-private.png}
	%\vspace{-1ex}
	\caption{\small Evaluation of average errors: fixed with $m=16$ and varying error bound $\epsilon$.}
	\label{fig:ae-m16}
	%\vspace{-1ex}
\end{figure*}





\begin{figure*}[tb]
	\centering
	\includegraphics[scale = 0.2900]{Figures/Exp-opt-error-epsilon-service.png}\hspace{1ex}
	\includegraphics[scale = 0.2900]{Figures/Exp-opt-error-epsilon-geolife.png}\hspace{1ex}
	\includegraphics[scale = 0.2900]{Figures/Exp-opt-error-epsilon-mopsi.png}\hspace{1ex}
	\includegraphics[scale = 0.2900]{Figures/Exp-opt-error-epsilon-private.png}
	%\vspace{-1ex}
	\caption{\small Evaluation of average errors: fixed with $m=16$ and varying error bound $\epsilon$ (on small datasets).}
	\label{fig:ae-optimal-m16}
	%\vspace{-1ex}
\end{figure*}




\begin{figure*}[tb!]
	\centering
	\includegraphics[scale = 0.2900]{Figures/Exp-error-size-service.png}\hspace{1ex}
	\includegraphics[scale = 0.2900]{Figures/Exp-error-size-geolife.png}\hspace{1ex}
	\includegraphics[scale = 0.2900]{Figures/Exp-error-size-mopsi.png}\hspace{1ex}
	\includegraphics[scale = 0.2900]{Figures/Exp-error-size-private.png}
	%\vspace{-1ex}
	\caption{\small Evaluation of average errors: fixed with $m=16$ and $\epsilon=60$ meters, and varying the size of trajectories.}
	\label{fig:ae-size}
	%\vspace{-1ex}
\end{figure*}


In the second set of tests, we first evaluate the impacts of parameter $m$ on the average errors of algorithms \cist and \cista, then compare the average errors of our algorithms \cist and \cista with \dps, \squishe and the optimal algorithm.

Given a set of trajectories $\{\dddot{\mathcal{T}_1}, \ldots, \dddot{\mathcal{T}}_M\}$ and their piecewise line representations $\{\overline{\mathcal{T}_1}, \ldots, \overline{\mathcal{T}}_M\}$, and point $P_{j,i}$ denoting
a point in trajectory $\dddot{\mathcal{T}}_j$ contained in a line segment $\mathcal{L}_{l,i}\in\overline{\mathcal{T}_l}$ ($l\in[1,M]$),
then the average error is $\sum_{j=1}^{M}\sum_{i=0}^{M} d(P_{j,i},
\mathcal{L}_{l,i})/\sum_{j=1}^{M}{|\dddot{\mathcal{T}}_j |}$.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{0.5ex}
\stitle{Exp-2.1: Impacts of parameter $m$ on average errors}.
To evaluate the impacts of parameter $m$ on average errors of algorithms \cist and \cista, and to confirm that our fast regular polygon intersection algorithm \rpia has the same average errors as the convex polygon intersection algorithm \cpia,
we fixed the error bound {$\epsilon =60$ meters}, and varied $m$ from $4$ to $40$. The results are reported in Figure~\ref{fig:m-error-e60}.


%\ni(1) The polygon intersection algorithms \rpia and \cpia have the same impacts on average errors on all datasets. \eg the average error of \rpia equipped simplification algorithm \cist, \ie \cist-\rpia, is the same as the \cpia equipped algorithm, \ie \cist-\cpia, for each $m$.

\ni(1) Algorithms \cist and \cista using \rpia have the same average errors as their counterparts using \cpia, respectively, on all datasets and for all $m$.

\ni(2) When varying $m$, the average errors of algorithms \cist and \cista increase with the increase of $m$ on all datasets.
\textcolor{blue}{The increase of edge number $m$ of a polygon lets the polygon more closely approximate its corresponding circle, which means that some points having larger \sed, \ie closer to half-$\epsilon$ in \cist or $\epsilon$ in \cista, are also included to a line segment, which further leads to a larger average error.}

\ni(3) When varying $m$, similar to compression ratios, the average errors of
algorithms \cist and \cista increase (a) fast when $m < 12$, (b) slowly when $m
\in [12, 20]$, and (c) very slowly when $m > 20$.
\emph{The range of $[12, 20]$ is also the good candidate region for $m$ in terms of errors.}
Here the average error of $m=12$ is only on average {$98.49\%$} of $m=20$.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{0.5ex}
\stitle{Exp-2.2: Impacts of the error bound $\epsilon$ on average errors (vs. algorithms \dps and \squishe)}.
To evaluate the average errors of these algorithms, we fixed {$m$=$16$}, and
varied $\epsilon$ from $10$ to $200$ meters on the entire
{datasets} \sercar, \geolife, \mopsi and \pricar, respectively.
The results are reported in Figure~\ref{fig:ae-m16}.

\ni(1) Average errors increase with the increase of $\epsilon$.
\textcolor{blue}{More specifically, the average error of each algorithm has approximately a linear relation to $\epsilon$.}
\textcolor{blue}{It is clear a larger $\epsilon$ will include more points into a line segment, including points with larger \sed, which brings a better compression ratio as well as a larger average error.}

\ni(2) The average errors of these algorithms from the largest to the smallest are \cista, \cist, \dps and \squishe, on all datasets and for all $\epsilon$.
The average errors of algorithms \cist and \cista are on average
($119.3\%$, $127.7\%$, $119.9\%$, $138.0\%$)
and ($210.1\%$, $207.5\%$, $200.9\%$, $217.5\%$)
of \dps and ($188.2\%$, $215.2\%$, $212.8\%$, $180.3\%$) and
($331.1\%$, $349.7\%$, $356.7\%$, $284.2\%$)
 of \squishe on datasets (\sercar, \geolife, \mopsi, \pricar), respectively.
\textcolor{blue}{Algorithms \cista and \cist apply a greedy policy, \ie, they include as more points as possible into a line segment, this policy would usually lead to a larger average error.}

\ni(3) When the error bound of algorithm \cista is set as the half of \cist, the
average errors of \cista are on average ($93.8\%$, $86.0\%$, $81.4\%$, {$79.4\%$}) of \cist on {datasets} (\sercar, \geolife,\mopsi, \pricar), respectively, meaning that the large average errors of algorithm \cista are caused by its cone \wrt $\epsilon$ compared with the narrow cone \wrt $\epsilon/2$ of \cist.
%\ni(2) All datasets have the similar average error in every $\epsilon$.
%\ni(3) Algorithm \squishe has lower average errors than algorithms \dps and \cist on all datasets and all $\epsilon$ values.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{0.5ex}
\stitle{Exp-2.3: Impacts of the error bound $\epsilon$ on average errors (vs. the optimal algorithm).}
To evaluate the average errors of these algorithms, we fixed {$m$=$16$}, and
varied $\epsilon$ from $10$ to $200$ meters on the first $1K$ points of each trajectory of the selected \textit{small datasets}, respectively.
The results are reported in Figure~\ref{fig:ae-optimal-m16}.

The average errors of these algorithms from the largest to the smallest are \cista, the optimal algorithm and \cist, on all datasets and for all $\epsilon$.
The average errors of \cist and \cista are on average
($73.6\%$, $80.7\%$, $85.1\%$, $81.0\%$)
and ($133.3\%$, $130.7\%$, $131.0\%$, $126.3\%$)
of the optimal algorithm on datasets (\sercar, \geolife, \mopsi, \pricar), respectively.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{0.5ex}
\stitle{Exp-2.4: Impacts of trajectory sizes on average errors}.
To evaluate the impacts of trajectory sizes on average errors, we chose the same
{$10$} trajectories from  datasets \sercar, \geolife, \mopsi and \pricar, respectively.
We fixed {$m$=$16$} and $\epsilon = 60$ meters, and varied the size \trajec{|T|} of trajectories from $1K$ points to $10K$ points.
%
The results are reported in Figure~\ref{fig:ae-size}.

\ni(1) The average errors of these algorithms ordered from the smallest to the largest are \squishe, \dps, \cist and \cista, on all datasets and for all trajectory sizes,
\textcolor{blue}{which is consistent with the above tests.}
 %, which is consistent with Figure~\ref{fig:ae-m16}.

\ni(2) The sizes of input trajectories have few impacts on the average errors of \lsa algorithms on all datasets.



	





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Evaluation of Running Time}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In the third set of tests, we evaluate the impacts of parameter $m$ on the running time of algorithms \cist and \cista, and compare the running time of our approaches \cist and \cista with the optimal algorithm and algorithms \dps and \squishe.

%\ie the edge number of a regular polygon,
%
%The execution time is the running time of the compressing process.
%For a small size trajectory, we repeat compress it tens of times and accumulation the total running time so as to get the average compression time.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{0.5ex}
\stitle{Exp-3.1: Impacts of algorithm \rpia and parameter $m$ on running time.}
To evaluate the impacts of parameter $m$ on the running time of algorithm \cist and \cista,
 and also to confirm that our fast regular polygon intersection algorithm \rpia runs faster than the convex polygon intersection algorithm \cpia,
we equipped \cist and \cista with \rpia and \cpia, respectively, fixed $\epsilon =60$ meters, and varied $m$ from $4$ to $40$.
%
The results are reported in Figures~\ref{fig:m-poly-time} and~\ref{fig:m-time-e60}.

\ni(1) Algorithms \cist and \cista spend most their time on executing the
polygon intersections. For all $m$, the execution time of algorithms \cpia and
\rpia is on average {($93.5\%$, $96.0\%$, $94.5\%$, $92.0\%$)
	and ($90.5\%$, $92.5\%$, $91.0\%$, $90.5\%$)} of the entire compression  time on {datasets}
(\sercar, \geolife, \mopsi, \pricar), respectively.

\ni(2) \rpia runs faster than \cpia on all datasets and for all $m$ \textcolor{blue}{due to the techniques it applied to speed up
the computation of polygon intersection}. The execution time of algorithms \cist-\rpia and \cista-\rpia is one average $83.74\%$ their counterparts with \cpia.

\ni(3) When varying $m$, the execution time of algorithms \cist-\rpia, \cist-\cpia, \cista-\rpia and \cista-\cpia increases approximately linearly with the increase of $m$ on all the datasets, \textcolor{blue}{\eg the running time of $m=12$ is on average $69.92\%$ of $m=20$ for \cist and \cista on all datasets. This is because the time complexities of \rpia and \cpia are both $O(m)$, and a larger $m$ leads to more comparisons of edges during the computation of  polygon intersection.}

%\ni(4) The running time of $m=12$ is on average $69.92\%$ of $m=20$ for \cist and \cista on all datasets.

%\ni(6) The execution time of regular polygon intersection algorithm \rpia is average \textcolor[rgb]{1.00,0.00,0.00}{$20\%$ }less than convex polygon intersection algorithm \cpia on all the datasets and parameter $m$.


%%%%%%%%%%%%%%%%%%%% Time %%%%%%%%%%%%%%%%%%

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale = 0.290]{Figures/Exp-M-poly-time-ratio-service.png}\hspace{1ex}
	\includegraphics[scale = 0.290]{Figures/Exp-M-poly-time-ratio-geolife.png}\hspace{1ex}
	\includegraphics[scale = 0.290]{Figures/Exp-M-poly-time-ratio-mopsi.png}\hspace{1ex}
	\includegraphics[scale = 0.290]{Figures/Exp-M-poly-time-ratio-private.png}
%	\vspace{-1ex}
	\caption{\small Evaluation of running time of polygon intersection algorithms: fixed error bound with $\epsilon=60$ meters, and varying $m$. Here ``R'' denotes our fast regular polygon intersection algorithm \rpia, and ``C'' denotes \cpia, respectively.}
	\label{fig:m-poly-time}
	%\vspace{-1ex}
\end{figure*}


\begin{figure*}[tb!]
	\centering
	\includegraphics[scale = 0.290]{Figures/Exp-M-e-60-time-service.png}\hspace{1ex}
	\includegraphics[scale = 0.290]{Figures/Exp-M-e-60-time-geolife.png}\hspace{1ex}
	\includegraphics[scale = 0.290]{Figures/Exp-M-e-60-time-mopsi.png}\hspace{1ex}
	\includegraphics[scale = 0.290]{Figures/Exp-M-e-60-time-private.png}
%	\vspace{-1ex}
	\caption{\small Evaluation of running time: fixed error bound with $\epsilon=60$ meters, and varying $m$. }
	\label{fig:m-time-e60}
	%\vspace{-1ex}
\end{figure*}





\begin{figure*}[tb!]
\centering
\includegraphics[scale = 0.290]{Figures/Exp-time-epsilon-service.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-time-epsilon-geolife.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-time-epsilon-mopsi.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-time-epsilon-private.png}
%\vspace{-1ex}
\caption{\small Evaluation of running time: fixed with $m=16$ and varying error bounds $\epsilon$.}
\label{fig:time-epsilon}
%\vspace{-1ex}
\end{figure*}





\begin{figure*}[tb!]
\centering
\includegraphics[scale = 0.290]{Figures/Exp-opt-time-epsilon-service.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-opt-time-epsilon-geolife.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-opt-time-epsilon-mopsi.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-opt-time-epsilon-private.png}
%\vspace{-1ex}
\caption{\small Evaluation of running time: fixed with $m=16$ and varying error bounds $\epsilon$ (on small datasets).}
\label{fig:time-optimal-epsilon}
\vspace{-1ex}
\end{figure*}




\begin{figure*}[tb!]
\centering
\includegraphics[scale = 0.290]{Figures/Exp-time-size-service.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-time-size-geolife.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-time-size-mopsi.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-time-size-private.png}
%\vspace{-1ex}
\caption{\small Evaluation of running time: fixed with $m=16$ and $\epsilon=60$ meters, and varying the size of trajectories. }
\label{fig:time-size}
\vspace{-1ex}
\end{figure*}







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{0.5ex}
\stitle{{Exp-3.2}:  Impacts of the error bound $\epsilon$ on running time (VS. algorithms \dps and \squishe).}
To evaluate the impacts of $\epsilon$ on running time, we fixed $m$ = $16$,
and varied $\epsilon$  from $10$ meters to $200$ meters on the entire
datasets, respectively.
The results are reported in Figure~\ref{fig:time-epsilon}.

\ni(1) All algorithms are not very sensitive to $\epsilon$ on any datasets, and algorithm \dps is more sensitive to $\epsilon$ than the other three algorithms.
The running time of \dps decreases a little bit with the increase of $\epsilon$, as the increment of $\epsilon$ decreases the number of partitions of the input trajectory.


\ni(2) Algorithms \cist and \cista are obviously faster than \dps and \squishe for all cases.
They are on average ($14.21$, $18.19$, $17.06$, $9.98$) times faster than \dps,
and ($2.84$, $3.45$, $3.69$, $2.86$) times faster than \squishe on
{datasets} (\sercar, \geolife, \mopsi, \pricar), respectively.
\textcolor{blue}{This is consistent with their time complexity analyses.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{0.5ex}
\stitle{Exp-3.3: Impacts of the error bound $\epsilon$ on running time (VS. the optimal algorithm).}
To evaluate the impacts of $\epsilon$ on running time, we fixed $m$ = $16$,
and varied $\epsilon$ from $10$ to $200$ meters on the first $1K$ points of each trajectory of the selected \textit{small datasets}, respectively.
The results are reported in Figure~\ref{fig:time-optimal-epsilon}.

\ni(1) Algorithms \cist and \cista are obviously faster than the optimal algorithm for all cases.
They are on average ($925.25$, $7888.26$, $40041.59$, $8528.76$) times faster than the optimal algorithm on
datasets (\sercar, \geolife, \mopsi, \pricar), respectively.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{0.5ex}
\stitle{{Exp-3.4}: Impacts of trajectory sizes on running time}.
To evaluate the impacts of trajectory sizes on running time,
we chose the same {$10$} trajectories, from datasets (\sercar, \geolife, \mopsi, \pricar), respectively,
fixed $m$ = $16$ and $\epsilon = 60$ meters, and varied the size \trajec{|T|} of trajectories from $1K$ points to $10K$ points.
%
The results are reported in Figure~\ref{fig:time-size}.

%\ni(1) \textcolor{blue}{Algorithm \cisto is the slowest \sed enabled \lsa algorithms,
%and is {($2.17$--$3.30$, $11.02$--$18.83$, $29.55$--$109.98$, $13.47$--$22.18$)} times slower than \dps, on the selected $1K$ to $10K$ points datasets (\sercar,\geolife, \mopsi, \pricar), respectively.}

\ni(1) Algorithms \cist and \cista are both the fastest \lsa algorithms using \sed,
and are {($8.00$--$10.00$, $5.83$--$8.11$, $4.00$--$9.50$, $5.00$--$8.09$) times faster than \dps,
	and {($2.53$--$3.00$, $2.62$--$3.12$, $2.50$--$3.33$, $2.89$--$3.40$)}} times faster than \squishe on the selected $1K$ to $10K$ points datasets (\sercar,
\geolife, \mopsi, \pricar), respectively.

\ni(2) Algorithms \cist and \cista scale well with the increase of the size of trajectories on all datasets,
and both have a linear running time, while algorithm \dps does not.
This is consistent with their time complexity analyses.

\ni(3) The advantage of running time of algorithms \cist and \cista increases with the increase of trajectory sizes compared with \dps and \squishe.



\subsubsection{Evaluation of Distance Metrics \ped vs. \sed}


\begin{figure*}[tb!]
\centering
\includegraphics[scale = 0.290]{Figures/Exp-CR-epsilon-ped-service.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-CR-epsilon-ped-geolife.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-CR-epsilon-ped-mopsi.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-CR-epsilon-ped-private.png}
%\vspace{-1ex}
\caption{\small Evaluation of compression ratios (\ped vs. \sed): fixed with $m=16$ and varying
  error bound $\epsilon$.}
\label{fig:cr-ped}
%\vspace{-1.0ex}
\end{figure*}

\begin{figure*}[tb]
	\centering
	\includegraphics[scale = 0.2900]{Figures/Exp-error-epsilon-ped-service.png}\hspace{1ex}
	\includegraphics[scale = 0.2900]{Figures/Exp-error-epsilon-ped-geolife.png}\hspace{1ex}
	\includegraphics[scale = 0.2900]{Figures/Exp-error-epsilon-ped-mopsi.png}\hspace{1ex}
	\includegraphics[scale = 0.2900]{Figures/Exp-error-epsilon-ped-private.png}
	%\vspace{-1ex}
	\caption{\small Evaluation of average errors (\ped vs. \sed): fixed with $m=16$ and varying
    error bound $\epsilon$ .}
	\label{fig:ae-ped}
	%\vspace{-1ex}
\end{figure*}


\begin{figure*}[tb!]
\centering
\includegraphics[scale = 0.290]{Figures/Exp-time-epsilon-ped-service.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-time-epsilon-ped-geolife.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-time-epsilon-ped-mopsi.png}\hspace{1ex}
\includegraphics[scale = 0.290]{Figures/Exp-time-epsilon-ped-private.png}
%\vspace{-1ex}
\caption{\small Evaluation of running time (\ped vs. \sed): fixed with $m=16$ and varying error
  bounds $\epsilon$.}
\label{fig:time-ped}
\vspace{-1ex}
\end{figure*}


In this set of tests, we compare the performance of algorithms using \ped vs. \sed. Two pairs of algorithms are tested, namely, (1) the algorithm \dpa using \ped and \sed, respectively, and (2) the sector intersection  algorithm \cite{Williams:Longest, Sklansky:Cone} using \ped and our spatio-temporal cone intersection algorithm using \sed.

\stitle{Exp-4.1: Impacts of distance metrics on compression ratios}.
To evaluate the impacts of distance metrics, \ie \ped and \sed, on compression ratios, we fixed {$m$=$16$} and varied $\epsilon$ from $10$ meters to $200$ meters on the entire four datasets, respectively.
The results are reported in Figure~\ref{fig:cr-ped}.


Given the same error bound $\epsilon$, the compression ratios using \ped are obviously better
than using \sed.
More specifically, the compression ratios of algorithm \dpa
using \ped are on average ($47.1\%$, $55.5\%$, $60.7\%$, $44.7\%$) of algorithm \dpa using \sed and
the compression ratios of algorithm \cist are on average
($45.4\%$, $54.5\%$, $60.1\%$, $43.0\%$) of algorithm \kw{SIPED} on datasets (\sercar, \geolife, \mopsi, \pricar), respectively.
\textcolor{blue}{
The reason behind this is that a \ped of a point is the shortest
distance from the point to a line segment while a \sed of a point is the distance between the point and its synchronized data point \wrt the line segment, thus, the \sed of a point to a line segment is always not less than the \ped of the point to the line segment. Hence, given the same error bound $\epsilon$, \lsa algorithms using \sed usually include fewer points into a line segment, in other words, they output more line segments.}

\stitle{Exp-4.2: Impacts of distance metrics on average errors}.
To evaluate the impacts of distance metrics on average errors, we fixed {$m$=$16$} and varied $\epsilon$ from $10$ to $200$ meters on the entire four datasets, respectively.
The results are reported in Figure~\ref{fig:ae-ped}.


Given the same error bound $\epsilon$, the average errors of algorithms using \sed are a bit larger than using \ped.
The average errors of algorithm \dpa using \ped are on average
($76.7\%$, $77.6\%$, $79.7\%$, $63.0\%$) of algorithm \dpa  using \sed, and  the average
errors of algorithm \kw{SIPED}  are on average
($97.5\%$, $78.1\%$, $92.4\%$, $74.2\%$) of algorithm \cist on (\sercar, \geolife, \mopsi, \pricar), respectively.
\textcolor{blue}{As we know the \ped error is originally caused by the direction changes of a moving object while the
\sed error is caused by the changes of both the direction and the speed of a moving object. It seems the speed factor introduces an extra error and leads to a larger average error. }


\stitle{Exp-4.3: Impacts of distance metrics on running time}.
To evaluate the impacts of distance metrics on running time, we also fixed {$m$=$16$} and varied $\epsilon$ from $10$ to $200$ meters on the entire four datasets, respectively.
The results are reported in Figure~\ref{fig:time-ped}.

Given the same error bound $\epsilon$, the running time of \dpa  using \ped is on average
($24.3\%$, $119.9\%$, $23.4\%$, $91.3\%$) of \dpa  using \sed.
\textcolor{blue}{Algorithm \dpa using \ped runs faster than using \sed because \dpa using \ped has a better compression ratio than \sed, which is the result of a fewer trajectory splitting and distance computing operations during the compression.}
%
The running time of algorithm \kw{SIPED} is on average ($7.0\%$, $36.3\%$, $19.9\%$, $69.2\%$)
of algorithm \cist on datasets (\sercar, \geolife, \mopsi, \pricar), respectively.
\textcolor{blue}{Algorithm \cist runs slower than \kw{SIPED} partially because
finding the common intersection of spatial-temporal cones is a heavier work than sectors.
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{\textcolor{blue}{Evaluation of Spatio-Temporal Queries on Compressed Trajectories}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textcolor{blue}{We finally evaluate compressed trajectories from the view of trajectory application, \ie spatio-temporal query. The well-known spatio-temporal queries are \emph{where\_at, when\_at, range, nearest\_neighbor and spatial\_join} \cite{Cao:Spatio}. Among them, \emph{where\_at} and \emph{when\_at} are fundamental and easy to implement.}
\textcolor{blue}{Hence, for convenience and without losing generality, we choose \emph{where\_at} query, \ie ``\emph{the position $P$ of a moving object at time $t$}", to evaluate compressed trajectories simplified by \lsa algorithms using \ped and/or \sed.
As mentioned in \cite{Cao:Spatio}, the answer to \emph{where\_at} query is the expected position $P'$ of the moving object at time $t$. Indeed, it is the synchronized point of $P$ when the query is performed on simplified trajectories.}

\textcolor{blue}{In this set of tests, we first compress these trajectories using both \ped and \sed. When compressing, we also fixed {$m$=$16$} for \cista and varied $\epsilon$ from $10$ to $200$ meters for all algorithms on the entire four datasets, respectively.}
\textcolor{blue}{Then, for each point $P$ in an original trajectory $\dddot{\mathcal{T}}$, we perform a query on each of its compressed trajectories taking its time $P.t$ as input, and calculate the distance between the actual position $P$ and the expected position $P'$ to denote the error of query.
}
%
\textcolor{blue}{The max and average errors of the queries are reported in Table~\ref{tab:query-me} and Figure~\ref{fig:query-ae}, respectively.}

\begin{figure*}[tb!]
\centering
\includegraphics[scale = 0.295]{Figures/Exp-query-ae-epsilon-service.png}\hspace{1ex}
\includegraphics[scale = 0.295]{Figures/Exp-query-ae-epsilon-geolife.png}\hspace{1ex}
\includegraphics[scale = 0.295]{Figures/Exp-query-ae-epsilon-mopsi.png}\hspace{1ex}
\includegraphics[scale = 0.295]{Figures/Exp-query-ae-epsilon-private.png}
%\vspace{-1ex}
\caption{\small Average errors of spatio-temporal queries: fixed with $m=16$ and varying error bound $\epsilon$.}
\label{fig:query-ae}
%\vspace{-1.0ex}
\end{figure*}


\ni \textcolor{blue}{(1) When using \sed, the max errors of spatio-temporal queries on compressed trajectories are always not larger than error bounds. However, when using \ped, they are more than $10^6$ metres in datasets \sercar, \geolife and \mopsi, and more than $10^3$ metres in dataset \pricar, significantly larger than error bounds. Although they are large, they are actually possible. For example, someone traveled from Beijing of China to Sydney of Australia. During the trip, he first closed his mobile when the air plane was ready to take off, then he turned on his mobile after he arrived at a hotel in Sydney, and went to sleep for hours in the hotel. Because the sub-trajectory from his taking off to his waking up includes data points located in two small regions, \ie the location he took off and the hotel he lived in, it is possible that the sub-trajectory is compressed by some \lsa algorithm using \ped to only one line segment, even the error bound $\epsilon$ is set to just $60$ metres. Thus, when a spatio-temporal query runs on the simplified sub-trajectory taking as input the time he arrived at the hotel, it returns the synchronized point between Beijing and Sydney, having a distance significantly larger than error bound to the actual position, \ie the hotel.}
%
\textcolor{blue}{Besides, we also found that the data quality problem of the original trajectory, such as an abnormal change of GPS location or time, \eg the latitude and longitude of a moving object suddenly change from one country to another country, or even somewhere in the ocean, can aggravate the large error phenomenon of spatio-temporal queries on compressed trajectories that are simplified using \ped. These confirm that \sed is more suitable than \ped for spatio-temporal queries.} %, as illustrated in Section~\ref{sec-intro}



\begin{table}[bt!]
	%\renewcommand{\arraystretch}{1.2}
	\vspace{-1ex}
	\caption{\small The max errors of spatio-temporal queries on compressed trajectories: fixed with $m=16$ and $\epsilon=60$ metres.}
	\centering
	\scriptsize
	\begin{tabular}{|l|c|c|c|c|}
		\hline
		\bf{Alg.}&\sercar &\geolife &\mopsi &\pricar \\
		\hline
		\kw{SIPED}	&$4.81 \times 10^6$	    	&$1.91 \times 10^6$	    &$1.40 \times 10^6$     &$9.45 \times 10^3$\\
		\hline
        \kw{DPPED}	&$4.27 \times 10^6$	    &$1.03 \times 10^6$	    &$4.21 \times 10^6$   &$2.24 \times 10^3$\\
		\hline
		\dps  &59.99	    &59.99	    &59.99   &59.99\\
		\hline
		\cist	&59.99	    &59.99	        &59.99      &59.99 \\
		\hline
		\cista	&59.98	    &59.99	        &59.99      &59.95 \\
		\hline
		\squishe &59.99	    &59.98	        &59.99      &59.99 \\
		\hline
	\end{tabular}
	\label{tab:query-me}
	\vspace{-2ex}
\end{table}


\ni \textcolor{blue}{(2) Given the same error bound, the average errors of these queries on compressed trajectories using \ped are obvious larger than those using \sed, and they are usually larger than error bounds. Moreover, algorithm \cia using \ped has larger spatio-temporal query errors than \dpa using \ped because \cia applies a greedy policy that tries to include more points into a line segment, and some of these ``extra-points" lead to large errors.}
% due to some points having extraordinary large errors



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Summary and Discussion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\stitle{Summary}. From these tests we find the following.

\sstab \emph{(1) Datasets}. The behaviors of all algorithms across all datasets are quite similar.

\sstab \emph{(2) Polygon intersection algorithms}. Algorithm \rpia runs faster than  algorithm \cpia, and has the same compression ratios and average errors as \cpia.

\sstab\emph{(3) Parameter $m$}. The compression ratio decreases with the increase of $m$, and the running time increases nearly linearly with the increase of $m$. In practice, the range of $[12, 20]$ is a good candidate region for $m$.

\sstab\emph{(4) Compression ratios}. The optimal \lsa algorithm has the best compression ratios among all strong simplification algorithms. Algorithm \cist is close to \dps and algorithm \cista is better than all the sub-optimal \lsa algorithms.
%They are all better than \squishe.
The compression ratios of algorithm \cist, the optimal algorithm and algorithm \cista are on average
($79.3\%$, $71.9\%$, $67.3\%$, $72.7\%$),
{($58.1\%$, $45.1\%$, $39.2\%$, $52.8\%$)} and ($57.7\%$, $53.8\%$, $50.0\%$, $54.6\%$) of \squishe
and ($109.2\%$, $108.0\%$, $111.7\%$, $109.1\%$), {($81.3\%$, $75.5\%$, $72.5\%$, $78.1\%$)} and ($79.5\%$, $81.0\%$, $83.0\%$, $82.0\%$) of \dps on {datasets} (\sercar, \geolife, \mopsi, \pricar), respectively.

\sstab\emph{(5) Average errors}. The average errors of these algorithms from the smallest to the largest are \squishe, \dps, \cist, the optimal \lsa algorithm and \cista. Algorithm \cista has obvious higher average errors than \cist as the former essentially forms spatio-temporal cones with a radius of $\epsilon$.

\sstab\emph{(6) Running time}. Algorithms \cist and \cista are the fastest. They are on average
($14.21$, $18.19$, $17.06$, $9.98$), ($2.84$, $3.45$, $3.69$, $2.86$) and ($925.25$, $7888.26$, $40041.59$, $8528.76$) times faster than \dps, \squishe and the optimal \lsa algorithm on datasets (\sercar, \geolife, \mopsi, \pricar), respectively.
The advantage of running time of algorithms \cist and \cista also increases  with the increase of the trajectory size.


\sstab \emph{(7) Distance metrics}. Compared with \ped, \sed supports  spatio-temporal queries. However, it comes a price, \eg  the compression ratios of algorithms using \ped are better than those using \sed.}

\sstab \textcolor{blue}{\emph{(8) Trajectory applications}. \sed is more suitable than \ped for spatio-temporal queries.}


\stitle{Discussion}. We next briefly discuss the choice of algorithms to compress trajectories.
As different applications may have different requirements to reach a balance among multiple metrics, we only provide a brief guideline from the views of running time, compression ratio and average error, respectively.

\sstab(1) When the running time is the first-level consideration or algorithms are run in resource-constrained devices, then the one-pass algorithms, \ie~\cist and \cista, are surely the best choices, and they have pretty good compression ratios at the same time.

\sstab(2) When the compression ratio is the priority, then algorithm \cista and the optimal algorithm are the selections, followed by algorithms \dps and \cist.

\sstab(3) When considering error, \squishe is a good choice because it has a relative small average error. Alternatively, we can also use \dps or \cist by setting a smaller error bound $\epsilon$ compared with \squishe.


%%********************************* The End **********************************


