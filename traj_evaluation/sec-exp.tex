%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-1ex}
\section{Evaluation} %Experimental Study
\label{sec-exp}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In this section, we present extensive and systematic experimental studies and analyses of eleven representative \lsa algorithms.
Using four real-life datasets, we conduct three sets of tests to evaluate compression ratios, errors and efficiency of these representative algorithms using distance metrics \ped, \sed and \dad, and the impacts of error bounds $\epsilon$ and trajectory sizes.
%
%(1) the effectiveness of these algorithms, and
%(2) the efficiency of them.
%{An additional test of the effectiveness of near optimal algorithm (\nopts) is presented in Appendix B.}

%\vspace{-1ex}
\subsection{Experimental Setting}
%We first introduce the settings of our experimental study.

\stitle{Real-life Trajectory Datasets}.
We use four varied real-life datasets shown in \mytable{tab:datasets}, namely, taxi trajectory data (\taxi) collected by a Beijing taxi company, Service car trajectory data (\ucar) collected by a Chinese car rental company, Geolife trajectory data (\geolife) collected in GeoLife project~\cite{Web:Geolife} and \mopsi trajectory data (\mopsi) collected in Mopsi project \cite{Web:Mopsi}, to evaluate those \lsa algorithms. These data sets have varied sampling rates, ranging from one point per minute to one point per second.
They also come from different sources, where \taxi and \ucar are collected by cars in urban, and \geolife and \mopsi are a mixing of cars and individuals. The data source and sampling rate also affect the performance of \lsa algorithms using certain distance metrics.

\begin{table}
	\vspace{-1ex}
	\caption{\small Real-life trajectory datasets}
	\centering
	\small
	\begin{tabular}{|l|c|c|c|r|}
		\hline
		\bf{Data}& \bf{Number\ of}     &\bf{Sampling}   &\bf{Points~Per}    &\bf{Total} \\
		\bf{Sets} & \bf{Trajectories}   &\bf{Rates (s)}  &\bf{Trajectory}&\bf{points}\\	\hline
		\taxi	&{500}	    &60	        &{$\sim42.8$K}      &{21.4M} \\	\hline
		%\truck	&10,368	    &1-60	    &$\sim71.9$     &746M \\	\hline
		%\ucar	&11,000	    &3-5	    &$\sim119.1$   &1.31G\\		\hline
		%
		\ucar	&200	    &3-5	&$\sim114.0$K   &22.8M 	\\	\hline
		\geolife &182	    &1-5	&$\sim131.4$K   &24.2M	\\	\hline
		\mopsi   &51	    	&2	    &$\sim153.9$K   &7.9M	\\	\hline
		%\act	& 10	    &1	    &$\sim11.8$    &112.8K	\\	\hline
	\end{tabular}
	\label{tab:datasets}
	\vspace{-3ex}
\end{table}


% \ni \emph{(1) Truck trajectory data} (\truck) is the GPS trajectories collected by \eat{10,368} trucks equipped with GPS sensors in China
% during a period from Mar. 2015 to Oct. 2015. The sampling rate varied from 1s to 60s.
%Trajectories mostly have around $50$ to $90$ thousand data points.

%\vspace{0.5ex}
%\ni \emph{(1) Service car trajectory data} (\ucar) is the GPS trajectories collected by a Chinese car rental company during Apr. 2015 to Nov. 2015. The sampling rate was one point per $3$--$5$ seconds, and each trajectory has around $114.1K$ points.
%.We randomly chose $1,000$ cars from them

%\vspace{0.5ex}
%\ni \emph{(2) GeoLife trajectory data} (\geolife) is the GPS trajectories collected in GeoLife project~\cite{Web:Geolife} by 182 users in a period from Apr. 2007 to Oct. 2011. These trajectories have a variety of sampling rates, among which 91\% are logged in each 1-5 seconds per point. %or each 5-10 meters
%This dataset contains 182 trajectories, one trajectory for each user, with a total distance of about 1.2 million kilometers.
%The longest trajectory has 2,156,994 points.

%\vspace{0.5ex}
%\ni \emph{(3) Mopsi trajectory data} (\mopsi) is the GPS trajectories collected in Mopsi project~\cite{Web:Mopsi} by 51 users in a period from 2008 to 2014. Most routes are in Joensuu region, Finland. The sampling rate was one point per $2$ seconds, and each trajectory has around $153.9K$ points.
%exist on every continent.

%\vspace{0.5ex}
%\ni \emph{(4) Act trajectory data} (\act) is a small set GPS trajectories collected with a high sampling rate of one point per second by our team members in 2017. There are 10 trajectories and each trajectory has around 11.8K points.

%The details of these datasets are shown in Table~\ref{tab:dataset}.

\stitle{Algorithms and implementation}.
We implement the representative algorithms of \mytable{tab:summary-lsa}.
 They are optimal algorithm \opt, batch algorithms \dpa and \tpa, online algorithms  \opwa, \bqsa and \squishe, and one-pass algorithms  \operb, \siped, \cised, \intersec and \interval.
For one-pass algorithms \siped and \cised, we implement two versions of them (half and full $\epsilon$), denoted as \siped($\epsilon$), \siped($\frac{\epsilon}{2}$), \cised($\epsilon$) and \cised($\frac{\epsilon}{2}$).
For algorithm \cised($\epsilon$) and \cised($\frac{\epsilon}{2}$), we fixed parameter $m=16$ as evaluated in \cite{Lin:Cised}, \ie 16-edges inscribe regular polygon.
% For algorithm \nopts, we fixed parameter $m=32$.
All algorithms were implemented with Java.
All tests were run on an x64-based  PC with 4 Intel(R) Core(TM) i7-6700 CPU @
3.40GHz  and 8GB of memory, and {the max heap size of Java VM is 4GB.}
%, and each test was repeated over 3 times and the average is reported here.


We test these algorithms under varied error bounds $\epsilon$ and trajectory sizes, respectively. We first varied $\epsilon$ from $10m$ to $100m$ in \ped and \sed (or from $15^o$ to $90^o$ in \dad) on the entire four datasets, respectively. We then chose $10$ trajectories from each dataset, and varied the size \trajec{|T|} of a trajectory from $1,000$ points to $10,000$ points while fixed the error bound $\epsilon=40$ metres or $\epsilon=45$ degrees.

\eat{%%%%%%%%%%%%%%%%%%%
	\stitle{Real-life Trajectory Datasets}.
	We use four real-life datasets shown in Table~\ref{tab:dataset} to test our solutions.
	
	\sstab{\bf(1) Taxi trajectory data}, referred to as \taxi, is the GPS trajectories collected by $12,727$ taxies equipped with GPS sensors in Beijing during a period
	from Nov. 1, 2010 to Nov. 30, 2010. The sampling rate was one point  per 60s, and \taxi has $39,100$ data points on average per trajectory.
	
	\sstab{\bf(2) Truck trajectory data}, referred to as \truck, is the GPS trajectories collected by 10,368 trucks equipped with GPS sensors in China
	during a period from Mar. 2015 to Oct. 2015. The sampling rate varied from 1s to 60s. Trajectories mostly have around $50$ to $90$ thousand data points.
	
	\sstab{\bf(3) Service car trajectory data}, referred to as \ucar,  is the GPS trajectories collected by a car rental company.
	We chose $11,000$ cars from them, during Apr. 2015 to Nov. 2015. The sampling rate was one point per $3$--$5$ seconds, and
	each trajectory has around $119.1K$ data points.
	
	{\sstab{\bf(4) GeoLife trajectory data}, referred to as \geolife, is the GPS trajectories collected in GeoLife project~\cite{Zheng:GeoLife} by 182 users in a period from Apr. 2007 to Oct. 2011. These trajectories have a variety of sampling rates, among which 91\% are logged in each 1-5 seconds or each 5-10 meters per point. The longest trajectory has 2,156,994 points.}
	%This dataset contains 182 trajectories, one trajectory for each user, with a total distance of about 1.2 million kilometers.
}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\subsection{Evaluation Metrics}
Compression ratios, errors and running time are the most popular metrics to evaluate \lsa algorithms.

\stitle{Compression ratios.}
For trajectories $\{\dddot{\mathcal{T}_1}, \ldots, \dddot{\mathcal{T}_M}\}$ and their piecewise line representations $\{\overline{\mathcal{T}_1}, \ldots, \overline{\mathcal{T}_M}\}$,
the compression ratio is $(\sum_{j=1}^{M} |\overline{\mathcal{T}}_j |)/(\sum_{j=1}^{M} |\dddot{\mathcal{T}}_j |)$.
By this definition, algorithms with lower compression ratios are better.

\stitle{Average Errors.}
All these algorithms in \mytable{tab:summary-lsa} are error bounded, \ie the max errors are bounded. Hence, we only evaluate the average errors here. Given a set of trajectories $\{\dddot{\mathcal{T}_1}, \ldots, \dddot{\mathcal{T}_M}\}$ and their piecewise line representations
$\{\overline{\mathcal{T}_1}, \ldots, \overline{\mathcal{T}_M}\}$, and $P_{j,i}$ denoting
a point in trajectory $\dddot{\mathcal{T}}_j$ contained in a line segment $\mathcal{L}_{l,i}\in\overline{\mathcal{T}_l}$ ($l\in[1,M]$),
then the average error is $\sum_{j=1}^{M}\sum_{i=0}^{M} d(P_{j,i},
\mathcal{L}_{l,i})/\sum_{j=1}^{M}{|\dddot{\mathcal{T}}_j |}$.

\stitle{Running time.}
It is the efficiency of algorithms.
%We load and compress trajectories one by one, and only count the running time of the compressing process.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experimental Results and Analyses}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We next present our findings.



\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-epsilon-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-epsilon-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-epsilon-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of compression ratios (\ped) on full datasets: varying the error bound $\epsilon$.}
	\label{fig:cr-ped-epsilon}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-epsilon-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-epsilon-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-epsilon-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of compression ratios (\sed) on full datasets: varying the error bound $\epsilon$.}
	\label{fig:cr-sed-epsilon}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-epsilon-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-epsilon-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-epsilon-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of compression ratios (\dad) on full datasets: varying the error bound $\epsilon$.}
	\label{fig:cr-dad-epsilon}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-size-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-size-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of compression ratios (\ped) on small datasets: varying the size of
    trajectories.}
  \label{fig:cr-ped-size}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-size-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-size-mopsi.png}		
	\vspace{-3ex}

	\caption{\small Evaluation of compression ratios (\sed) on small datasets: varying the size of
    trajectories.}
  \label{fig:cr-sed-size}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-size-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-size-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of compression ratios (\dad) on small datasets: varying the size of trajectories.}
	\label{fig:cr-dad-size}
	\vspace{-3ex}
\end{figure*}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-1ex}
\subsubsection{Compression Ratio Evaluation and Analyses}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\eat{%%%%%%%
We first test the compression ratios of these algorithms under varied error bounds $\epsilon$ and trajectory sizes, respectively. We varied $\epsilon$ from $10m$ to $100m$ in \ped and \sed (or from $15^o$ to $90^o$ in \dad) on the entire four datasets, respectively. The results are reported in Figure~\ref{fig:cr-ped-epsilon}, Figure~\ref{fig:cr-sed-epsilon} and Figure~\ref{fig:cr-dad-epsilon} ({Note that the naive optimal algorithm using \sed or \dad is not reported here because it can not run with the full dataset as input}).
%
We then chose $10$ trajectories from each dataset \taxi, \ucar, \geolife and \mopsi, respectively, and varied the size \trajec{|T|} of a trajectory from $1,000$ points to $10,000$ points, while fixed error bound $\epsilon = 60$ meters for \ped and \sed ({or $\epsilon = 45$ degrees for \dad}).
The experimental results are reported in Figure~\ref{fig:cr-ped-size}, Figure~\ref{fig:cr-sed-size} and Figure~\ref{fig:cr-dad-size}.
}%%%%%%%%%%%

%We test the compression ratios of these algorithms under varied error bounds $\epsilon$ and trajectory sizes, respectively.
The compression ratios of these algorithms under varied error bounds $\epsilon$ and trajectory sizes are reported in Figures~\ref{fig:cr-ped-epsilon},~\ref{fig:cr-sed-epsilon},~\ref{fig:cr-dad-epsilon},~\ref{fig:cr-ped-size},~\ref{fig:cr-sed-size} and~\ref{fig:cr-dad-size}.
{Note that the optimal algorithm using \sed and \dad is not reported in Figures~\ref{fig:cr-ped-epsilon},~\ref{fig:cr-sed-epsilon} and~\ref{fig:cr-dad-epsilon} as it runs out of memory when compressing the full dataset}. We first report our findings.

%%%%%%%%%%%%%%%%%
\sstab(1) The compression ratios of algorithms using \ped from the best
to the worst are the \opt algorithm, online algorithm \bqsa, one-pass algorithm \siped($\epsilon$), batch algorithms \tpa and
\dpa, and one-pass algorithms \siped($\frac{\epsilon}{2}$) and \operb.
The output sizes of algorithms \bqsa and \siped({$\epsilon$}) are on average
($103.58\%$, $113.32\%$, $120.22\%$, $120.83\%$) and ($103.98\%$, $116.04\%$, $124.46\%$, $124.24\%$) of the optimal algorithm \opt
on datasets \dSets, respectively.
Algorithms \tpa and \dpa are comparable, and their output sizes are on average
($103.17\%$, $125.05\%$, $131.01\%$, $138.01\%$) and ($106.98\%$, $130.03\%$, $140.56\%$, $139.00\%$) of \opt
on \dSets, respectively.
Algorithms \siped($\frac{\epsilon}{2}$) and \operb are comparable, and they are on average
($113.09\%$, $136.73\%$, $150.23\%$, $152.29\%$)
and ($119.89\%$, $143.14\%$, $147.80\%$, $152.37\%$) of \opt on \dSets, respectively.
%
For example, in \mopsi, the compression ratios of algorithms
(\opt, \tpa, \dpa, \bqsa, \siped(${\epsilon}$), \siped($\frac{\epsilon}{2}$), \operb ) are ($1.6\%$, $2.2\%$, $2.2\%$, $1.9\%$, $2.0\%$, $2.4\%$, $2.4\%$) when $\epsilon$ = $40m$.
%

%%%%%%%%%%%%%%%%%
\sstab(2) The compression ratios of algorithms using \sed from the best
to the worst are the \opt algorithm, one-pass algorithm \cised($\epsilon$), batch algorithms \tpa and
\dpa, one-pass algorithm \cised($\frac{\epsilon}{2}$), and online algorithm \squishe.
%
{Algorithms \tpa and \dpa are comparable, and they are on average
($102.72\%$, $125.23\%$, $143.92\%$, $128.63\%$) and ($103.18\%$, $123.93\%$, $141.46\%$, $121.14\%$)
 of algorithm \opt on datasets \dSets, respectively.}
%
{Algorithms \cised(${\epsilon}$), \cised($\frac{\epsilon}{2}$) and \squishe are on average (
  $102.04\%$, $109.27\%$, $110.13\%$, $115.90\%$,), ($108.00\%$,
  $134.35\%$, $159.30\%$, $136.06\%$) and ($110.27\%$, $165.94\%$, $225.68\%$, $206.90\%$)
 of \opt on \dSets, respectively.}
%
For example, in \mopsi, the compression ratios of algorithms
(\tpa, \dpa, \squishe, \cised(${\epsilon}$), \cised($\frac{\epsilon}{2}$))
are ($3.45\%$, $3.41\%$, $5.75\%$, $3.02\%$, $3.86\%$), respectively, when $\epsilon$ = $40m$.
%
%Algorithms \tpa and \dpa are comparable, and they are on average ($122.69\%$, $129.08\%$, $131.97\%$, $131.01\%$) and ($121.36\%$, $129.27\%$, $130.11\%$, $126.21\%$) of the near optimal algorithm \nopts on datasets \dSets, respectively.
%Algorithms \cised and \squishe are on average ($132.07\%$, $139.67\%$, $146.56\%$, $135.10\%$) and ($164.47\%$, $189.87\%$, $213.30\%$, $186.72\%$) of \nopts on datasets \dSets, respectively.
%
%For example, in \mopsi, the compression ratios of algorithms (\nopts, \tpa, \dpa, \squishe, \cised) are ($2.62\%$, $3.45\%$, $3.41\%$, $5.75\%$, $3.86\%$), respectively, when $\epsilon$ = $40m$.
%

%%%%%%%%%%%%%%%%%
\sstab(3) The compression ratios of algorithms using \dad from the best
to the worst are the \opt algorithm, batch algorithm \tpa and
one-pass algorithm \interval, online algorithm \opwa, one-pass algorithm \intersec and batch algorithm \dpa.
%
{Algorithms \tpa, \opwa and \interval are comparable, and are on average
($100.81\%$, $102.91\%$, $102.27\%$, $106.88\%$), ($104.39\%$, $116.09\%$, $107.11\%$, $115.42\%$) and ($102.38\%$, $101.98\%$, $103.52\%$, $103.43\%$)
 of algorithm \opt on datasets \dSets, respectively.}
%
{Algorithms \intersec and \dpa are on average ($111.72\%$, $156.00\%$, $121.20\%$, $230.52\%$) and ($133.19\%$, $283.93\%$, $143.79\%$, $278.89\%$)
 of algorithm \opt on datasets \dSets, respectively.}
%
For example, in \mopsi, the compression ratios of algorithms (\tpa, \dpa, \opwa, \interval, \intersec)
are ($13.3\%$, $23.1\%$, $14.12\%$, $13.7\%$, $18.96\%$), respectively, when $\epsilon$ = $45$ degrees.
%


We then present analyses from the views of \lsa algorithms and distance metrics.

\stitle{Analyses of \lsa algorithms}. The \opt algorithm is the best in term of compression ratios, followed by online algorithms \opwa and \bqsa and one-pass algorithms using the full $\epsilon$ \emph{sector/cone/range}. One-pass algorithms using a half $\epsilon$ \emph{sector/cone/range} and batch algorithms except \dpa using \dad also have good compression ratios.
\eat{
 are the most outstanding algorithms among all sub optimal algorithms.
, followed by batch algorithms. Online algorithms have varied compression ratios, ranging from the worst to the similar with batch and one-pass algorithms.
}

%\todo{Batch: Bottom-up vs Top-down.}
For batch algorithms, bottom-up algorithm (\tpa) and top-down algorithm (\dpa) have the similar compression ratios when using \ped and \sed. However, when using \dad, bottom-up methods have obviously better compression ratios than top-down methods.  As we know that top-down algorithms split a long trajectory $[P_s, ..., P_e]$ into two sub trajectories by finding out a splitting point $P_i (s<i<e)$ that has the max position deviation (or whose line segment $\vv{P_{i-1}P_{i}}$ has the max direction deviation) to line segment $\vv{P_sP_{e}}$. Though this strategy works well with \ped and \sed, a point with the max direction deviation may not be a reasonable splitting point in the direction-aware scenario. Thus it leads to a poorer compression ratio. However, bottom-up methods do not have this weakness as they always merge neighbouring points.



%\todo{Online: }
For online algorithms, \bqsa and \opwa are comparable with the best sub-optimal algorithms. This is because \opwa is indeed a combination of \dpa and opening window, and \bqsa is mainly an efficiency optimized \opwa.
\squishe has the poorest compression ratio among all algorithms using \sed. This is the result of its mechanism: \squishe estimates the lowest \sed error and removes the point with ``predicted to introduce the lowest amount of error into the compression"\cite{Muckell:SQUISH}. Its ``prediction" method is not accurate enough, thus, in order to ensure the error bound, it may ignore too many potential points that could be represented by a line segment.

%\todo{One pass: half $\epsilon$ vs full $\epsilon$.}
For one-pass algorithms, the full $\epsilon$ sector/cone/range combining with a position/direction constraint always have better compression ratios than the half $\epsilon$ sector/cone/range versions in all datasets, and they are comparable with the best sub-optimal algorithms.
This may be related to the moving habits or patterns of moving objects that implied in trajectories.
That is, a moving object, like an individual or a car, usually keeps moving forward for quite a long time, engendering a sequence of data points distributing in a narrow strip. Under such circumstance, a new data point is quite possible living in the common intersection of larger sectors/cones/ranges, which further leads to a better compression ratio.
%which lets more data points be represented by a result line segment.

%combining with a constraint that the current point should live in the common intersection of preview sectors/cones/ranges



\stitle{Analyses of distance metrics}.
Though \ped, \sed and \dad are different distances, the comparison of their compression ratios is helpful to choose an effective distance metric.
%whose usages are mainly decided by application requirements
%
First, given the same error bound $\epsilon$, the compression ratios of algorithms using \ped are obviously better
than using \sed. More specifically, \emph{the output sizes of using \sed are approximately twice of \ped.}
%
As shown in Figures~\ref{fig:cr-ped-epsilon} and~\ref{fig:cr-sed-epsilon}, the output sizes of algorithms \tpa and \dpa
using \ped are on average ($55.08\%$, $43.55\%$, $47.49\%$, $63.15\%$) and ($56.75\%$, $45.79\%$,
$50.88\%$, $64.50\%$) of algorithms \tpa and \dpa using \sed on datasets \dSets, respectively.
%
%and in Figure~\ref{fig:cr-ped-size} and Figure~\ref{fig:cr-sed-size}, the compression ratios of algorithms \opt, \tpa and \dpa using \ped are on average {($56.03\%$, $33.42\%$, $33.12\%$, $72.42\%$),	($55.78\%$, $31.88\%$, $34.27\%$, $69.44\%$) and ($58.09\%$, $34.82\%$,	$40.91\%$, $75.06\%$)} of algorithms \opt, \tpa and \dpa using \sed on datasets \dSets, respectively.
%
This result shows ~\sed saves temporal information at a price with twice more points.


Secondly, in practice (\eg $\epsilon <100$ meters and $\epsilon < 60$ degrees), \sed have obviously better compression ratios than \dad in datasets \geolife and \mopsi, a bit better than \dad in \taxi and a bit poorer than \dad in \ucar.
This is because some \geolife and \mopsi trajectories are collected by individuals that are in transportation modes of walking, running and riding, and moving objects in those modes may change their directions with a considerable range (\eg large than $60$ degrees) more frequently than cars in urban. Moreover, \geolife and \mopsi have higher sampling rates than \taxi and \ucar, which capture more direction changes, \ie direction changes in a small time interval.

%It seems that it is a normal phenomenon that a moving object frequently changes its direction with a considerable range (\eg large than $60$ degrees) during a trip.




\eat{

\sstab (1) Trajectory sizes have few impacts on compression ratios.

\sstab (1) When increasing $\epsilon$, the compression ratios decrease.
%For example, in \mopsi, the compression ratios are greater than {$4\%$} when $\epsilon$ = $10m$, and less than {$2\%$} when $\epsilon$ = $100m$.

\sstab (2) Dataset \mopsi usually has the lowest compression ratios, compared with \taxi, \ucar and \geolife, due to its highest sampling rate, \taxi has the highest compression ratios due to its lowest sampling rate, and \ucar and \geolife and  have the compression ratios in the middle accordingly.
}


\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-epsilon-taxi.png} \hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-epsilon-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-epsilon-mopsi.png}	
	\vspace{-3ex}
	\caption{\small Evaluation of average errors (\ped) on full datasets: varying the error bound $\epsilon$.}
	\label{fig:ae-ped-epsilon}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-epsilon-taxi.png} \hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-epsilon-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-epsilon-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of average errors (\sed) on full datasets: varying the error bound $\epsilon$.}
	\label{fig:ae-sed-epsilon}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-epsilon-taxi.png} \hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-epsilon-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-epsilon-mopsi.png}	
	\vspace{-3ex}
	\caption{\small Evaluation of average errors (\dad) on full datasets: varying the error bound $\epsilon$.}
	\label{fig:ae-dad-ped-epsilon}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-size-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-size-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of average errors (\ped) on small datasets: varying the size of
    trajectories.}
  \label{fig:ae-ped-size}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-size-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-size-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of average errors (\sed) on small datasets: varying the size of
    trajectories.}
  \label{fig:ae-sed-size}
	\vspace{-2ex}
\end{figure*}


\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-size-taxi.png} \hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-size-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-size-mopsi.png}	
	\vspace{-3ex}
	\caption{\small Evaluation of average errors (\dad) on small datasets: varying the size of trajectories.}
	\label{fig:ae-dad-ped-size}
	\vspace{-2ex}
\end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-0.5ex}
\subsubsection{Average Error Evaluation and Analyses}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The average errors of these algorithms under varied error bounds $\epsilon$ and trajectory sizes are reported in Figures~\ref{fig:ae-ped-epsilon},~\ref{fig:ae-sed-epsilon},~\ref{fig:ae-dad-ped-epsilon},~\ref{fig:ae-ped-size},~\ref{fig:ae-sed-size} and~\ref{fig:ae-dad-ped-size}.
We first report our findings.

\sstab (1) When using \ped, the average errors from the smallest
to the largest are batch algorithms \tpa and \dpa, one-pass
algorithms \siped($\frac{\epsilon}{2}$) and \operb, the \opt algorithm and one-pass algorithm \siped(${\epsilon}$), and online algorithm \bqsa.
%
For full datasets, algorithms \tpa and \dpa are comparable, and they are on average ($77.43\%$, $58.69\%$, $61.34\%$,
$57.57\%$) and ($88.12\%$, $57.61\%$, $62.66\%$, $60.23\%$) of \opt on datasets \dSets, respectively.
Algorithms \siped($\frac{\epsilon}{2}$) and \operb are comparable, and they are on average
($73.08\%$, $80.96\%$, $79.12\%$, $79.33\%$), ($73.03\%$, $70.60\%$, $76.64\%$, $78.71\%$) of \opt on datasets \dSets, respectively.
%
Algorithms \siped(${\epsilon}$) and \bqsa are on average ($87.63\%$, $100.05\%$, $101.01\%$, $102.69\%$) and ($97.69\%$, $104.67\%$, $108.91\%$, $106.92\%$) of \opt on datasets \dSets, respectively.
For example, the average errors of algorithms
(\opt, \tpa, \dpa, \bqsa, \siped(${\epsilon}$), \siped($\frac{\epsilon}{2}$), \operb ) in the full \mopsi are ($16.08$, $9.19$, $9.68$, $17.4$, $12.96$, $16.83$, $12.77$) metres when $\epsilon$ = $40m$.

\eat{
In Figure~\ref{fig:ae-ped-size}, algorithms \tpa and \dpa are comparable, and they are on average
{($105.94\%$, $53.16\%$, $66.84\%$, $61.50\%$), ($111.96\%$, $52.04\%$, $78.65\%$, $60.57\%$)} of \opt on datasets \dSets, respectively.
Algorithms \siped($\frac{\epsilon}{2}$) and \operb are on average {($85.30\%$, $73.55\%$, $82.01\%$,
  $85.23\%$), ($97.69\%$, $67.20\%$, $82.58\%$, $81.88\%$)}
of \opt on datasets \dSets, respectively.
Algorithm \bqsa is  on average  {($108.51\%$, $102.06\%$, $104.63\%$, $113.80\%$)}
of \opt on datasets \dSets, respectively.
}

\sstab (2) When using \sed, the average errors from the smallest
to the largest are online algorithm \squishe, batch algorithms \tpa and \dpa,
one-pass algorithm \cised($\frac{\epsilon}{2}$), and one-pass algorithms \cised(${\epsilon}$) and the \opt algorithm.
%
Algorithms \tpa and \dpa are comparable, and they are on average
{($87.22\%$, $60.36\%$, $66.11\%$, $62.43\%$), ($81.04\%$, $62.54\%$, $67.04\%$, $68.64\%$)} of \opt on datasets \dSets, respectively.
Algorithms \cised(${\epsilon}$), \cised($\frac{\epsilon}{2}$) and \squishe are on average {($95.07\%$, $97.32\%$, $106.74\%$, $108.16\%$), ($73.15\%$, $75.29\%$, $76.03\%$, $81.44\%$) and ($46.27\%$, $40.61\%$, $38.15\%$, $34.22\%$)} of \opt on datasets \dSets, respectively.
%
For example, the average errors of algorithms
(\opt, \tpa, \dpa, \squishe, \cised(${\epsilon}$), \cised($\frac{\epsilon}{2}$)) in full \mopsi are ($19.39$, $12.17$, $12.20$, $6.76$, $20.68$, $14.71$) metres, respectively, when $\epsilon$ = $40m$.
%


\sstab {(3) When using \dad, the average errors from the smallest
to the largest are one-pass algorithm \intersec, batch algorithms \dpa and \tpa, one-pass algorithm \interval and online algorithm \opwa, and the \opt algorithm.
\eat{%%%%%%%%%%%%%
For example, in Figure~\ref{fig:ae-dad-ped-epsilon}, in \mopsi, the average errors of algorithms
(\tpa, \dpa, \interval) in terms of \ped are ($65.6$, $75.4$, $68.1$) meters, respectively, when $\epsilon$ = $45$ degrees.
It is also worth pointing out that the max errors of algorithms
(\tpa, \dpa, \interval) using \dad may be very large in terms of \ped, \eg they are ($68247.9$, $66794.4$, $68247.9$) meters, respectively, when $\epsilon$ = $45$ degrees.}
}%%%%%%%%%%%%%
Algorithms \tpa, \opwa and \interval are comparable, and they are on average
{($88.94\%$, $91.35\%$, $61.45\%$, $73.71\%$), ($88.23\%$, $91.95\%$, $61.37\%$, $76.17\%$) and ($93.97\%$, $90.36\%$, $68.23\%$, $163.47\%$)} of \opt on datasets \dSets, respectively.
Algorithms \intersec and \dpa are on average ($66.17\%$, $62.03\%$, $76.54\%$, $110.69\%$) and ($76.86\%$, $82.45\%$, $96.52\%$, $137.95\%$) of \opt on datasets \dSets, respectively.


We then present analyses from the views of \lsa algorithms and distance metrics.

\stitle{Analyses of \lsa algorithms}. The average errors of these algorithms  are generally on the contrary of compression ratios. The optimal algorithm is usually  the worst algorithm in term of average errors, followed by one-pass algorithms and then batch algorithms.
Online algorithms have varied average errors, ranging from the best to the worst.
(1) For batch algorithms, both bottom-up algorithm (\tpa) and top-down algorithm (\dpa) have similar average errors, and they are pretty good compared with other algorithms.
%
(2) Online algorithms \bqsa and \opwa often have the largest average errors in all sub-optimal algorithms, while \squishe has the smallest. This is also on the contrary of their compression ratios.
%
(3) For one-pass algorithms, the full $\epsilon$ sector/cone/range combining with a position/direction constraint always have larger average errors than the half $\epsilon$ sector/cone/range.
%
Local distance checking approaches try to include more points into a line segment, this greedy strategy is likely leading to larger average errors, considerable larger than batch algorithms that have the similar compression ratios as one-pass and online algorithms.


\stitle{Analyses of distance metrics}.
For the same error bound $\epsilon$, the average errors of algorithms using \sed are a bit larger than using \ped. {As we know that the \ped error is originally caused by the direction changes  of a moving object while the \sed error is caused by the changes of both the direction and the speed of a moving object, the above phenomenon probably reveals that the changes of speeds are more frequent than the changes of directions for moving objects.}
%
And in practice (\eg $\epsilon = 60$ meters and $\epsilon = 45$ degrees), the average errors of algorithms using \dad, when translated to position errors like \ped, are likely $10$ times larger than algorithms directly using \ped and \sed. This is obvious as a small direction deviation with a long trip may lead to a large position error.




\eat{
\sstab (1) When increasing $\epsilon$, the average errors increase linearly.

\sstab (2) Datasets have few impacts on the average errors.

\sstab (1) Trajectory sizes have few impacts on average errors.

\sstab (2) The average errors in this test are consistent with test Exp-2.1.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-1ex}
\subsubsection{Efficiency Evaluation and Analyses}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We finally compare the efficiency of these algorithms.
The results are reported in Figures~\ref{fig:time-epsilon-ped},~\ref{fig:time-epsilon-sed},~\ref{fig:time-epsilon-dad},~\ref{fig:time-size-ped},~\ref{fig:time-size-sed} and~\ref{fig:time-size-dad}.
Note that even on the small datasets, \emph{the running time of algorithm \opt  is thousands of times slower than one-pass algorithms}. As it is not clear to show all these algorithms in a single figure, only the results of sub-optimal algorithms are shown in these figures.
We first report our findings.


\sstab (1) When using \ped, in most cases, the running time from the smallest to the largest is one-pass algorithms \siped and \operb, batch algorithms \tpa and \dpa, and online algorithm \bqsa.
Algorithms \siped($\frac{\epsilon}{2}$) and \operb are comparable, algorithm \siped(${\epsilon}$) is $(0.99, 0.92, 0.92, 0.91)$ times of \siped($\frac{\epsilon}{2}$), and algorithms \tpa, \dpa and \bqsa are on average
($19.19$, $26.79$, $28.25$, $29.87$), ($17.90$, $16.32$, $15.40$, $11.02$) and ($15.07$, $37.73$, $62.23$, $61.29$)
times slower than one-pass algorithm \siped($\frac{\epsilon}{2}$) on datasets \dSets, respectively.
%
For example, in \mopsi, the running time of algorithms
(\tpa, \dpa, \bqsa, \siped(${\epsilon}$), \siped($\frac{\epsilon}{2}$), \operb ) is ($232.9$, $124.2$, $469.4$, $6.89$, $7.6$, $8.6$) seconds when $\epsilon$ = $40m$.

\sstab (2) When using \sed, the running time from the smallest to the largest is one-pass algorithm \cised, online algorithm \squishe, and batch algorithms \tpa and \dpa. Algorithm \cised(${\epsilon}$) is $(1.17, 1.17, 1.17, 0.91)$ times of \cised($\frac{\epsilon}{2}$), and algorithms \tpa, \dpa and \squishe are on average
($8.58$, $13.33$, $15.81$, $13.09$), ($12.81$, $12.93$, $10.64$, $8.79$) and
($2.63$, $2.75$, $2.78$, $2.57$) times slower than \cised($\frac{\epsilon}{2}$) on datasets \dSets, respectively.
%
For example, in \mopsi, the running time of algorithms
(\tpa, \dpa, \squishe, \cised($\epsilon$), \cised($\frac{\epsilon}{2}$)) is ($156.6$, $104.8$, $27.2$, $11.6$, $9.7$) seconds when $\epsilon$ = $40m$.

\sstab {(3) When using \dad,} the running time from the smallest to the
largest is one-pass algorithms \intersec and \interval, batch algorithms \tpa and \dpa, and online algorithm \opwa.
%
%Algorithm \interval is a bit slower than \intersec, and algorithms \tpa and \dpa are on average
%($6.66$, $13.55$, $12.73$, $12.73$) and ($11.67$, $14.24$, $16.51$, $17.59$)
%times slower than \interval on datasets \dSets, respectively.
%
Algorithm \interval is $(1.86,1.80, 1.84, 1.81)$ times slower than \intersec, and algorithms \tpa, \dpa and \opwa are on average
($12.53$, $24.63$, $23.53$, $23.23$), ($21.19$, $25.49$, $30.11$, $31.72$) and ($6.84$, $39.29$, $147.85$, $80.09$)
times slower than \intersec on datasets \dSets, respectively.
%
For example, the running time of algorithms
(\tpa, \dpa, \opwa, \interval, \intersec) is ($105.57$, $152.53$, $240.40$, $8.57$, $4.69$) seconds in \mopsi when
$\epsilon=45$ degrees, respectively.

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-epsilon-taxi.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-epsilon-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-epsilon-mopsi.png}	\hspace{1ex}
	\vspace{-3ex}
	\caption{\small Evaluation of running time (\ped) on full datasets: varying the error bound $\epsilon$.}\label{fig:time-epsilon-ped}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-epsilon-taxi.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-epsilon-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-epsilon-mopsi.png}	\hspace{1ex}
	\vspace{-3ex}
	\caption{\small Evaluation of running time (\sed) on full datasets: varying the error bound $\epsilon$.}\label{fig:time-epsilon-sed}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-epsilon-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-epsilon-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-epsilon-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of running time (\dad) on full datasets: varying the error bound $\epsilon$.}\label{fig:time-epsilon-dad}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-size-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-size-mopsi.png}	\hspace{1ex}
	\vspace{-3ex}
	\caption{\small Evaluation of running time (\ped) on small datasets: varying the size of trajectories.}\label{fig:time-size-ped}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-size-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-size-mopsi.png}	\hspace{1ex}
	\vspace{-3ex}
	\caption{\small Evaluation of running time (\sed) on small datasets: varying the size of trajectories.}\label{fig:time-size-sed}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-size-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-size-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of running time (\dad) on small datasets: varying the size of trajectories.}\label{fig:time-size-dad}
	\vspace{-2ex}
\end{figure*}


%\sstab (2) When using \ped, the running time from the smallest to the largest are one-pass algorithms \siped and \operb, and batch and online algorithms \tpa, \dpa and \bqsa. Algorithms \siped and \operb are comparable. Algorithms \tpa, \dpa and \bqsa are comparable, and they are on average \textcolor{red}{($3.8$--$5.3$, $3.5$--$4.8$, $4.6$--$7.2$, $6.2$--$8.4$)} times slower than the one-pass algorithms \siped and \operb on datasets \dSets, respectively.

%\sstab (3) When using \sed, the running time from the smallest to the largest are one-pass algorithm \cised, online algorithm \squishe, and batch algorithms \tpa and \dpa.  Algorithms \squishe, \tpa and \dpa are on average \textcolor{red}{($9.6$--$17.6$, $8.8$--$15.4$, $8.4$--$16.3$, $9.0$--$14.4$)}, \textcolor{red}{($9.6$--$17.6$, $8.8$--$15.4$, $8.4$--$16.3$, $9.0$--$14.4$)} and \textcolor{red}{($9.6$--$17.6$, $8.8$--$15.4$, $8.4$--$16.3$, $9.0$--$14.4$)} times slower than \cised on datasets \dSets, respectively.

%\sstab (4) Batch algorithms \dpa and \tpa using \sed run a bit faster than using \ped, while the one-pass algorithm \cised run \textcolor{red}{$2.0$--$3.0$} times slower than \siped and \operb.


We then present analyses from the views of \lsa algorithms and distance metrics.


\stitle{Analyses of \lsa algorithms.}
The running time from the fastest to the slowest is one-pass algorithms, online and batch algorithms, and optimal algorithms.

For batch algorithms, the running time of algorithms \dpa and \tpa decreases or increases with the increase of error bound $\epsilon$, respectively, due to the top-down and bottom-up approaches that they apply. When using \ped or \sed, top-down algorithm usually runs faster than bottom-up algorithm when the error bound $\epsilon$~is large (\eg in \geolife, $\epsilon >10$ metres when using \ped and $\epsilon >30$ metres when using \sed), which means that top-down (bottom-up) algorithm needs to split (merge) the original trajectory fewer (more) times in these cases, vice versa. When using \dad,  top-down algorithms are normally a bit slower than bottom-up algorithms (recall that top-down algorithms have poorer compression ratios compared with bottom-up algorithms, which means that it needs more time to split the raw trajectory into more sub trajectories).
In addition to error bounds, sampling rates also have impacts on the efficiency of batch algorithms. A dataset with high sampling rate likely needs more merging processes than splitting processes, thus, top-down algorithms run faster than bottom-up algorithms in high sampling datasets when using \ped or \sed.

For online algorithms, \squishe is faster than \bqsa and \opwa at a cost of poorer compression ratios, and it is still a few times slower than one-pass algorithms. \bqsa and \opwa both have poor efficiency as they finally need batch approaches, and batch approaches running in a buffer are still time consuming.

For one-pass algorithms, \operb, \siped, \cised and \interval show a linear running time that is consistent with their time complexity analyses. They are not very sensitive to error bound $\epsilon$, and also scale well with the increase of trajectory size on all datasets as a data point is processed only one time during the whole process.
Algorithms \siped, \operb and \interval have similar running time, and algorithm \cised runs a bit slower than them, partially because finding the common intersection of spatial-temporal cones is a heavier work than sectors or ranges.


\stitle{Analyses of distance metrics.}
The computation time of \dad is faster than \ped and \sed, and the computation time of \ped and \sed are 2.3 and 1.7 times of \dad, respectively.
{It is also worth pointing out that algorithms \dpa using \ped, \sed and \dad have similar running time in all datasets, though the computation of \ped is much heavier than \sed and \dad. The reason is that \dpa using \ped has the best compression ratios which instead leads to the least splitting processes in the top-down manner. Combining these two factors, \ie the computing of distance/direction deviation and the processing of trajectory splitting, finally, \dpa using \ped has similar running time as \dpa using \dad or \sed.}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\stitle{Summary}.
\subsubsection{Summary}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
From these tests we find the followings.

\stitle{\lsa Algorithms}.
(1) The optimal algorithm has the best compression ratios, large average errors and the worst efficiencies.
%
(2) Batch algorithms, except \dpa using \dad, have good compression ratios, normal average errors and poor efficiency.
%
The bottom-up (\tpa) and top-down (\dpa) algorithms have the similar compression ratios and average errors when using either \ped or \sed. The bottom-up method has obviously better compression ratios than the top-down method when using \dad.
%
The running time of batch algorithms \dpa and \tpa decreases and increases with the increase of error bound $\epsilon$, respectively. When using \ped or \sed, top-down algorithm \dpa usually runs faster than bottom-up algorithm \tpa when the error bound $\epsilon$~is large  (\eg in \geolife, $\epsilon >10$ metres when using \ped and $\epsilon >30$ metres when using \sed). When using \dad, the top-down algorithm is normally a bit slower than the bottom-up algorithm.
Top-down algorithms also run faster than bottom-up algorithms in high sampling datasets when using \ped or \sed.
%
(3) Online algorithms \opwa and \bqsa usually have better compression ratios than batch algorithms, the worst average errors, and poorer efficiency than batch algorithms. Algorithm \squishe is on the other side of \opwa and \bqsa.
%
(4) One-pass algorithms \operb, \siped, \cised, \intersec and \interval have good compression ratios (comparable with the best sub-optimal algorithms), poor average errors and the best efficiency.
%
The full $\epsilon$ \emph{sector/cone/range} combining with a position/direction constraint always have better compression ratios and also larger average errors than the half $\epsilon$ \emph{sector/cone/range}. %and they are comparable with the best sub-optimal algorithms.
%
One-pass algorithms show a linear running time and they are not very sensitive to error bound $\epsilon$, and also scale well with the increase of trajectory sizes.

%The average errors of algorithms as a whole are on the contrary of compression ratios. The optimal algorithm usually is the worst algorithm in term of average error, followed by one pass algorithms and then batch algorithms. Online algorithms have varied average errors, ranging from the best to the worst.


\stitle{Distance Metrics}.
The output sizes of algorithms using \sed are approximately twice of \ped, and in practice (\eg $\epsilon <100$ meters and $\epsilon < 60$ degrees), \ped and \sed usually bring obvious better compression ratios than \dad, especially in high sampling data sets.
%
The average errors of algorithms using \sed are a bit larger than using \ped.
%, and in practical, the average errors of algorithms using \dad, in terms of \ped, are obvious larger than algorithms using \ped and \sed.
%
Using \dad is in general faster than using \ped and \sed, and, indeed, the computation time of \ped and \sed is 2.3 and 1.7 times of \dad, respectively.



%%********************************* The End **********************************



\eat{%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\emph{\sstab{(1) Compression ratios}}.
The optimal algorithm is the best algorithm in term of compression ratio, and one-pass algorithms using full $\epsilon$ sector/cone/range are the most outstanding algorithms among all sub optimal algorithms, followed by batch algorithms. Online algorithms have varied compression ratios, ranging from the worst to the similar with batch and one-pass algorithms.
(a) When using \ped, the output data sizes of sub-optimal algorithms (\tpa,
\dpa, \bqsa, \siped, \operb) are on average ($125.67\%$, $130.24\%$, $115.94\%$, $139.41\%$, $141.15\%$)
of the optimal algorithm \opt, respectively.
%the compression ratios from the best to the worst are the optimal algorithm \opt, batch and online algorithms \tpa, \dpa and \bqsa, and one-pass algorithms \siped and \operb.
(b) When using \sed, the output data sizes of sub-optimal algorithms (\tpa,
\dpa, \squishe, \cised) are on average ($126.10\%$, $124.31\%$, $180.41\%$, $136.66\%$) of the optimal algorithm \opt, respectively.
%the compression ratios from the best to the worst are the near optimal algorithm \nopts, batch algorithms \tpa and \dpa, one-pass algorithm \cised, and online algorithm \squishe.
(c) When using \dad, the output data sizes of sub-optimal algorithms (\tpa,
\dpa, \interval) are on average ($103.22\%$, $109.95\%$, $102.83\%$) of the optimal algorithm \opt, respectively.

(d) The bottom-up (\tpa) and top-down (\dpa) algorithms have the similar compression ratios when using either \ped or \sed. The Bottom-up method has obviously better compression ratios than the top-down method when using \dad.
(e) For one-pass algorithms, the full $\epsilon$ sector/cone/range combining with a position/direction constraint always have better compression ratios than the half $\epsilon$ sector/cone/range versions in all datasets. %and they are comparable with the best sub optimal algorithms
(f) The output sizes of algorithms using \sed are approximately twice of \ped.
(g) In practical (\eg $\epsilon <100$ meters and $\epsilon < 60$ degrees), \ped and \sed usually bring obvious better compression ratios than \dad, especially in high sampling data sets.

\emph{\sstab{(2) Average errors}}. The average errors of these algorithms as a whole are on the contrary of compression ratios. The optimal algorithm usually is the worst algorithm in term of average error, followed by one pass algorithms and then batch algorithms. Online algorithms have varied average errors, ranging from the best to the worst.
(a) When using \ped, the average errors from the smallest to the largest are batch algorithms \tpa, \dpa, one-pass algorithms \siped and \operb, the optimal algorithm \opt, and online algorithm \bqsa.
(b) When using \sed, the average errors from the smallest to the largest are online algorithm \squishe, batch algorithms \tpa and \dpa, one-pass algorithm \cised, and the naive optimal algorithm \opt.
(c) When using \dad, the average errors from the smallest
to the largest are batch algorithms \dpa and \tpa, one-pass algorithm \interval, and the naive optimal algorithm \opt.
(d) Bottom-up algorithm (\tpa) and top-down algorithm (\dpa) have the similar average errors when using either \ped or \sed. Batch algorithm have pretty good average errors \wrt compression ratios compared with other algorithms. \todo{\dad}
(e) One-pass algorithms and online algorithms \opwa and \bqsa have large average errors due to the local distance checking approaches they applying.
(f) The average errors of algorithms using \sed are a bit larger than using \ped.
(g) In practical (\eg $\epsilon <100$ meters and $\epsilon < 60$ degrees), the average errors of algorithms using \dad, in terms of \ped, are obvious larger than algorithms using \ped and \sed.

\emph{\sstab{(3) Running time}}. The running time from the fastest to the slowest are one-pass algorithms, online and batch algorithms, and optimal algorithms.
(a) When using \ped, algorithms \siped and \operb are comparable, and algorithms
(\tpa, \dpa, \bqsa) are on average ($24.0$, $16.0$, $37.2$) times slower than the one-pass algorithms \siped, respectively.
%the running time from the smallest to the largest are one-pass algorithms \siped and \operb, and batch and online algorithms \tpa, \dpa and \bqsa.
(b) When using \sed, algorithms (\tpa, \dpa, \squishe) are on average ($11.6$, $14.4$, $2.6$) times slower than \cised, respectively.
%the running time from the smallest to the largest are one-pass algorithm \cised, online algorithm \squishe, and batch algorithms \tpa and \dpa.
(c) When using \dad, algorithms \tpa and \dpa are on average
$11.4$ and $15.0$ times slower than \ridad, respectively.
(d) The running time of batch algorithms \dpa and \tpa decreases and increases with the increase of error bound $\epsilon$, respectively. When using \ped or \sed, top-down algorithm \dpa usually runs faster than bottom-up algorithm \tpa when the error bound $\epsilon$~is large enough (\eg in \geolife, $\epsilon >10$ metres when using \ped and $\epsilon >30$ metres when using \sed). When using \dad, the top-down algorithm is normally a bit slower than the bottom-up algorithm.
Top-down algorithm runs faster than bottom-up algorithm in high sampling datasets when using \ped or \sed.
(e) Online algorithms \bqsa and \opwa both have poor efficiencies.
(f) One-pass algorithms \operb, \siped, \cised and \ridad show a linear running time and they are not very sensitive to error bound $\epsilon$, and also scale well with the increase of trajectory size on all datasets.
(g) The computing of a \dad is faster than \ped and \sed, and the running time of computing \ped and \sed are 2.3 and 1.7 times of \dad, respectively.

Note the findings of compression ratios and running time are not reported in \cite{Zhang:Evaluation}, and for average errors, the items (a),(b), (c) and (d) are concluded from more distinct error bounded \lsa algorithms, including \opt, \siped and \cised, and items (e), (f) and (g) are new findings.
}




