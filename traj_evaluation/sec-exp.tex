%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-1ex}
\section{Evaluation} %Experimental Study
\label{sec-exp}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In this section, we present an extensive experimental study of 11 representative \lsa algorithms on trajectory data sets.
Using 4 real-life datasets, we conducted 3 sets of experiments, each under varied error bounds $\epsilon$ and trajectory sizes, to evaluate the compression ratios, errors and execution time of these algorithms, and the impacts of 3 distance metrics, \ie \ped, \sed and \dad, to them.
%
%(1) the effectiveness of these algorithms, and
%(2) the efficiency of them.
%{An additional test of the effectiveness of near optimal algorithm (\nopts) is presented in Appendix B.}

\vspace{-1ex}
\subsection{Experimental Setting}
%We first introduce the settings of our experimental study.

\stitle{Real-life Trajectory Datasets}.
We use four varied real-life datasets shown in \mytable{tab:datasets}, namely, taxi trajectory data (\taxi) collected by a Beijing taxi company, Service car trajectory data (\ucar) collected by a Chinese car rental company, Geolife trajectory data (\geolife) collected in GeoLife project~\cite{Web:Geolife} and \mopsi trajectory data (\mopsi) collected in Mopsi project \cite{Web:Mopsi}, to evaluate those \lsa algorithms. These data sets have varied sampling rates, ranging from one point per minute to one point per second.
They also come from different sources, where \taxi and \ucar are collected by cars in urban, and \geolife and \mopsi are a mixing of cars and individuals. The data source and sampling rate also affect the performance of \lsa algorithms using certain distance metrics.

\begin{table}
	\vspace{-1ex}
	\caption{\small Real-life trajectory datasets}
	\centering
	\small
	\begin{tabular}{|l|c|c|c|r|}
		\hline
		\kw{Data}& \kw{Number\ of}     &\kw{Sampling}   &\kw{Points~Per}    &\kw{Total} \\
		\kw{Sets} & \kw{Trajectories}   &\kw{Rates (s)}  &\kw{Trajectory (K)}&\kw{points}\\	\hline
		\taxi	&{500}	    &60	        &{$\sim42.8$}      &{21.4M} \\	\hline
		%\truck	&10,368	    &1-60	    &$\sim71.9$     &746M \\	\hline
		%\ucar	&11,000	    &3-5	    &$\sim119.1$   &1.31G\\		\hline
		%
		\ucar	&200	    &3-5	&$\sim114.0$   &22.8M 	\\	\hline
		\geolife\cite{Web:Geolife} &182	    &1-5	&$\sim131.4$   &24.2M	\\	\hline
		\mopsi\cite{Web:Mopsi}	&51	    	&2	    &$\sim153.9$   &7.9M	\\	\hline
		%\act	& 10	    &1	    &$\sim11.8$    &112.8K	\\	\hline
	\end{tabular}
	\label{tab:datasets}
	\vspace{-3ex}
\end{table}


% \ni \emph{(1) Truck trajectory data} (\truck) is the GPS trajectories collected by \eat{10,368} trucks equipped with GPS sensors in China
% during a period from Mar. 2015 to Oct. 2015. The sampling rate varied from 1s to 60s.
%Trajectories mostly have around $50$ to $90$ thousand data points.

%\vspace{0.5ex}
%\ni \emph{(1) Service car trajectory data} (\ucar) is the GPS trajectories collected by a Chinese car rental company during Apr. 2015 to Nov. 2015. The sampling rate was one point per $3$--$5$ seconds, and each trajectory has around $114.1K$ points.
%.We randomly chose $1,000$ cars from them

%\vspace{0.5ex}
%\ni \emph{(2) GeoLife trajectory data} (\geolife) is the GPS trajectories collected in GeoLife project~\cite{Web:Geolife} by 182 users in a period from Apr. 2007 to Oct. 2011. These trajectories have a variety of sampling rates, among which 91\% are logged in each 1-5 seconds per point. %or each 5-10 meters
%This dataset contains 182 trajectories, one trajectory for each user, with a total distance of about 1.2 million kilometers.
%The longest trajectory has 2,156,994 points.

%\vspace{0.5ex}
%\ni \emph{(3) Mopsi trajectory data} (\mopsi) is the GPS trajectories collected in Mopsi project~\cite{Web:Mopsi} by 51 users in a period from 2008 to 2014. Most routes are in Joensuu region, Finland. The sampling rate was one point per $2$ seconds, and each trajectory has around $153.9K$ points.
%exist on every continent.

%\vspace{0.5ex}
%\ni \emph{(4) Act trajectory data} (\act) is a small set GPS trajectories collected with a high sampling rate of one point per second by our team members in 2017. There are 10 trajectories and each trajectory has around 11.8K points.

%The details of these datasets are shown in Table~\ref{tab:dataset}.

\stitle{Algorithms and implementation}.
We implement the representative algorithms selected from \mytable{tab:summary-lsa}. They are \opt, \dpa, \tpa, \opwa, \bqsa, \squishe, \operb, \siped, \cised, \intersec and \interval.
For one-pass algorithms \siped and \cised, we implement two versions of them, \ie the half and full \emph{Sectors/Cones}.
For algorithm \cised, we fixed parameter $m=16$ as evaluated in \cite{Lin:Cised}, \ie 16-edges inscribe regular polygon.
% For algorithm \nopts, we fixed parameter $m=32$.
All algorithms were implemented with Java.
All tests were run on an x64-based  PC with 4 Intel(R) Core(TM) i7-6700 CPU @
3.40GHz  and 8GB of memory, and {the max heap size of Java VM is 4GB.}
%, and each test was repeated over 3 times and the average is reported here.


\eat{%%%%%%%%%%%%%%%%%%%
	\stitle{Real-life Trajectory Datasets}.
	We use four real-life datasets shown in Table~\ref{tab:dataset} to test our solutions.
	
	\sstab{\bf(1) Taxi trajectory data}, referred to as \taxi, is the GPS trajectories collected by $12,727$ taxies equipped with GPS sensors in Beijing during a period
	from Nov. 1, 2010 to Nov. 30, 2010. The sampling rate was one point  per 60s, and \taxi has $39,100$ data points on average per trajectory.
	
	\sstab{\bf(2) Truck trajectory data}, referred to as \truck, is the GPS trajectories collected by 10,368 trucks equipped with GPS sensors in China
	during a period from Mar. 2015 to Oct. 2015. The sampling rate varied from 1s to 60s. Trajectories mostly have around $50$ to $90$ thousand data points.
	
	\sstab{\bf(3) Service car trajectory data}, referred to as \ucar,  is the GPS trajectories collected by a car rental company.
	We chose $11,000$ cars from them, during Apr. 2015 to Nov. 2015. The sampling rate was one point per $3$--$5$ seconds, and
	each trajectory has around $119.1K$ data points.
	
	{\sstab{\bf(4) GeoLife trajectory data}, referred to as \geolife, is the GPS trajectories collected in GeoLife project~\cite{Zheng:GeoLife} by 182 users in a period from Apr. 2007 to Oct. 2011. These trajectories have a variety of sampling rates, among which 91\% are logged in each 1-5 seconds or each 5-10 meters per point. The longest trajectory has 2,156,994 points.}
	%This dataset contains 182 trajectories, one trajectory for each user, with a total distance of about 1.2 million kilometers.
}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\subsection{Evaluation Metrics}
Compression ratios, errors and running time are the most popular metrics to evaluate \lsa algorithms.

\stitle{Compression ratios.}
Given a set of trajectories $\{\dddot{\mathcal{T}_1}, \ldots, \dddot{\mathcal{T}_M}\}$ and their piecewise line representations $\{\overline{\mathcal{T}_1}, \ldots, \overline{\mathcal{T}_M}\}$,
the compression ratio is $(\sum_{j=1}^{M} |\overline{\mathcal{T}}_j |)/(\sum_{j=1}^{M} |\dddot{\mathcal{T}}_j |)$.
By this definition, algorithms with lower compression ratios are better.

\stitle{Errors.}
All these algorithms in \mytable{tab:summary-lsa} are error bounded, \ie the max errors are approximate the values of error bounds. Hence, we only evaluate the average errors here. Given a set of trajectories $\{\dddot{\mathcal{T}_1}, \ldots, \dddot{\mathcal{T}_M}\}$ and their piecewise line representations
$\{\overline{\mathcal{T}_1}, \ldots, \overline{\mathcal{T}_M}\}$, and $P_{j,i}$ denoting
a point in trajectory $\dddot{\mathcal{T}}_j$ contained in a line segment $\mathcal{L}_{l,i}\in\overline{\mathcal{T}_l}$ ($l\in[1,M]$),
then the average error is $\sum_{j=1}^{M}\sum_{i=0}^{M} d(P_{j,i},
\mathcal{L}_{l,i})/\sum_{j=1}^{M}{|\dddot{\mathcal{T}}_j |}$.

\stitle{Running time.}
It is the time of compressing trajectories.
%We load and compress trajectories one by one, and only count the running time of the compressing process.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experimental Results}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%We next present our findings.
We test these algorithms under varied error bounds $\epsilon$ and trajectory sizes, respectively. We first varied $\epsilon$ from $10m$ to $100m$ in \ped and \sed (or from $15^o$ to $90^o$ in \dad) on the entire four datasets, respectively. We then chose $10$ trajectories from each dataset, and varied the size \trajec{|T|} of a trajectory from $1,000$ points to $10,000$ points while fixed the error bound $\epsilon=40$ metres or $\epsilon=45$ degrees.


\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-epsilon-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-epsilon-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-epsilon-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of compression ratios (\ped) on full datasets: varying the error bound $\epsilon$.}
	\label{fig:cr-ped-epsilon}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-epsilon-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-epsilon-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-epsilon-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of compression ratios (\sed) on full datasets: varying the error bound $\epsilon$.}
	\label{fig:cr-sed-epsilon}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-epsilon-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-epsilon-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-epsilon-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of compression ratios (\dad) on full datasets: varying the error bound $\epsilon$.}
	\label{fig:cr-dad-epsilon}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-size-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-CR-size-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of compression ratios (\ped) on small datasets: varying the size of
    trajectories.}
  \label{fig:cr-ped-size}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-size-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-CR-size-mopsi.png}		
	\vspace{-3ex}

	\caption{\small Evaluation of compression ratios (\sed) on small datasets: varying the size of
    trajectories.}
  \label{fig:cr-sed-size}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-size-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-CR-size-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of compression ratios (\dad) on small datasets: varying the size of trajectories.}
	\label{fig:cr-dad-size}
	\vspace{-3ex}
\end{figure*}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-1ex}
\subsubsection{Compression Ratio Evaluation and Analyses}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\eat{%%%%%%%
We first test the compression ratios of these algorithms under varied error bounds $\epsilon$ and trajectory sizes, respectively. We varied $\epsilon$ from $10m$ to $100m$ in \ped and \sed (or from $15^o$ to $90^o$ in \dad) on the entire four datasets, respectively. The results are reported in Figure~\ref{fig:cr-ped-epsilon}, Figure~\ref{fig:cr-sed-epsilon} and Figure~\ref{fig:cr-dad-epsilon} ({Note that the naive optimal algorithm using \sed or \dad is not reported here because it can not run with the full dataset as input}).
%
We then chose $10$ trajectories from each dataset \taxi, \ucar, \geolife and \mopsi, respectively, and varied the size \trajec{|T|} of a trajectory from $1,000$ points to $10,000$ points, while fixed error bound $\epsilon = 60$ meters for \ped and \sed ({or $\epsilon = 45$ degrees for \dad}).
The experimental results are reported in Figure~\ref{fig:cr-ped-size}, Figure~\ref{fig:cr-sed-size} and Figure~\ref{fig:cr-dad-size}.
}%%%%%%%%%%%

%We test the compression ratios of these algorithms under varied error bounds $\epsilon$ and trajectory sizes, respectively.
The compression ratios of these algorithms under varied error bounds $\epsilon$ and trajectory sizes are reported in Figure~\ref{fig:cr-ped-epsilon}, Figure~\ref{fig:cr-sed-epsilon}, Figure~\ref{fig:cr-dad-epsilon}, Figure~\ref{fig:cr-ped-size}, Figure~\ref{fig:cr-sed-size} and Figure~\ref{fig:cr-dad-size}.
{Note that the optimal algorithm using \sed or \dad is not reported in Figure~\ref{fig:cr-ped-epsilon}, Figure~\ref{fig:cr-sed-epsilon}, Figure~\ref{fig:cr-dad-epsilon} because it runs out of memory taking the full dataset as input}. From them, we have the following straight-forward findings.

%%%%%%%%%%%%%%%%%
\sstab(1) The compression ratios of algorithms using \ped from the best
to the worst are the optimal algorithm \opt, online algorithm \bqsa, one-pass algorithm \siped($\epsilon$), batch algorithms \tpa and
\dpa, and one-pass algorithms \siped($\frac{\epsilon}{2}$) and \operb.
The output sizes of algorithms \bqsa and \siped({$\epsilon$}) are on average
($103.58\%$, $113.32\%$, $120.22\%$, $120.83\%$) and ($?\%$, $?\%$, $?\%$, $?\%$) of the optimal algorithm \opt
on datasets \dSets, respectively.
Algorithms \tpa and \dpa are comparable, and their output sizes are on average
($103.17\%$, $125.05\%$, $131.01\%$, $138.01\%$) and ($106.98\%$, $130.03\%$, $140.56\%$, $139.00\%$) of \opt
on datasets \dSets, respectively.
Algorithms \siped($\frac{\epsilon}{2}$) and \operb are comparable, and they are on average
($113.09\%$, $136.73\%$, $150.23\%$, $152.29\%$)
and ($119.89\%$, $143.14\%$, $147.80\%$, $152.37\%$) of \opt on datasets \dSets, respectively.
%
For example, in \mopsi, the compression ratios of algorithms
(\opt, \tpa, \dpa, \bqsa, \siped(${\epsilon}$), \siped($\frac{\epsilon}{2}$), \operb ) are ($1.6\%$, $2.2\%$, $2.2\%$, $1.9\%$, $?\%$, $2.4\%$, $2.4\%$) when $\epsilon$ = $40m$.
%

%%%%%%%%%%%%%%%%%
\sstab(2) The compression ratios of algorithms using \sed from the best
to the worst are the optimal algorithm \opt, one-pass algorithm \cised($\epsilon$), batch algorithms \tpa and
\dpa, one-pass algorithm \cised($\frac{\epsilon}{2}$), and online algorithm \squishe.
%
{Algorithms \tpa and \dpa are comparable, and they are on average
($102.72\%$, $125.23\%$, $143.92\%$, $128.63\%$) and ($103.18\%$, $123.93\%$, $141.46\%$, $121.14\%$)
 of the optimal algorithm \opt on datasets \dSets, respectively.}
%
{Algorithms \cised(${\epsilon}$), \cised($\frac{\epsilon}{2}$) and \squishe are on average ($?\%$,
  $?\%$, $?\%$, $?\%$), ($108.00\%$,
  $134.35\%$, $159.30\%$, $136.06\%$) and ($110.27\%$, $165.94\%$, $225.68\%$, $206.90\%$)
 of \opt on datasets \dSets, respectively.}
%
For example, in \mopsi, the compression ratios of algorithms
(\tpa, \dpa, \squishe, \cised(${\epsilon}$), \cised($\frac{\epsilon}{2}$))
are ($3.45\%$, $3.41\%$, $5.75\%$, $?\%$, $3.86\%$), respectively, when $\epsilon$ = $40m$.
%
%Algorithms \tpa and \dpa are comparable, and they are on average ($122.69\%$, $129.08\%$, $131.97\%$, $131.01\%$) and ($121.36\%$, $129.27\%$, $130.11\%$, $126.21\%$) of the near optimal algorithm \nopts on datasets \dSets, respectively.
%Algorithms \cised and \squishe are on average ($132.07\%$, $139.67\%$, $146.56\%$, $135.10\%$) and ($164.47\%$, $189.87\%$, $213.30\%$, $186.72\%$) of \nopts on datasets \dSets, respectively.
%
%For example, in \mopsi, the compression ratios of algorithms (\nopts, \tpa, \dpa, \squishe, \cised) are ($2.62\%$, $3.45\%$, $3.41\%$, $5.75\%$, $3.86\%$), respectively, when $\epsilon$ = $40m$.
%

%%%%%%%%%%%%%%%%%
\sstab(3) The compression ratios of algorithms using \dad from the best
to the worst are the optimal algorithm \opt, batch algorithm \tpa and
one-pass algorithm \interval, one-pass algorithm \intersec and batch algorithm \dpa.
%
{Algorithms \tpa and \interval are comparable, and they are on average
($100.81\%$, $102.91\%$, $102.27\%$, $106.88\%$) and ($102.38\%$, $101.98\%$, $103.52\%$, $103.43\%$)
 of the optimal algorithm \opt on datasets \dSets, respectively.}
%
{Algorithms \intersec and \dpa are on average ($?\%$, $?\%$, $?\%$, $?\%$) and ($133.19\%$, $283.93\%$, $143.79\%$, $278.89\%$)
 of the optimal algorithm \opt on datasets \dSets, respectively.}
%
For example, in \mopsi, the compression ratios of algorithms (\tpa, \dpa, \interval, \intersec)
are ($13.3\%$, $23.1\%$, $13.7\%$, $?\%$), respectively, when $\epsilon$ = $45$ degrees.
%


We then discuss some extended findings from the views of \lsa algorithms and distance metrics.

\stitle{Extended analyses of \lsa algorithms}. The optimal algorithm is the best algorithm in term of compression ratio, and one pass algorithms using full $\epsilon$ sector/cone/range are the most outstanding algorithms among all sub optimal algorithms, followed by batch algorithms. Online algorithms have varied compression ratios, ranging from the worst to the similar with batch and one-pass algorithms.

%\todo{Batch: Bottom-up vs Top-down.}
For batch algorithms, the bottom-up algorithm (\tpa) and top-down algorithm (\dpa) have the similar compression ratios when using either \ped or \sed. However, when using \dad, bottom-up method has obviously better compression ratios than top-down method. We note that the experimental results of \cite{Long:Direction} also show this phenomenon (but without discuss). As we know the top-down algorithm will split a long trajectory $[P_s, ..., P_e]$ into two sub trajectories by finding out a splitting point $P_i (s<i<e)$ who has the max position deviation (or whose line segment $\vv{P_{i-1}P_{i}}$ has the max direction deviation) to line segment $\vv{P_sP_{e}}$. Through this strategy works well with \ped and \sed, a point with the max direction deviation may not be a reasonable splitting point in the direction-aware scenario. Thus it leads to a poorer compression ratio. The bottom-up method does not have this weakness as it always merges neighbouring points.



%\todo{Online: }
For online algorithms, \bqsa and \opwa are comparable with the best sub-optimal algorithms. This is because \opwa is indeed a combination of \dpa and opening window, and \bqsa is mainly an efficiency optimization of the \opwa.
\squishe has the poorest compression ratio among all algorithms using \sed. This is the result of its mechanism: \squishe estimates the lowest \sed error and removes the point with is ``predicted to introduce the lowest amount of error into the compression"\cite{Muckell:SQUISH}. Its ``prediction" method is not accurate enough, thus, in order to ensure the error bound, it may ignore too many potential points that could be represented by a line segment.

%\todo{One pass: half $\epsilon$ vs full $\epsilon$.}
For one-pass algorithms, the full $\epsilon$ sector/cone/range combining with a position/direction constraint always have better compression ratios than the half $\epsilon$ sector/cone/range versions in all datasets, and they are comparable with the best sub optimal algorithms.
This may be related to the moving habits or patterns of moving objects that engender trajectories.
A moving object, like an individual or a car, usually keeps moving forward for quite a long time, engendering a sequence of data points distributing in a narrow strip. Under such circumstance, a new data point is quite possible living in the common intersection of larger sectors/cones/ranges, which further leads to a better compression ratio.
%which lets more data points be represented by a result line segment.
\todo{strict proof?}
%combining with a constraint that the current point should live in the common intersection of preview sectors/cones/ranges



\stitle{Extended analyses of distance metrics}.
Though \ped, \sed and \dad are different distances, we can still compare them from the view of compression ratio, so as to help choose an effective distance metric.
%whose usages are mainly decided by application requirements
%
First, given the same error bound $\epsilon$, the compression ratios of algorithms using \ped are obviously better
than using \sed. More specifically, \emph{the output sizes of using \sed are approximately twice of \ped.}
%
As shown in Figure~\ref{fig:cr-ped-epsilon} and Figure~\ref{fig:cr-sed-epsilon}, the output sizes of algorithms \tpa and \dpa
using \ped are on average ($55.08\%$, $43.55\%$, $47.49\%$, $63.15\%$) and ($56.75\%$, $45.79\%$,
$50.88\%$, $64.50\%$) of algorithms \tpa and \dpa using \sed on datasets \dSets, respectively.
%
%and in Figure~\ref{fig:cr-ped-size} and Figure~\ref{fig:cr-sed-size}, the compression ratios of algorithms \opt, \tpa and \dpa using \ped are on average {($56.03\%$, $33.42\%$, $33.12\%$, $72.42\%$),	($55.78\%$, $31.88\%$, $34.27\%$, $69.44\%$) and ($58.09\%$, $34.82\%$,	$40.91\%$, $75.06\%$)} of algorithms \opt, \tpa and \dpa using \sed on datasets \dSets, respectively.
%
This result shows ~\sed saves temporal information at a cost of saving more points.


Secondly, in practical (\eg $\epsilon <100$ meters and $\epsilon < 60$ degrees), \sed have obviously better compression ratios than \dad in datasets \geolife and \mopsi, a bit better than \dad in \taxi and a bit poorer than \dad in \ucar.
This is because some \geolife and \mopsi trajectories are collected by individuals that are in transportation modes of walking, running and riding, and moving objects in those modes may change their directions with a considerable range (\eg large than $60$ degrees) more frequently than cars in urban. Moreover, \geolife and \mopsi have higher sampling rates than \taxi and \ucar, which will capture more direction changes, \ie direction changes in a small time interval.

%It seems that it is a normal phenomenon that a moving object frequently changes its direction with a considerable range (\eg large than $60$ degrees) during a trip.




\eat{

\sstab (1) Trajectory sizes have few impacts on compression ratios.

\sstab (1) When increasing $\epsilon$, the compression ratios decrease.
%For example, in \mopsi, the compression ratios are greater than {$4\%$} when $\epsilon$ = $10m$, and less than {$2\%$} when $\epsilon$ = $100m$.

\sstab (2) Dataset \mopsi usually has the lowest compression ratios, compared with \taxi, \ucar and \geolife, due to its highest sampling rate, \taxi has the highest compression ratios due to its lowest sampling rate, and \ucar and \geolife and  have the compression ratios in the middle accordingly.
}


\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-epsilon-taxi.png} \hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-epsilon-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-epsilon-mopsi.png}	
	\vspace{-3ex}
	\caption{\small Evaluation of average errors (\ped) on full datasets: varying the error bound $\epsilon$.}
	\label{fig:ae-ped-epsilon}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-epsilon-taxi.png} \hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-epsilon-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-epsilon-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of average errors (\sed) on full datasets: varying the error bound $\epsilon$.}
	\label{fig:ae-sed-epsilon}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-epsilon-taxi.png} \hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-epsilon-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-epsilon-mopsi.png}	
	\vspace{-3ex}
	\caption{\small Evaluation of average errors (\dad) on full datasets: varying the error bound $\epsilon$.}
	\label{fig:ae-dad-ped-epsilon}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-size-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-error-size-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of average errors (\ped) on small datasets: varying the size of
    trajectories.}
  \label{fig:ae-ped-size}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-size-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-error-size-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of average errors (\sed) on small datasets: varying the size of
    trajectories.}
  \label{fig:ae-sed-size}
	\vspace{-2ex}
\end{figure*}


\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-size-taxi.png} \hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-size-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-error-size-mopsi.png}	
	\vspace{-3ex}
	\caption{\small Evaluation of average errors (\dad) on small datasets: varying the size of trajectories.}
	\label{fig:ae-dad-ped-size}
	\vspace{-2ex}
\end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.5ex}
\subsubsection{Average Error Evaluation and Analyses}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The average errors of these algorithms under varied error bounds $\epsilon$ and trajectory sizes are reported in Figure~\ref{fig:ae-ped-epsilon}, Figure~\ref{fig:ae-sed-epsilon}, Figure~\ref{fig:ae-dad-ped-epsilon}, Figure~\ref{fig:ae-ped-size}, Figure~\ref{fig:ae-sed-size} and Figure~\ref{fig:ae-dad-ped-size}.


\sstab (1) When using \ped, the average errors from the smallest
to the largest are batch algorithms \tpa and \dpa, one-pass
algorithms \siped($\frac{\epsilon}{2}$) and \operb, the optimal algorithm \opt and one-pass algorithm \siped(${\epsilon}$), and online algorithm \bqsa.
%
In full datasets, algorithms \tpa and \dpa are comparable, and they are on average ($77.43\%$, $58.69\%$, $61.34\%$,
$57.57\%$) and ($88.12\%$, $57.61\%$, $62.66\%$, $60.23\%$) of the optimal algorithm \opt on datasets \dSets, respectively.
Algorithms \siped($\frac{\epsilon}{2}$) and \operb are comparable, and they are on average
($73.08\%$, $80.96\%$, $79.12\%$, $79.33\%$), ($73.03\%$, $70.60\%$, $76.64\%$, $78.71\%$) of \opt on datasets \dSets, respectively.
%
Algorithms \siped(${\epsilon}$) and \bqsa are on average ($?\%$, $?\%$, $?\%$, $?\%$) and ($97.69\%$, $104.67\%$, $108.91\%$, $106.92\%$) of \opt on datasets \dSets, respectively.
For example, the average errors of algorithms
(\opt, \tpa, \dpa, \bqsa, \siped(${\epsilon}$), \siped($\frac{\epsilon}{2}$), \operb ) in full \mopsi are ($16.08$, $9.19$, $9.68$, $17.4$, $12.96$, $?$, $12.77$) metres when $\epsilon$ = $40m$.

\eat{
In Figure~\ref{fig:ae-ped-size}, algorithms \tpa and \dpa are comparable, and they are on average
{($105.94\%$, $53.16\%$, $66.84\%$, $61.50\%$), ($111.96\%$, $52.04\%$, $78.65\%$, $60.57\%$)} of \opt on datasets \dSets, respectively.
Algorithms \siped($\frac{\epsilon}{2}$) and \operb are on average {($85.30\%$, $73.55\%$, $82.01\%$,
  $85.23\%$), ($97.69\%$, $67.20\%$, $82.58\%$, $81.88\%$)}
of \opt on datasets \dSets, respectively.
Algorithm \bqsa is  on average  {($108.51\%$, $102.06\%$, $104.63\%$, $113.80\%$)}
of \opt on datasets \dSets, respectively.
}

\sstab (2) When using \sed, the average errors from the smallest
to the largest are online algorithm \squishe, batch algorithms \tpa and \dpa,
one-pass algorithm \cised($\frac{\epsilon}{2}$), and one pass algorithms \cised(${\epsilon}$) and the optimal algorithm \opt.
%
Algorithms \tpa and \dpa are comparable, and they are on average
{($87.22\%$, $60.36\%$, $66.11\%$, $62.43\%$), ($91.04\%$, $62.54\%$, $67.04\%$, $68.64\%$)} of \opt on datasets \dSets, respectively.
Algorithms \cised($\frac{\epsilon}{2}$) and \squishe are on average {($73.15\%$, $75.29\%$, $76.03\%$, $81.44\%$), ($46.27\%$, $40.61\%$, $38.15\%$, $34.22\%$)} of \opt on datasets \dSets, respectively.
%
For example, the average errors of algorithms
(\opt, \tpa, \dpa, \squishe, \cised(${\epsilon}$), \cised($\frac{\epsilon}{2}$)) in full \mopsi are ($?$, $12.17$, $12.20$, $6.76$, $?$, $14.71$) metres, respectively, when $\epsilon$ = $40m$.
%


\sstab {(3) When using \dad, the average errors from the smallest
to the largest are batch algorithms \dpa and \tpa, one-pass algorithm \interval, and the optimal algorithm \opt.
\eat{
For example, in Figure~\ref{fig:ae-dad-ped-epsilon}, in \mopsi, the average errors of algorithms
(\tpa, \dpa, \interval) in terms of \ped are ($65.6$, $75.4$, $68.1$) meters, respectively, when $\epsilon$ = $45$ degrees.
It is also worth pointing out that the max errors of algorithms
(\tpa, \dpa, \interval) using \dad may be very large in terms of \ped, \eg they are ($68247.9$, $66794.4$, $68247.9$) meters, respectively, when $\epsilon$ = $45$ degrees.}
}
Algorithms \tpa and \interval are comparable, and they are on average
{($88.94\%$, $91.35\%$, $61.45\%$, $73.71\%$) and ($93.97\%$, $90.36\%$, $68.23\%$, $163.47\%$)} of algorithm \opt on datasets \dSets, respectively.
Algorithms \intersec and \dpa are on average ($?\%$, $?\%$, $?\%$, $?\%$) and ($76.86\%$, $82.45\%$, $96.52\%$, $137.95\%$) of \opt on datasets \dSets, respectively.



%We next discuss our findings also from the views of \lsa algorithms and distance metrics.

\stitle{Extended analyses of \lsa algorithms}. The average errors of these algorithms as a whole are on the contrary of compression ratios. The optimal algorithm usually is the worst algorithm in term of average error, followed by one-pass algorithms and then batch algorithms.
Online algorithms have varied average errors, ranging from the best to the worst.
(1) For batch algorithms, bottom-up algorithm (\tpa) and top-down algorithm (\dpa) have the similar average errors when using either \ped or \sed as well as they have the similar compression ratios. Batch algorithm have pretty good average errors \wrt compression ratios compared with other algorithms. \todo{\dad}
%
(2) For one-pass algorithms, the full $\epsilon$ sector/cone/range combining with a position/direction constraint always have larger average errors than the half $\epsilon$ sector/cone/range versions in all datasets. Anyway, the local distance checking approaches try to include more points into a line segment, this greedy strategy is likely leading to larger average errors, considerable larger than batch algorithms that have the similar compression ratios as one pass algorithms.
%
(3) Online algorithms, \bqsa and \opwa, often have the largest average errors in all sub-optimal algorithms, while \squishe has the smallest. This is also on the contrary of their compression ratios.



\stitle{Extended analyses of distance metrics}.
Given the same error bound $\epsilon$, the average errors of algorithms using \sed are a bit larger than using \ped. {As we know the \ped error is caused by the changes of direction of a moving object while the \sed error is caused by the changes of both the direction and the speed of a moving object, the above phenomenon probably reveals that the changes of speed is more often than the changes of direction of a moving object.}
%
And in practical (\eg $\epsilon = 60$ meters and $\epsilon = 45$ degrees), the average errors of algorithms using \dad, when translated to position errors like \ped, are likely $10$ times larger than algorithms directly using \ped and \sed. It is clearly a small direction deviation plus a long trip may lead to a large position error.




\eat{
\sstab (1) When increasing $\epsilon$, the average errors increase linearly.

\sstab (2) Datasets have few impacts on the average errors.

\sstab (1) Trajectory sizes have few impacts on average errors.

\sstab (2) The average errors in this test are consistent with test Exp-2.1.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-1ex}
\subsubsection{Running Time Evaluation and Analyses}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We finally compare the running time of these algorithms.
The results are reported in Figure~\ref{fig:time-epsilon-ped}, Figure~\ref{fig:time-epsilon-sed}, Figure~\ref{fig:time-epsilon-dad}, Figure~\ref{fig:time-size-ped}, Figure~\ref{fig:time-size-sed} and Figure~\ref{fig:time-size-dad}.
Note that even on the small datasets, the running time of the \opt algorithm is thousands of times slower than one-pass algorithms on our datasets. Indeed, it is not easy to show all these algorithms in a figure, thus, only the results of sub-optimal algorithms are reported in these figures.

\sstab (1) When using \ped, in most cases, the running time from the smallest to the largest are one-pass algorithms \siped and \operb, batch algorithms \tpa and \dpa, and online algorithm \bqsa.
Algorithms \siped($\frac{\epsilon}{2}$) and \operb are comparable, algorithm \siped(${\epsilon}$) is a bit slower than \siped($\frac{\epsilon}{2}$), and algorithms \tpa, \dpa and \bqsa are on average
($19.19$, $26.79$, $28.25$, $29.87$), ($17.90$, $16.32$, $15.40$, $11.02$) and ($15.07$, $37.73$, $62.23$, $61.29$)
times slower than the one-pass algorithm \siped($\frac{\epsilon}{2}$) on datasets \dSets, respectively.
%
For example, in \mopsi, the running time of algorithms
(\tpa, \dpa, \bqsa, \siped(${\epsilon}$), \siped($\frac{\epsilon}{2}$), \operb ) are ($232.9$, $124.2$, $469.4$, $?$, $7.6$, $8.6$) seconds when $\epsilon$ = $40m$.

\sstab (2) When using \sed, the running time from the smallest to the largest are one-pass algorithm \cised, online algorithm \squishe, and batch algorithms \tpa and \dpa. Algorithm \cised(${\epsilon}$) is also a bit slower than \cised($\frac{\epsilon}{2}$), and algorithms \tpa, \dpa and \squishe are on average
($8.58$, $13.33$, $15.81$, $13.09$), ($12.81$, $12.93$, $10.64$, $8.79$) and
($2.63$, $2.75$, $2.78$, $2.57$) times slower than \cised($\frac{\epsilon}{2}$) on datasets \dSets, respectively.
%
For example, in \mopsi, the running time of algorithms
(\tpa, \dpa, \squishe, \cised($\epsilon$), \cised($\frac{\epsilon}{2}$)) are ($156.6$, $104.8$, $27.2$, $?$, $9.7$) seconds when $\epsilon$ = $40m$.

\sstab {(3) When using \dad,} the running time from the smallest to the
largest are one-pass algorithms \intersec and \interval, and batch algorithms \tpa and \dpa.
%
%Algorithm \interval is a bit slower than \intersec, and algorithms \tpa and \dpa are on average
%($6.66$, $13.55$, $12.73$, $12.73$) and ($11.67$, $14.24$, $16.51$, $17.59$)
%times slower than \interval on datasets \dSets, respectively.
%
Algorithm \interval is a bit slower than \intersec, and algorithms \tpa and \dpa are on average
($?$, $?$, $?$, $?$) and ($?$, $?$, $?$, $?$)
times slower than \intersec on datasets \dSets, respectively.
%
For example, the running time of algorithms
(\tpa, \dpa, \interval, \intersec) are ($105.57$, $152.53$, $8.57$, $?$) seconds in \mopsi when
$\epsilon=45$ degrees, respectively.



%\sstab (2) When using \ped, the running time from the smallest to the largest are one-pass algorithms \siped and \operb, and batch and online algorithms \tpa, \dpa and \bqsa. Algorithms \siped and \operb are comparable. Algorithms \tpa, \dpa and \bqsa are comparable, and they are on average \textcolor{red}{($3.8$--$5.3$, $3.5$--$4.8$, $4.6$--$7.2$, $6.2$--$8.4$)} times slower than the one-pass algorithms \siped and \operb on datasets \dSets, respectively.

%\sstab (3) When using \sed, the running time from the smallest to the largest are one-pass algorithm \cised, online algorithm \squishe, and batch algorithms \tpa and \dpa.  Algorithms \squishe, \tpa and \dpa are on average \textcolor{red}{($9.6$--$17.6$, $8.8$--$15.4$, $8.4$--$16.3$, $9.0$--$14.4$)}, \textcolor{red}{($9.6$--$17.6$, $8.8$--$15.4$, $8.4$--$16.3$, $9.0$--$14.4$)} and \textcolor{red}{($9.6$--$17.6$, $8.8$--$15.4$, $8.4$--$16.3$, $9.0$--$14.4$)} times slower than \cised on datasets \dSets, respectively.

%\sstab (4) Batch algorithms \dpa and \tpa using \sed run a bit faster than using \ped, while the one-pass algorithm \cised run \textcolor{red}{$2.0$--$3.0$} times slower than \siped and \operb.




\stitle{Extended analyses of \lsa algorithms.}
The running time from the fastest to the slowest are one-pass algorithms, online and batch algorithms, and optimal algorithms.

For batch algorithms, the running time of algorithms \dpa and \tpa decreases and increases with the increase of error bound $\epsilon$, respectively, due to the top-down and bottom-up approaches they applying. When using \ped or \sed, top-down algorithm usually runs faster than bottom-up algorithm when the error bound $\epsilon$~is large enough (\eg in \geolife, $\epsilon >10$ metres when using \ped and $\epsilon >30$ metres when using \sed), which means that top-down (bottom-up) algorithm needs to split (merge) the original trajectory fewer (more) times in these cases, vice versa. When using \dad, recall the top-down algorithm has poorer compression ratios compared with bottom-up algorithm, meaning it needs more time to split the raw trajectory into more sub trajectories, thus, the top-down algorithm is normally a bit slower than the bottom-up algorithm.
Besides error bounds, datasets also impact the efficiencies of batch algorithms. A dataset with high sampling rate likely needs more merging processes than splitting processes, thus, top-down algorithm runs faster than bottom-up algorithm in high sampling datasets when using \ped or \sed.

For online algorithm \squishe is faster than \bqsa and \opwa at a cost of poorer compression ratios. Note it is still times slower than one pass algorithms. \bqsa and \opwa both have poor efficiencies as they finally need the batch approach. Even this batch approach is run in a buffer, it is still time consuming.

One-pass algorithms \operb, \siped, \cised and \interval show a linear running time which is consistent with their time complexity analyses. They are not very sensitive to error bound $\epsilon$, and also scale well with the increase of trajectory size on all datasets as a data point is processed only one time during the whole process.
Among these one pass algorithms, \siped, \operb and \interval have the similar running time, and algorithm \cised runs a bit slower than them, partially because finding the common intersection of spatial-temporal cones is a heavier work than sectors or ranges.


\stitle{Extended analyses of distance metrics.}
Our tests also show that the computing of a \dad is faster than \ped and \sed, and the running time of computing \ped and \sed are 2.3 and 1.7 times of \dad, respectively.
{It is also worth pointing out that the algorithm \dpa using \ped, \sed and \dad have the similar running time in all datasets, though the computing of \ped is more heavy than \sed and \dad. The reason is \dpa using \ped has the best compression ratios which instead leads to the least splitting processes in the top-down manner. Combining these two factors, \ie the computing of distance/direction deviation and the processing of trajectory splitting, finally, \dpa using \ped has the similar running time as \dpa using \dad or \sed.}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-epsilon-taxi.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-epsilon-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-epsilon-mopsi.png}	\hspace{1ex}
	\vspace{-3ex}
	\caption{\small Evaluation of running time (\ped) on full datasets: varying the error bound $\epsilon$.}\label{fig:time-epsilon-ped}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-epsilon-taxi.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-epsilon-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-epsilon-mopsi.png}	\hspace{1ex}
	\vspace{-3ex}
	\caption{\small Evaluation of running time (\sed) on full datasets: varying the error bound $\epsilon$.}\label{fig:time-epsilon-sed}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-epsilon-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-epsilon-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-epsilon-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-epsilon-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of running time (\dad) on full datasets: varying the error bound $\epsilon$.}\label{fig:time-epsilon-dad}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-size-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-PED-time-size-mopsi.png}	\hspace{1ex}
	\vspace{-3ex}
	\caption{\small Evaluation of running time (\ped) on small datasets: varying the size of trajectories.}\label{fig:time-size-ped}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-size-service.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-SED-time-size-mopsi.png}	\hspace{1ex}
	\vspace{-3ex}
	\caption{\small Evaluation of running time (\sed) on small datasets: varying the size of trajectories.}\label{fig:time-size-sed}
	\vspace{-2ex}
\end{figure*}

\begin{figure*}[tb!]
	\centering
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-size-taxi.png}\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-size-service.png} 	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-size-geolife.png}	\hspace{1ex}
	\includegraphics[scale=0.315]{Figures/Exp-DAD-time-size-mopsi.png}		
	\vspace{-3ex}
	\caption{\small Evaluation of running time (\dad) on small datasets: varying the size of trajectories.}\label{fig:time-size-dad}
	\vspace{-2ex}
\end{figure*}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\stitle{Summary}.
\subsubsection{Summary}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
From these tests we find the following.

\emph{\sstab{(1) Compression ratios}}.
The optimal algorithm is the best algorithm in term of compression ratio, and one-pass algorithms using full $\epsilon$ sector/cone/range are the most outstanding algorithms among all sub optimal algorithms, followed by batch algorithms. Online algorithms have varied compression ratios, ranging from the worst to the similar with batch and one-pass algorithms.
(a) When using \ped, the output data sizes of sub-optimal algorithms (\tpa,
\dpa, \bqsa, \siped, \operb) are on average ($125.67\%$, $130.24\%$, $115.94\%$, $139.41\%$, $141.15\%$)
of the optimal algorithm \opt, respectively.
%the compression ratios from the best to the worst are the optimal algorithm \opt, batch and online algorithms \tpa, \dpa and \bqsa, and one-pass algorithms \siped and \operb.
(b) When using \sed, the output data sizes of sub-optimal algorithms (\tpa,
\dpa, \squishe, \cised) are on average ($126.10\%$, $124.31\%$, $180.41\%$, $136.66\%$) of the optimal algorithm \opt, respectively.
%the compression ratios from the best to the worst are the near optimal algorithm \nopts, batch algorithms \tpa and \dpa, one-pass algorithm \cised, and online algorithm \squishe.
(c) When using \dad, the output data sizes of sub-optimal algorithms (\tpa,
\dpa, \interval) are on average ($103.22\%$, $109.95\%$, $102.83\%$) of the optimal algorithm \opt, respectively.
(d) The bottom-up (\tpa) and top-down (\dpa) algorithms have the similar compression ratios when using either \ped or \sed. The Bottom-up method has obviously better compression ratios than the top-down method when using \dad.
(e) For one-pass algorithms, the full $\epsilon$ sector/cone/range combining with a position/direction constraint always have better compression ratios than the half $\epsilon$ sector/cone/range versions in all datasets. %and they are comparable with the best sub optimal algorithms
(f) The output sizes of algorithms using \sed are approximately twice of \ped.
(g) In practical (\eg $\epsilon <100$ meters and $\epsilon < 60$ degrees), \ped and \sed usually bring obvious better compression ratios than \dad, especially in high sampling data sets.

\emph{\sstab{(2) Average errors}}. The average errors of these algorithms as a whole are on the contrary of compression ratios. The optimal algorithm usually is the worst algorithm in term of average error, followed by one pass algorithms and then batch algorithms. Online algorithms have varied average errors, ranging from the best to the worst.
(a) When using \ped, the average errors from the smallest to the largest are batch algorithms \tpa, \dpa, one-pass algorithms \siped and \operb, the optimal algorithm \opt, and online algorithm \bqsa.
(b) When using \sed, the average errors from the smallest to the largest are online algorithm \squishe, batch algorithms \tpa and \dpa, one-pass algorithm \cised, and the naive optimal algorithm \opt.
(c) When using \dad, the average errors from the smallest
to the largest are batch algorithms \dpa and \tpa, one-pass algorithm \interval, and the naive optimal algorithm \opt.
(d) Bottom-up algorithm (\tpa) and top-down algorithm (\dpa) have the similar average errors when using either \ped or \sed. Batch algorithm have pretty good average errors \wrt compression ratios compared with other algorithms. \todo{\dad}
(e) One-pass algorithms and online algorithms \opwa and \bqsa have large average errors due to the local distance checking approaches they applying.
(f) The average errors of algorithms using \sed are a bit larger than using \ped.
(g) In practical (\eg $\epsilon <100$ meters and $\epsilon < 60$ degrees), the average errors of algorithms using \dad, in terms of \ped, are obvious larger than algorithms using \ped and \sed.

\emph{\sstab{(3) Running time}}. The running time from the fastest to the slowest are one-pass algorithms, online and batch algorithms, and optimal algorithms.
(a) When using \ped, algorithms \siped and \operb are comparable, and algorithms
(\tpa, \dpa, \bqsa) are on average ($24.0$, $16.0$, $37.2$) times slower than the one-pass algorithms \siped, respectively.
%the running time from the smallest to the largest are one-pass algorithms \siped and \operb, and batch and online algorithms \tpa, \dpa and \bqsa.
(b) When using \sed, algorithms (\tpa, \dpa, \squishe) are on average ($11.6$, $14.4$, $2.6$) times slower than \cised, respectively.
%the running time from the smallest to the largest are one-pass algorithm \cised, online algorithm \squishe, and batch algorithms \tpa and \dpa.
(c) When using \dad, algorithms \tpa and \dpa are on average
$11.4$ and $15.0$ times slower than \ridad, respectively.
(d) The running time of batch algorithms \dpa and \tpa decreases and increases with the increase of error bound $\epsilon$, respectively. When using \ped or \sed, top-down algorithm \dpa usually runs faster than bottom-up algorithm \tpa when the error bound $\epsilon$~is large enough (\eg in \geolife, $\epsilon >10$ metres when using \ped and $\epsilon >30$ metres when using \sed). When using \dad, the top-down algorithm is normally a bit slower than the bottom-up algorithm.
Top-down algorithm runs faster than bottom-up algorithm in high sampling datasets when using \ped or \sed.
(e) Online algorithms \bqsa and \opwa both have poor efficiencies.
(f) One-pass algorithms \operb, \siped, \cised and \ridad show a linear running time and they are not very sensitive to error bound $\epsilon$, and also scale well with the increase of trajectory size on all datasets.
(g) The computing of a \dad is faster than \ped and \sed, and the running time of computing \ped and \sed are 2.3 and 1.7 times of \dad, respectively.

Note the findings of compression ratios and running time are not reported in \cite{Zhang:Evaluation}, and for average errors, the items (a),(b), (c) and (d) are concluded from more distinct error bounded \lsa algorithms, including \opt, \siped and \cised, and items (e), (f) and (g) are new findings.


%%********************************* The End **********************************








