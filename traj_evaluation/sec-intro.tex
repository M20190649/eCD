%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-0.5ex}
\section{Introduction}
\label{sec-intro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\eat{%%%%%%%%%%%%
\begin{figure*}[tb!]
	\centering
	%\vspace{-1ex}
	\includegraphics[scale=0.60]{Figures/Fig-DP.png}
	\vspace{-6ex}
	\caption{\small A trajectory $\dddot{\mathcal{T}}[P_0, \ldots, P_{10}]$  with 11 points is represented by (2) two and (3) four continuous line segments (solid blue), compressed by the Douglas--Peucker algorithm \cite{Douglas:Peucker} with error metrics \ped and \sed, respectively.}
	\vspace{-3ex}
	\label{fig:notations}
\end{figure*}
}%%%%%%%%%%%%%%%

%A trajectory is a sequence of GPS data points representing the track of a moving object, which is collected at a certain sampling rate by a GPS sensor, transmitted to and saved in cloud servers for subsequent applications, such as location based services, moving object tracking, user behavior analysis, POI recommendation, {traffic analysis} and so on.
%
With the increasing popularity of GPS sensors on various mobile devices, such as smart-phones, on-board diagnostics, personal navigation devices and wearable smart devices, trajectory data is increasing rapidly. Sampling rates are also improved for acquiring more accurate position information, which leads to longer trajectories than before. Thus, transmitting and storing raw trajectory data consume a large amount of network, storage and computing resources \cite{Chen:Trajectory, Chen:Fast, Meratnia:Spatiotemporal, Keogh:online, Liu:BQS, Muckell:Compression,Cao:Spatio, Popa:Spatio, Schmid:Semantic,Richter:Semantic,Long:Direction,Nibali:Trajic}, and trajectory compression techniques \cite{Douglas:Peucker, Hershberger:Speeding, Meratnia:Spatiotemporal, Liu:BQS, Muckell:Compression, Chen:Trajectory, Chen:Fast, Keogh:online, Cao:Spatio, Shi:Survey, Richter:Semantic ,Long:Direction, Song:PRESS, Nibali:Trajic} have been developed to alleviate this situation.
%
%Various mobile devices, such as smart-phones, on-board diagnostics, personal navigation devices, and wearable smart devices, have been using their GPS sensors to collect massive trajectory data of moving objects at a certain sampling rate, and transmit it to cloud servers for location based services, trajectory mining and many other applications.
%
%
%Further, we find that the online transmitting of raw trajectories also seriously aggravates several other issues such as out-of-order and duplicate data points in our experiences when implementing an online vehicle-to-cloud data transmission system.
%Fortunately, these issues can be resolved or greatly alleviated by the trajectory compression techniques \cite{Douglas:Peucker, Hershberger:Speeding, Meratnia:Spatiotemporal, Liu:BQS, Muckell:Compression, Chen:Trajectory, Chen:Fast, Keogh:online, Cao:Spatio, Shi:Survey, Richter:Semantic ,Long:Direction, Song:PRESS, Nibali:Trajic}.

Due to the  limitations (poor compression ratio and data reconstruction overhead) of lossless compression,  lossy compression techniques has become the mainstream of trajectory compression \cite{Lin:Operb,Zhang:Evaluation}. Quite a few lossy trajectory compression techniques, most notably the piece-wise line simplification \cite{Douglas:Peucker, Hershberger:Speeding, Keogh:online,Liu:BQS, Muckell:Compression, Chen:Trajectory, Chen:Fast, Cao:Spatio, Shi:Survey} solving the \emph{min-$\#$} problem \cite{Chan:Optimal, Imai:Optimal,Pavlidis:Segment}, have been developed. The idea of piece-wise line simplification (\lsa) comes from computational geometry, whose target is to approximate a given finer piece-wise linear curve by another coarser piece-wise linear curve ({normally} a sub set of the former), such that the maximum distance of the former from the later is bounded by a user specified threshold. It is widely used due to its distinct advantages: (a) simple and easy to implement, (b) no need of extra knowledge and suitable for freely  moving  objects \cite{Popa:Spatio}, and (c) bounded errors with good compression ratios.

%These techniques may be lossless or lossy \cite{Muckell:Compression}.
%Lossless compression methods enable exact reconstruction of the original data from the compressed data without information loss.
%For example, delta compression \cite{Nibali:Trajic} is a lossless compression technique for trajectory data, which has zero error.
%The limitation of lossless compression lies in that its compression ratio is relatively poor \cite{Nibali:Trajic} and {queries on the compressed data are time consuming because data reconstructions from the compressed data are needed before the queries}.
%
%In contrast, lossy compression methods typically identify important data points and remove statistical redundant data points from the original data, and allow errors or derivations compared with the original trajectory data.
%These techniques focus on good compression ratios with acceptable errors, and are the mainstream techniques in field of trajectory compression.
%, or replace original data points in a trajectory with other places of interests, such as roads and shops.


\stitle{Algorithm taxonomy}. \lsa algorithms fall into two categories: \textit{optimal} and \textit{sub-optimal} algorithms.
\textit{Optimal} methods\cite{Imai:Optimal,Chan:Optimal} are to find the minimum number of points or segments to represent the original polygonal lines \wrt an error bound $\epsilon$, by transforms the problem to search for the shortest path of a graph built from the original trajectory.
The optimal \lsa algorithms have relative high time/space complexities which make them impractical for large trajectory data.
Hence, \textit{sub-optimal} \lsa algorithms have been developed and/or introduced for trajectory compression, and they achieve better efficiencies at the expense of outputting a little more data points. By the applied distance checking policies, sub-optimal algorithms can further be classified into
batch, online and one-pass algorithms.

\ni (1) {\em Batch algorithms} such as Douglas-Peucker\cite{Douglas:Peucker,Meratnia:Spatiotemporal} and \pavlidis~\cite{Pavlidis:Segment} apply global distance checking policies such that all trajectory points need to be loaded before starting compression, and a point may be checked multiple times to compute its distance to the corresponding line segments.

\ni (2) {\em Online algorithms} such as \opwa \cite{Meratnia:Spatiotemporal}, \squishe \cite{Muckell:SQUISH} and \bqsa \cite{Liu:BQS} apply local distance checking policies, and need not to have the entire trajectory ready before compressing. They restrict the checking within a window, but may still check a point  multiple times during the process.

\ni (3) {\em One-pass algorithms} such as \operb\cite{Lin:Operb}, \siped  \cite{Williams:Longest,Sklansky:Cone,Dunham:Cone, Zhao:Sleeve}, \cised \cite{Lin:Cised} and \interval \cite{Ke:Interval} apply better local distance checking policies, which even do not need a window to buffer the previous read points, and process each point in a trajectory once and only once.

By using local distance checking, online and one-pass algorithms are much more efficient than batch algorithms.

%, such as the convex hull in \bqsa~\cite{Liu:BQS}, the priority queue in \squishe \cite{Muckell:Compression}, the {fitting function} in \operb \cite {Lin:Operb} and the spatio-temporal cone intersection in \cised \cite {Lin:Cised}.


%This work focus on the piece-wise line simplification (\lsa) methods of trajectory compression, more specially, the \emph{min-$\#$ problem} \cite{Chan:Optimal, Imai:Optimal,Pavlidis:Segment} of the piece-wise line based trajectory simplification.
%In trajectory compression, the \lsa algorithms commonly use two distance metrics, \ie the \emph{perpendicular Euclidean distances} (\ped) and the \emph{synchronous Euclidean distances} (\sed).
%Originally, \lsa algorithms adopt \ped as a distance metric.
%\eg $|\vv{P_4P^*_4}|$ is the \ped of data point $P_4$ to line segment $\vv{P_0P_{10}}$ in Figure~\ref{fig:notations} (left).
%\lsa algorithms using \ped have good compression ratios~ \cite{Douglas:Peucker, Hershberger:Speeding, Liu:BQS, Muckell:Compression, Chen:Trajectory, Cao:Spatio, Shi:Survey}. However, when using \ped, the temporal information is lost.
%Thus, a spatio-temporal query, \eg ``\emph{the position of a moving object at time $t$}", on the compressed trajectories by line simplification algorithms using \ped may return an approximate point $P'$ whose distance to the actual position $P$ of the moving object at time $t$ is unbounded.
%For example, a query for the position of $P_7$ at time $t_7$ may return an approximate data point $P'_7$ whose distance to $P_7$ is great than the  bound $\epsilon$ in Figure~\ref{fig:notations} (left).

\stitle{Distance metrics}. Trajectory simplification algorithms are closely coupled with distance metrics, and different techniques are typically needed for different distance metrics.  We consider three wildly adopted metrics: \emph{perpendicular Euclidean distances} (\ped), \emph{synchronous Euclidean distances} (\sed) and \emph{direction-aware distances} (\dad).


Originally, \lsa algorithms adopt \ped as the distance metric, which brings good compression ratios~ \cite{Douglas:Peucker, Hershberger:Speeding, Liu:BQS, Muckell:Compression, Chen:Trajectory, Cao:Spatio, Shi:Survey}. (1) \ped does not preserve the temporal information. Hence, \sed was then introduced to preserve temporal information of trajectories and to support spatio-temporal queries\cite{Meratnia:Spatiotemporal}.
(2) \dad~\cite{Long:Direction, Zhang:Evaluation} was  introduced to preserve the direction information of moving objects, and was initially called the \emph{direction-based measurement} in \cite{Long:Direction}). It is important for applications such as trajectory clustering and direction-based query processing \cite{Long:Direction}.
%
Note that \lsa algorithms using \sed or \dad may produce more line segments than using \ped. However, the use of \sed and \dad further preserve temporal and direction information, respectively.




\begin{table*}
	\renewcommand{\arraystretch}{1.20}
	\vspace{-1ex}
	\caption{\small Evaluated error bounded trajectory simplification algorithms}
	\label{tab:summary-lsa}
	\centering
	\small
	\begin{tabular}{|l|c|c|c|c|c|c|c|c}
		\hline
		\kw{Name}  & \kw{Type}      &\kw{\ped} &\kw{\sed}  &\kw{\dad} &  \kw{Time} & \kw{Space} & \kw{Key~Idea}\\		\hline
		\opt~\cite{Imai:Optimal}	&optimal		&Y & Y & Y & $O(n^3)$	& {$O(n^2)$}  & Reachability Graph\\		\hline
%		\optp\cite{Chan:Optimal}	&optimal		&Y & N & N & $O(n^2)$	& {$O(n)$}  &Graph and Sector intersection  \\		\hline
		\dpa\cite{Douglas:Peucker, Meratnia:Spatiotemporal}	&batch  &Y &Y & Y   & $O(n^2)$ & O(n)   & Top-down \\		\hline
		\tpa\cite{Pavlidis:Segment}	&batch       &Y &Y & Y  & $O(n^2/K)$ & O(n)   &Bottom-up \\		\hline
		\bqsa\cite{Liu:BQS}	&online	   &Y   & N & N & $O(n^2)$  & $O(|Q|)$    &Top-down, opening window and Convex hull  \\		\hline
		\squishe\cite{Muckell:Compression}	&{online}	  & N &Y  & N  & $O(n\log|Q|)$ & $O(|Q|)$  &Bottom-up and Priority queue \\		\hline
		\operb\cite{Lin:Operb}	& one-pass	  &Y & N & N & $O(n)$ & O(1)   & Fitting function \\		\hline
		\siped\cite{Dunham:Cone, Zhao:Sleeve}	&one-pass	  &Y & N & N & $O(n)$ & O(1)  & Sector intersection\\		\hline
		\cised\cite{Lin:Cised}	&one-pass	 	&N & Y & N & $O(n)$ & O(1)  & Spatio-temporal cone intersection \\		\hline
		\interval\cite{Ke:Interval}	&one-pass	 	&N & N & Y & $O(n)$ & O(1)  & Interval intersection \\		\hline
	\end{tabular}
	{\\  Note: $K$ is the number of the final segments of a trajectory and $|Q|$ is the size of a buffer/window.}
	\vspace{-3ex}
\end{table*}



\stitle{Motivations}. Empirical studies on trajectory compression algorithms have been conducted~\cite{Muckell:Compression,MuckellHLR10,mThesis}. However, they only discuss a small number of algorithms. The very recent study \cite{Zhang:Evaluation} does evaluate a wide range of trajectory simplification algorithms,
and it provides a good experimental study on compression error and spatio-temporal query analyses. However, two important aspects for trajectory simplification (\ie  compression ratios and running time) are not systematically studied in \cite{Zhang:Evaluation}. As a consequence, it remains difficult for practitioners to decide which algorithms and distance metrics should be adopted for a specific application.

%concerning the compression ratio and error of the result data, and the execution time of these compression algorithms.
% Thus, these issues call for a more comprehensive evaluation of the existing \lsa techniques. % on trajectory data.





\stitle{Contributions}.
In this paper, we conduct a thorough and systematic evaluation and analyese of the mainstream trajectory compression techniques (\ie  error bounded trajectory simplification) for large-scale trajectory data.

\sstab (1) We classify error bounded \lsa algorithms into different categories, review each category of algorithms, and systematically evaluate the representative algorithms of each category.
%
\mytable{tab:summary-lsa} summarizes the algorithms, which consist of
optimal and suboptimal algorithms, and the later is further classified into batch, online and one-pass algorithms.
Note that online and one-pass algorithms are typically designed for a specific distance metric of \ped, \sed and \dad.
%optimal algorithm \opt,
%batch algorithms \douglas and \pavlidis,
%online algorithms \bqsa and \squishe,  and
%one-pass algorithms \operb, \siped, \cised and \interval.

\sstab (2) Using four real-life trajectory datasets, we systematically evaluate and analyze the performance (compression ratio, average error and running
time) of error bounded \lsa algorithms in terms of trajectory sizes and error bounds.
%
(i) For a fair running time analysis, all algorithms are (re)-implemented in Java, unlike \cite{Zhang:Evaluation} that reports running time of algorithms with different programming languages. (ii) compression ratio analyses are not considered in \cite{Zhang:Evaluation}. (iii) Optimal algorithms of \ped and \sed and one-pass algorithms \siped and \cised are not investigated in \cite{Zhang:Evaluation}. Indeed, algorithm \siped (sector intersection) is {\em completely overlooked} by existing trajectory compression studies as it is originally developed in fields of computational geometry and pattern recognition~\cite{Williams:Longest,Sklansky:Cone,Dunham:Cone, Zhao:Sleeve}, and we find that it can be easily adopted for trajectory compression with good performances.


 Essentially, this study is an important complimentary to \cite{Zhang:Evaluation} by  providing a thorough and systematic evaluation and analyese of error bounded trajectory simplification algorithms. Further, though  \cite{Zhang:Evaluation}  tests the average errors of algorithms from the aspect
of applications, \ie spatio-temporal queries,  different applications have different requirements, and it is hardly to enumerate all of them.  Hence, we focus on revealing the intrinsic characteristics of algorithms, and providing guidelines and suggestions on the choice of methods and distance metrics for different scenarios.

 \eat{%%%%%%%%%%%%%%%%%
 provides a good experimental study on databases usability in terms of spatio-temporal query analyses,




This paper presents an experimental comparison of the state-of-the-art \lsa algorithms for trajectory compression, including \emph{both the optimal and the sub-optimal methods that use either \ped or \sed or \dad}.



Using a variety of real trajectory datasets, we evaluated the performance of each technique in terms of its processing time, compression ratio and average error.
%with up to \textcolor{red}{$2.5$} billion data points
Our experimental results reveal the characteristics of different techniques.
%%\textcolor{red}{In addition, some of our findings are not reported in preview work and some are the supplements of or in contradiction with the preview works such as \cite{Zhang:Evaluation}.}
%
Based on these findings, we provide guidelines on selecting appropriate methods and distance metrics for various scenarios.

Note algorithms without error bound, \eg the $n^{th}$ point routine and the routine of random-selection of points\cite{Shi:Survey},
and algorithms using cumulative error, \eg MRPA that uses the  integral square synchronous Euclidean distance \cite{Chen:Fast}, are out of the scope.

%\begin{enumerate}
\ni (1) Three distance metrics, \ie the \ped and \dad for spatial compression and the \sed \cite{Meratnia:Spatiotemporal} for spatio-temporal compression, which are supported in those algorithms, and what impacts they are on performance, have not been compared systematically under the same experimental platform.

\ni (2) The effectiveness and the room for improvement of sub optimal \lsa algorithms compared with the optimal \lsa algorithms on trajectory data are not comprehensively studied.

\ni (3) The ``sector intersection" algorithms \cite{Williams:Longest, Sklansky:Cone, Dunham:Cone, Zhao:Sleeve} developed in fields of graphic, cartographic and pattern recognition, which run fast as well as have good performance, are still not introduced to the field of trajectory compression.

\ni (4) The recent important progresses in the field of trajectory simplification, \ie online algorithms \squishe~\cite{Muckell:Compression} using \sed and \bqsa~\cite{Liu:BQS} using \ped, and one-pass algorithms \operb~\cite{Lin:Operb} and \siped \cite{Williams:Longest, Sklansky:Cone, Dunham:Cone, Zhao:Sleeve} using \ped, \cised~\cite{Lin:Cised} using \sed and \interval \cite{Ke:Interval} using \dad are not systematically evaluated for trajectory data.

%\end{enumerate}
\stitle{\textcolor{blue}{Notes: Advantages of Zhang' Evaluation\cite{Zhang:Evaluation}}}.

\textcolor{blue}{(1) Tests a wild list of algorithms}

\textcolor{blue}{(2) Tests the average errors of algorithms from the view of application: Spatio-temporal query}

\stitle{\textcolor{blue}{Notes: Limitations of Zhang' Evaluation\cite{Zhang:Evaluation}}}.

\textcolor{blue}{(1) Algorithms are listed without organizing.}

\textcolor{blue}{(2) Many algorithms are not so important or typical or practical for trajectory simplification, \eg Uniform is not error bounded, Dead Reckoning has really poor compression ratios.}
% It is easy to conclude these from the natures of these algorithms or from preview works,

\textcolor{blue}{(3) The optimal algorithms of \ped and \sed are not covered in the work.}

\textcolor{blue}{(4) Some important sub-optimal algorithms are not covered, \eg \sleeve, \cised.}

\textcolor{blue}{(5) Distance metrics, especially \ped and \sed, are not comprehensively compared in the work.}

\textcolor{blue}{(6) Compression ratio is not tested and compared, though it is one of the most important metrics of trajectory simplification algorithms.}

\textcolor{blue}{(7) Another metric, runtime time, is not systematically tested in the same environment. Algorithms are implemented in different programming languages, \ie C/C++, Java, Matlab and Python, and the impacts of trajectory sizes and error bounds on running time are not tested.}

\textcolor{blue}{(8) The max distance errors are not discussed in the tests, and it is unjustified to take the average errors as the only quality metric of algorithms and neglect the max distance errors, especially that some algorithms in the tests are not error bounded or use threshold on the accumulate errors.
Indeed, the average errors and the max errors both are metrics of quality of algorithms. Some algorithms, \eg the optimal algorithms, may have relative larger average errors, however, they are error bounded. Some algorithms, \eg algorithms MRPA and DOTS that apply the accumulate SED error (ISSED), may lead to very large max errors though they have relative small average errors.}

\textcolor{blue}{(9) It is unfair to conclude the guidelines based on the average error only. As we know, the algorithm that outputs the original input points is sure having the best/smallest average errors, but it is nonsense. In other words, algorithm has relative large average error as well as has good compression ratios may be a good choice in some scenarios.}
 }%%%%%%%%%%%%%%%%%



\stitle{Organization}. Section 2 introduces basics concepts of trajectory simplification,
Section 3 and Section 4 systematically review optimal and sub-optimal \lsa methods, respectively,
Section 5 reports and analyzes the experimental results, followed by
conclusions in Section 6.
%, and the appendix covers additional related work and experimental results.% on algorithm \nopts compared with \opt.



