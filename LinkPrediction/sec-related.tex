\section{Related work}
\label{sec-related}

% extension
\marked{This paper is an extension of our earlier work \cite{liang2016} by adding
(a) an optimizing method for speeding up top-$k$ predictions when a threshold is
available, (b) an edge sampling method to reduce the network sizes of ensembles
while keeping high prediction accuracy, and (c) experiments on the above modifications. }\\


%\stitle{Link Prediction}. \\
%\cite{dong2015} studies the problem of link prediction in coupled networks when given the structure
%of one (source) network and the interactions between this network and another (target) network.
%Predicting the missing links in the target network. \\

%\cite{chen2015} proposes a framework called Divers Ensemble of Drastic Sparsification (DEDS) to
%construct ensemble classifiers with good accuracy while keeping the prediction time short by graph
%sparsification. \\

%\cite{song2015} proposes two top-$k$ link recommendation algorithms which focus on optimizing the top
%ranked links. \\

%\cite{song2015kdd} develops two linear time probabilistic models, entitled efficient latent link
%recommendation (ELLR) algorithms, to infer personalized ranking lists of latent links. \\


%\cite{zhai2015} investigates both matrix factorization and autoencoder's application to the link prediction
%problem in sparse graphs. \\

%\cite{subbian2015} is to build a robust and effective classifier for link prediction using multiple auxiliary
%networks. \\

%\cite{zhao2016} is to predict links online and in a dynamic way in graph streams. \\

%\cite{parotsidis2016} is to recommend to users links that if adopted would improve the user centrality in the
%network. \\



%\stitle{\NMF}.
%\cite{yu2015} proposes a novel matrix computation system, name DMac, which exploits the matrix
%dependencies in matrix programs for efficient matrix computation in the distributed environment.\\


%\stitle{top-k}. \cite{ballard2015} finds the top-$t$ largest dot products among all possible pairs of
%two sets of vectors.\\
%\cite{lemp} studies the problem of efficiently retrieving large entries in the product of two given factor
%matrices. \\



%\stitle{Graph Sampling, Graph Sparsification}.
%\cite{li2015} systematically analyze the drawbacks of the
%existing random walk based graph sampling algorithms, and present new solutions to balance the tradeoffs
%of these drawbacks.
%\cite{zhou2015} provides two algorithms by leveraging historic transitions to speed up random walks over
%online social networks.
%\cite{nazi2015} introduces a backward random walk techniques for faster sampling of nodes over an online social network.\\
%\cite{chierichetti2016} considers the problem of sampling nodes from a large graph according to a prescribed
%distribution by using random walk as the basic primitive.




% link prediction: survey, unsupervised vs. supervised, neighborhood-based, path-based, low-rank approximate, nmf, svd,
% refer to missing values, negative link prediction, explanation, cross networks, community detection
% bagging, graph sampling methods,

The link prediction problem has been studied extensively in the data mining and machine learning community
\cite{kleinberg,linyuan-2011}, which falls into unsupervised and supervised methods \cite{propflow}. Unsupervised methods
often assign scores to potential links based on the topology of the given graphs:
(a) Adamic/Adar \cite{adamic} is a common neighbor based method; (b) Katz \cite{katz-1953} is a
path based method which sums over all paths between two nodes, and there are also other path based
methods, such as Local Path and Random Walk with Restart \cite{linyuan-2011}; And (c)
\marked{\cite{kunegis,kleinberg, zhai2015} } investigates the low rank approximation methods by generating a
small rank matrix to approximate the initial adjacency matrix. Supervised methods
\marked{\cite{Link09,propflow,chen2015} }typically treat link prediction as a classification problem, e.g., supervised matrix factorization and random walk based approaches \cite{menon,back}.

Recently, several models for link prediction have been proposed,
such as  community affiliation models \cite{yang-wsdm2013}, stochastic topic models \cite{barbieri2014},
negative link prediction models \cite{tang2015} and statistical relational models \cite{bilgic,Getoor01,Getoor02}. 
Moreover, link prediction has also been studied for mining
missing hyperlinks \cite{west2015}.
While some recent work has focused on the heterogeneous \cite{yang}, temporal \cite{back,dwang} scenarios, \marked{dynamic networks \cite{zhu2016}, coupled networks \cite{dong2015},
graph streams \cite{zhao2016} and signed networks \cite{song2015kdd}. Some optimizing methods for link recommendation have been proposed to improve the precision at the top of the recommending list \cite{song2015}.}
These methods are not essentially
designed to search the entire space of $O(n^2)$ possibilities. Indeed, they are often not able to prune the search space of possibilities, and are mostly designed to evaluate the link prediction propensities of a subset of node pairs.

Our method is related to \NMF proposed in \cite{NMF-nature99}, which
has been successfully used for collaborative
filtering \cite{web}. Since the adjacency matrix in our approach is symmetric, we adopt
the symmetric \NMF method \cite{ding}. \marked{Methods for retrieving large entries in the product of
two matrices have been studied in \cite{ballard2015, lemp}, which motivate us to speed up the
top-$(\epsilon, k)$ prediction.} Our work is also related
to bagging predictor \cite{Breiman96b-1996} that generates an aggregated
predictor based on multiple bootstrap samples. Different from the bootstrap
sampling methods, we focus on sampling subgraphs from large networks. Although a
variety of graph sampling techniques \marked{  and analyze were introduced
in \cite{ahmed2014tkdd,li2015,chierichetti2016} }
, our approach combines link
prediction characteristics \cite{leskovec-2008} with graph sampling
methods to achieve high link prediction accuracy.






