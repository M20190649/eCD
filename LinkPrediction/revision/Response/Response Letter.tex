\documentclass{letter}
\usepackage{geometry}

% duan
\usepackage{xspace}

\geometry{left=2.0cm, right=2.0cm, top=2.5cm, bottom=2.5cm}
\newcommand{\ie}{\emph{i.e.,}\xspace}
\newcommand{\eg}{\emph{e.g.,}\xspace}
\newcommand{\wrt}{\emph{w.r.t.}\xspace}
\newcommand{\aka}{\emph{a.k.a.}\xspace}
\newcommand{\kwlog}{\emph{w.l.o.g.}\xspace}
\newcommand{\etal}{\emph{et al.}\xspace}
\newcommand{\sstab}{\rule{0pt}{8pt}\\[-2.4ex]}



\begin{document}

Prof. Xuemin Lin,\\
Editor-in-Chief,\\
IEEE Transactions on Knowledge and Data Engineering\\

Dear Prof. Lin,

Attached please find a revised version of our submission to
IEEE Transactions on Knowledge and Data Engineering, \emph{An Ensemble
Approach to Link Prediction}.

The paper has been substantially revised according to the referees＊ comments.
In particular, (1) we have added an example for illustrating the procedure of
the top-$(\epsilon, k)$ prediction in Section 2.1, (2) we have added the
Resource Allocation (RA) algorithm for comparison in the experimental study,
(3) we have compared our methods with the state-of-the-art methods when
$k$ is fixed to the number of links in the ground truth data, (4) we have added
a set of tests for evaluating the ensemble-enabled approach with other link
prediction methods, \eg Adamic/Adar (AA) and RA,
and (5) we have also taken this opportunity to rewrite several parts of the
paper to improve the presentation.

We would like to thank all the referees for their thorough reading of our
paper and for their valuable comments.

Below please find our responses to the comments by the referees.

%******************* reviewer 1 ***********************************************
\line(1,0){500}

\textbf{Response to the comments of Referee 1.}

\textbf{[R1C1]} \emph{When talking about the recommendation, in addition to
the survey by Adomavicius and Tuzhilin, I recommend another survey from
physical society [L. Lu, et al., Recommender Systems, Phys. Rep. 519 (2012) 1-49],
in particular, this survey discussed the similarity and difference of link
prediction and personalized recommendation.}

We have added this survey in the related work (Section 5). Thanks!

[29] L. L\"{u}, M. Medo, C. H. Yeung, Y. Zhang, and Z. Zhang. Recommender
systems. Physics Reports, 519:1-49, 2012.


\textbf{[R1C2]} \emph{In a sparse network, for most common neighborhood
based methods (e.g., CN, AA, Resource Allocation Index, Jaccard coefficient, etc.),
the time complexity is not $O(n^2)$, but $O(n*k^2)$, where $k$ is the average degree.
It is because for most node pairs, the CN-based similarities are zero.
Therefore, the corresponding statements should be modified.}

Yes, we have discussed the complexities of AA and RA when we introduce them in Section 4.1. Moreover, $O(n^2)$ typically refers to the number of possible links in our paper.


\textbf{[R1C3]} \emph{I can follow the operations to obtain S and R for
the efficient top-k search, however, the physical meaning of this approximation
is not clear. I strongly suggest the authors to show a clear picture,
for example, by illustrate the procedure for a small-size case link $n$ around 7,8
and r around 3,4. So that we could see the meaning of the method as well as
how to construct S and R step by step.}

We have added Example 1 (Section 2.1) to illustrate the procedure for   
top-$(\epsilon, k)$ prediction searching. Thanks for the suggestion!


\textbf{[R1C4]} \emph{How to determine $\theta$ when using the speeding up
method (Eq. 4 and Eq. 5). In addition, I do NOT think the proof of
Proposition 2 is necessary, since it is very obvious and provides
nothing more than Eq. 4 and Eq. 5.}

We have explained the setting of the parameter $\theta$ in the second last paragraph of Section 3.6, and removed Proposition 2. Thanks for the suggestion!



\textbf{[R1C5]} \emph{The edge bagging method is originally called snowball
sampling, please cite the original paper [P. Biernacki and D. Waldorf,
Snowball sampling: Problems and techniques of chain referral sampling,
Sociological Methods and Research 10 (1981) 141].}

The snowball sampling has been introduced in the graph sampling
survey [4] in our references. Indeed, the edge bagging method
is different from the snowball sampling because the edge bagging only
selects a random adjacent node when the sampled node set is grown.
Hence, we did not cite the recommended paper directly due to space limitations (as you can see, we already provide a supplementary).  Thanks!


[4] N. K. Ahmed, J. Neville, and R. Kompella. Network sampling: From
static to streaming graphs. Transactions on Knowledge Discovery from
Data (TKDD), 8(2):7:1每7:56, 2014.


\textbf{[R1C6]} \emph{I personally like the biased edge bagging method,
and I agree with the statement "it often becomes more difficult to make
robust predictions between low-degree nodes". Please read and discuss
the following paper [Y. X. Zhu, Uncovering missing links with cold ends.
Physica A 391 (2012) 5769-5778.] that focuses on the related issue.
By the way, the authors are encouraged to test their novel bagging
methods for links with cold ends.}
 
We focus on predicting future links that split by timestamps (the datasets we used have timestamps of edge arrivals) rather than missing links
that selected randomly from the network as the testing set [17][24]. Hence, we believe these methods are not comparable.

[17] M. A. Hasan and M. J. Zaki. A survey of link prediction in social
networks. In Social Network Data Analytics, 2011.

[24] D. Liben-Nowell and J. Kleinberg. The link prediction problem for social
networks. Journal of the American society for information science and
technology, 58(7):1019每1031, 2007.


\textbf{[R1C7]} \emph{In addition to the related works from computer
science community, the authors should also highlight some important
works from physical science community, such as [Clauset, A., Moore, C., $\&$ Newman, M. E. (2008).
Hierarchical structure and the prediction of missing links in networks. Nature, 453(7191), 98-101],
[Guimer角, R., $\&$ Sales-Pardo, M. (2009). Missing and spurious interactions
and the reconstruction of complex networks. PNAS, 106(52), 22073-22078]
and [L邦, L., Pan, L., Zhou, T., Zhang, Y. C., $\&$ Stanley, H. E. (2015).
Toward link predictability of complex networks. PNAS, 112(8), 2325-2330.].}

We have added
the link predictability work [30] in the related work (Section 5), and the surveys papers [17]\&[31]. 

[17] M. A. Hasan and M. J. Zaki. A survey of link prediction in social
networks. In Social Network Data Analytics, 2011.

[30] L. L\"{u}, L. Pan, T. Zhou, Y. Zhang, and H. Stanley. Toward link
predictablility of complex networks. PNAS, 118(8):2325每2330, 2015.

[31] L. L\"{u} and T. Zhou. Link prediction in complex networks: A survey.
Physica A, pages 1150每1170, 2011.

\textbf{[R1C8]} \emph{Please compare the prediction accuracy of current
bagging methods with some other methods like resource allocation index
[Zhou, T., L邦, L., $\&$ Zhang, Y. C. (2009). Predicting missing links via
local information. The European Physical Journal B-Condensed Matter and
Complex Systems, 71(4), 623-630.], loop model [Pan, L., Zhou, T., L邦, L., $\&$ Hu, C. K. (2016).
Predicting missing links and identifying spurious links via likelihood
analysis. Scientific reports, 6, 22955.] and the above mentioned three
methods (see comment 7, Nature 2008, PNAS 2009 and PNAS 2015), in some
smaller size networks. Therefore we get more clear picture how accurate
the present method is.}

Yes, we have added RA as a comparison algorithm in the experimental study. However,
we did not adopt other algorithms for comparison since the complexities of these
algorithms are at least $O(n^2)$ and they cannnot work on large
networks with millions of nodes. Thanks for the suggestion!


%******************* reviewer 2 ***********************************************
\line(1,0){500}

\textbf{Response to the comments of Referee 2.}

\textbf{[R2W1]} \emph{Due to the fact that the decomposition is based
on random sampling, thus authors should provide the 95\% confidence
intervals of performance. This is important to demonstrate that the
proposed methods are significantly better than the state-of-the-art
methodology.}

We have added comparisons of accuracy together with its
95\% confidence intervals of our methods when $k$ is fixed
to its default value and the number of links in the ground truth
data. For the lack of space, we report these results in the Appendix A
of the supplementary material. The results verifies the robustness of
our methods compared with the state-of-the-art methods.
Thanks for the suggestion!


\textbf{[R2W2]} \emph{Authors are using top-k precision to evaluate
the link prediction results. However, the measurement is not used
correctly. Top-k precision will give a fair comparison between different
link prediction methods only when the K is well selected. Please refer
to the paper "Evaluating link prediction methods". Top-k precision
measurement can have different conclusions on link prediction results
when there are some small changes of the value K. K should be the
number of true links in test set (fixed). In this paper, authors
mentioned that the K range from $10^4 - 10^5$, this is not a correct
way to employ this measurement.}

Since we focus on the top-$k$ ranking problem for link prediction, we
intuitively adopt the top-$k$ precision for evaluation. We agree with
that small changes of the value $k$ may lead to different conclusions,
so we tested the impact of varying $k$ in the experimental study.
Moreover, we tested the ensemble-enabled approach when $k$ is fixed to the number of links in
the ground truth data. The results are reported in the Appendix A
of the supplementary material and indicate the robustness
and efficiency of our methods compared with other methods.
One thing should be noted that the datasets used in our experiments
are more sparse than that used in [S1], which means that it
is more difficult to predict links in our datasets. As a result, the top-$k$
precision on our datasets, when $k$ is fixed to the number of links in the
ground truth data, is too small to be used in practice. Therefore, we maintain
the default values for $k$ in the experimental study similar to [35][39].

[S1] Y. Yang, R. N. Lichtenwalter, and N. V. Chawla. Evaluating link prediction
methods. Knowl Inf Syst, 45:751每782, 2015.

[35] D. Song, D. Meyer, and D. Tao. Top-k link recommendation in social
networks. In ICDM, 2015.

[39] R. West, A. Paranjape, and J. Leskovec. Mining missing hyperlinks from
human navigation traces: A case study of wikipedia. In WWW, 2015.



\textbf{[R2W3]} \emph{AA can only predict two hops links, it has no
predictive power to infer any potential links with larger hop distance.
Thus to provide a fair comparison, authors should provide the performance
comparison in each hop distance, namely hop 2, hop 3, and etc.
An example can be found in "Evaluating link prediction methods".}

We have added an accuracy comparison of our methods and
BIGCLAM in each hop distance in Section 4.2.4. The results illustrate
that all of these methods are more accurate in predicting short distance
links and have little ability to predict links with distance greater than
3 hops. This is a limitation of our methods and we want to address it
in the future to provide a better predictor. Thanks for the suggestion!


\textbf{[R2W4]} \emph{Authors proposed a framework to decompose the
large scale network link prediction problem, thus the latent factor
model can be replaced with some other link prediction methods. So
what if we replace latent factor model with the AA method, how is
the performance? Whether the ensembled AA results yield comparable
performance than the AA in the original network?}

We have declared in Section 3.6 that the ensemble-enabled approach
is a general method for decomposing the large network link prediction
problem into smaller subproblems. It is not only designed for NMF, but also
applied to any other link prediction methods. Moreover, we revised the bagging+
and bagging methods by replacing NMF with AA and RA and evaluated their performance
in the Appendix B of the supplementary material. The results indicate that the
ensemble-enabled AA and RA are more accurate and faster than their counterparts
AA and RA on most of the datasets, which verifies the robustness and efficiency
of our ensemble-enabled approach.


%******************* reviewer 3 ***********************************************
\line(1,0){500}

\textbf{Response to the comments of Referee 3.}

\textbf{[R3C1]} \emph{The section could be preceded by clearly noting
the two challenges (prediction/training complexity) in large networks,
and how separate tools are used to handle each.}

We have added the remarks to explain the two challenges and how to handle
them by latent fact models and the top-$(\epsilon, k)$ prediction searching
method in Section 2.


\textbf{[R3C2]} \emph{The basic model proposed is $W = FF^T$. This is
quite sensible, but in comparison with the eigendecomposition,
one misses the diagonal matrix of possibly negative weights.
A comment on the limitation of this assumption may be prudent. See also
Peter Hoff. Modeling homophily and stochastic equivalence in symmetric
relational data. NIPS 2008.}

We adopt NMF because it requires only $O(nr^2)$ time to be trained and
it generates non-negative and sparse factorized matrices [21], which could
be searched efficiently by our top-$(\epsilon, k)$ prediction searching method.
Without the non-negativity constrains, the factorized matrix would contain
negative entries and be dense [46], which makes it more difficult to be searched.

%Moreover, NMF gives latent space an parts-based
%interpretation. Each dimension of latent space could be interpreted by a
%part of user's attributes, such as current city, hometown, personality and
%so on. It is more intuitive to represent each user as an additive mixture of
%attributes rather than represent each user as a combination of different
%representatives [51].


[21] D. D. Lee and H. S. Seung. Learning the parts of objects by non-negative
matrix factorization. Nature, 401:788每791, 1999.

[46] L. Zhu, D. Guo, J. Yin, G. V. Steeg, and A. Galstyan. Scalable temporal
latent space inference for link prediction in dynamic social networks.
TKDE, 28(10):2765每2777, 2016.

\textbf{[R3C3]} \emph{The remark that absent links may be interpreted
as noisy ones is a reasonable one. There has been relevant work on
dealing with such noisy data in a matrix setting, e.g. Cho-Jui Hsieh,
Nagarajan Natarajan, Inderjit Dhillon. PU Learning for Matrix Completion.
ICML 2015. This is perhaps more prudent that directly fitting the value 0
for absent links.}

Since the social networks are often sparse, we fit the value 0 for absent links,
which simplifies the framework of latent factor models and provides an
intuitive way for predicting links. Thanks!


\textbf{[R3C4]} \emph{A citation should be provided for the claim
that NMF usually results in sparse F. In standard matrix factorisation
models the latent weights are usually completely dense.}

We have added a citation [21] that shows the factorized matrices of NMF
are usually sparse. Thanks!

[21] D. D. Lee and H. S. Seung. Learning the parts of objects by non-negative
matrix factorization. Nature, 401:788每791, 1999.

\textbf{[R3C5]} \emph{The explanation of the top-K prediction component
could be considerably improved. At present, the algorithm is presented,
and correctness shown, but one is not left with a lot of intuition for
what exactly is being done, and how it speeds up the computation. My
current understanding is that one views the computation of scores for a
pair (i, j) via
$W_{ij} = F_i F_j^T = S_i S_j^T = \sum_{p} S_{ip} * S_{jp} = \sum_{p} B^{p}_{ij}$
for a suitable set of matrices $B^{p}$. And that one then looks to compute
only some of the entries of this matrix, with the rest treated as zero.
However, in this view it is unclear why the loop over j does not include
the nodes with score greater than $\sqrt{(eps/r)}$; in fact what happens
when all nodes satisfy this condition is a bit unclear.}

To illustrate the procedure of the top-$(\epsilon, k)$ prediction clearly,
we have added an example in Section 2.1. Thanks!

\textbf{[R3C6]} \emph{In Proof of Prop 1, it is worth commenting that
when we break the loop, we are guaranteed that $S(i,p) * S(j',p) < e/r$
for all further j', since the S are sorted.}

We have added the commentary in the Proof of Proposition 1.
Thanks for the suggestion!

\textbf{[R3C7]} \emph{In discussing the motivation, comment could be
made about the complexity of stochastic gradient training of latent
factor models.}

We have added the complexity of training of latent factor models in
Section 3. Thanks!

\textbf{[R3C8]} \emph{Comment could be made that in principle, the
methods proposed here could be applied to any link prediction method,
and that there is nothing latent factor specific.}

We have added an explanation in Section 3.6 to declare that the ensemble-enabled approach
is a general method for decomposing the large network link prediction
problem into smaller subproblems. It is not only designed for NMF, but also
applied to any other link prediction methods. Moreover, we implemented
ensemble-enabled methods with AA and RA and evaluated their performance
in the Appendix B of the supplementary material. The results indicate that the
ensemble-enabled AA and RA are more accurate and faster than their counterparts
AA and RA on most of the datasets, which verifies the robustness and efficiency
of our ensemble-enabled approach.



\textbf{[R3C9]} \emph{The Flickr dataset only seems to be used
in Sex 4.2.5, and not the other experiments. If this is indeed so,
there does not appear to be an explanation of why.}

The Flickr dataset in used to illustrate the limitation that
bagging methods may reduce the prediction accuracy when the pairwise
overlapping of predicted links is high, \ie the diversity of ensembles
is lower. We think this result is useful for instructing uses to apply
the bagging methods in a correct way.


\textbf{[R3C10]} \emph{4.2.1 and 4.2.4 seem like they should be merged,
as both deal with the comparison of the same two groups of methods.}

We have merged the Section 4.2.1 and 4.2.4. Thanks!

\textbf{[R3C11]} \emph{On the presentation side, below are a few
comments that may improve the final manuscript:\\
- perhaps using $\bar{f}_i$ rather $\bar{F}_i$ would be clearer\\
- use $\backslash$left( and $\backslash$right) for Eqn 3\\
- use $\cos$, $\log$, $\exp$\\
- Prop 3, "IS included"\\
- Sec 3.5, "pretty good result" is informal\\
- Sec 4, "impacts of various factors" seems vague\\
- Sec 4.1, "largest AA SCORING"\\
- Sec 4.1, "that THE more communities"\\
- Sec 4.1, "GIVEN F, the BIGCLAM"\\
- Sec 4, consider expanding lists of conclusions of the form (a) ..., (b) ..., so that each bullet starts on a new line.\\
- Exp 1.2, "methods SCALE better than"}

We have fixed these typos. Thanks!


\line(1,0){500}

Your sincerely,

Liang Duan, Charu Aggarwal, Shuai Ma, Tiejun Ma, Jinpeng Huai

\end{document}
